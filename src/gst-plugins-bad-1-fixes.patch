diff --git a/sys/wasapi2/gstwasapi2activator.cpp b/sys/wasapi2/gstwasapi2activator.cpp
index a8b70d1..6563130 100644
--- a/sys/wasapi2/gstwasapi2activator.cpp
+++ b/sys/wasapi2/gstwasapi2activator.cpp
@@ -89,16 +89,32 @@ Wasapi2ActivationHandler::ActivateCompleted (IActivateAudioInterfaceAsyncOperati
 {
   ComPtr<IUnknown> iface;
   HRESULT hr = S_OK;
-  hr = op->GetActivateResult (&hr, &iface);
+  HRESULT activate_hr = S_OK;
+  hr = op->GetActivateResult (&activate_hr, &iface);
+  if (!gst_wasapi2_result (hr))
+    GST_WARNING ("Couldn't get activate result, hr: 0x%x", (guint) hr);
+
+  if (!gst_wasapi2_result (activate_hr)) {
+    GST_WARNING ("GetActivateResult failed, hr: 0x%x", (guint) activate_hr);
+    hr = activate_hr;
+  }
+
+  if (SUCCEEDED (hr) && !iface) {
+    GST_ERROR ("Couldn't get inteface from asyncop");
+    hr = E_FAIL;
+  }
+
   if (FAILED (hr)) {
-    GST_ERROR ("Couldn't get activate result, hr: 0x%x", (guint) hr);
     activate_hr_ = hr;
     SetEvent (event_);
     return hr;
   }
 
-  hr = iface.As (&client_);
-  activate_hr_ = hr;
+  {
+    std::lock_guard<std::mutex> lk (lock_);
+    hr = iface.As (&client_);
+    activate_hr_ = hr;
+  }
 
   GST_LOG ("Activation result 0x%x", (guint) hr);
 
@@ -133,6 +149,10 @@ Wasapi2ActivationHandler::GetClient (IAudioClient ** client, DWORD timeout)
   if (!client)
     return S_OK;
 
+  std::lock_guard<std::mutex> lk (lock_);
+  if (!client_)
+    return E_FAIL;
+
   *client = client_.Get ();
   (*client)->AddRef ();
 
diff --git a/sys/wasapi2/gstwasapi2activator.h b/sys/wasapi2/gstwasapi2activator.h
index ed3c433..a00ee11 100644
--- a/sys/wasapi2/gstwasapi2activator.h
+++ b/sys/wasapi2/gstwasapi2activator.h
@@ -24,6 +24,7 @@
 #include <wrl.h>
 #include <atomic>
 #include <string>
+#include <mutex>
 
 /* Copy of audioclientactivationparams.h since those types are defined only for
  * NTDDI_VERSION >= NTDDI_WIN10_FE */
@@ -85,6 +86,7 @@ private:
 private:
   Microsoft::WRL::ComPtr<IAudioClient> client_;
   std::atomic<HRESULT> activate_hr_ = { E_FAIL };
+  std::mutex lock_;
   HANDLE event_;
   PROPVARIANT prop_ = { };
   AUDIOCLIENT_ACTIVATION_PARAMS params_ = { };
diff --git a/sys/wasapi2/gstwasapi2device.cpp b/sys/wasapi2/gstwasapi2device.cpp
index 007e610..d0f88ac 100644
--- a/sys/wasapi2/gstwasapi2device.cpp
+++ b/sys/wasapi2/gstwasapi2device.cpp
@@ -26,8 +26,21 @@
 #include "gstwasapi2util.h"
 #include "gstwasapi2enumerator.h"
 
-GST_DEBUG_CATEGORY_EXTERN (gst_wasapi2_debug);
-#define GST_CAT_DEFAULT gst_wasapi2_debug
+#ifndef GST_DISABLE_GST_DEBUG
+#define GST_CAT_DEFAULT ensure_debug_category()
+static GstDebugCategory *
+ensure_debug_category (void)
+{
+  static GstDebugCategory *cat = nullptr;
+
+  GST_WASAPI2_CALL_ONCE_BEGIN {
+    cat = _gst_debug_category_new ("wasapi2deviceprovider",
+        0, "wasapi2deviceprovider");
+  } GST_WASAPI2_CALL_ONCE_END;
+
+  return cat;
+}
+#endif
 
 enum
 {
@@ -42,6 +55,7 @@ struct _GstWasapi2Device
   gchar *device_id;
   const gchar *factory_name;
   GstWasapi2EndpointClass device_class;
+  gboolean is_default;
 };
 
 G_DEFINE_TYPE (GstWasapi2Device, gst_wasapi2_device, GST_TYPE_DEVICE);
@@ -216,24 +230,62 @@ gst_wasapi2_device_provider_probe (GstDeviceProvider * provider)
 
     auto props = gst_structure_new ("wasapi2-proplist",
         "device.api", G_TYPE_STRING, "wasapi2",
-        "device.id", G_TYPE_STRING, entry->device_id,
+        "device.id", G_TYPE_STRING, entry->device_id.c_str (),
         "device.default", G_TYPE_BOOLEAN, entry->is_default,
-        "wasapi2.device.description", G_TYPE_STRING, entry->device_name,
-        nullptr);
+        "wasapi2.device.description", G_TYPE_STRING,
+        entry->device_name.c_str (),
+        "device.form-factor", G_TYPE_INT,
+        (gint) entry->device_props.form_factor,
+        "device.form-factor-name", G_TYPE_STRING,
+        gst_wasapi2_form_factor_to_string (entry->device_props.form_factor),
+        "device.enumerator-name", G_TYPE_STRING,
+        entry->device_props.enumerator_name.c_str (), nullptr);
+
+    if (entry->is_default) {
+      if (!entry->actual_device_id.empty ()) {
+        gst_structure_set (props, "device.actual-id", G_TYPE_STRING,
+            entry->actual_device_id.c_str (), nullptr);
+      }
+
+      if (!entry->actual_device_name.empty ()) {
+        gst_structure_set (props, "device.actual-name", G_TYPE_STRING,
+            entry->actual_device_name.c_str (), nullptr);
+      }
+    } else {
+      gst_structure_set (props,
+          "device.shared-mode-engine-default-period-us", G_TYPE_INT64,
+          entry->shared_mode_engine_default_period_us,
+          "device.shared-mode-engine-fundamental-period-us", G_TYPE_INT64,
+          entry->shared_mode_engine_fundamental_period_us,
+          "device.shared-mode-engine-min-period-us", G_TYPE_INT64,
+          entry->shared_mode_engine_min_period_us,
+          "device.shared-mode-engine-max-period-us", G_TYPE_INT64,
+          entry->shared_mode_engine_max_period_us,
+          "device.default-device-period-us", G_TYPE_INT64,
+          entry->default_device_period_us,
+          "device.min-device-period-us", G_TYPE_INT64,
+          entry->min_device_period_us, nullptr);
+    }
 
     if (entry->flow == eCapture) {
       gst_structure_set (props,
           "wasapi2.device.loopback", G_TYPE_BOOLEAN, FALSE, nullptr);
 
+      if (!entry->is_default && entry->exclusive_caps) {
+        gst_structure_set (props, "device.exclusive-caps", GST_TYPE_CAPS,
+            entry->exclusive_caps, nullptr);
+      }
+
       auto device = (GstDevice *) g_object_new (GST_TYPE_WASAPI2_DEVICE,
-          "device", entry->device_id,
-          "display-name", entry->device_name, "caps", entry->caps,
+          "device", entry->device_id.c_str (),
+          "display-name", entry->device_name.c_str (), "caps", entry->caps,
           "device-class", "Audio/Source", "properties", props, nullptr);
       gst_structure_free (props);
 
-      GST_WASAPI2_DEVICE (device)->factory_name = "wasapi2src";
-      GST_WASAPI2_DEVICE (device)->device_class =
-          GST_WASAPI2_ENDPOINT_CLASS_CAPTURE;
+      auto wasapi2_dev = GST_WASAPI2_DEVICE (device);
+      wasapi2_dev->factory_name = "wasapi2src";
+      wasapi2_dev->device_class = GST_WASAPI2_ENDPOINT_CLASS_CAPTURE;
+      wasapi2_dev->is_default = entry->is_default;
 
       devices = g_list_append (devices, device);
     } else {
@@ -241,27 +293,34 @@ gst_wasapi2_device_provider_probe (GstDeviceProvider * provider)
       gst_structure_set (prop_copy,
           "wasapi2.device.loopback", G_TYPE_BOOLEAN, TRUE, nullptr);
 
+      if (!entry->is_default && entry->exclusive_caps) {
+        gst_structure_set (props, "device.exclusive-caps", GST_TYPE_CAPS,
+            entry->exclusive_caps, nullptr);
+      }
+
       auto device = (GstDevice *) g_object_new (GST_TYPE_WASAPI2_DEVICE,
-          "device", entry->device_id,
-          "display-name", entry->device_name, "caps", entry->caps,
+          "device", entry->device_id.c_str (),
+          "display-name", entry->device_name.c_str (), "caps", entry->caps,
           "device-class", "Audio/Sink", "properties", props, nullptr);
       gst_structure_free (props);
 
-      GST_WASAPI2_DEVICE (device)->factory_name = "wasapi2sink";
-      GST_WASAPI2_DEVICE (device)->device_class =
-          GST_WASAPI2_ENDPOINT_CLASS_RENDER;
+      auto wasapi2_dev = GST_WASAPI2_DEVICE (device);
+      wasapi2_dev->factory_name = "wasapi2sink";
+      wasapi2_dev->device_class = GST_WASAPI2_ENDPOINT_CLASS_RENDER;
+      wasapi2_dev->is_default = entry->is_default;
 
       devices = g_list_append (devices, device);
 
       device = (GstDevice *) g_object_new (GST_TYPE_WASAPI2_DEVICE,
-          "device", entry->device_id,
-          "display-name", entry->device_name, "caps", entry->caps,
+          "device", entry->device_id.c_str (),
+          "display-name", entry->device_name.c_str (), "caps", entry->caps,
           "device-class", "Audio/Source", "properties", prop_copy, nullptr);
       gst_structure_free (prop_copy);
 
-      GST_WASAPI2_DEVICE (device)->factory_name = "wasapi2src";
-      GST_WASAPI2_DEVICE (device)->device_class =
-          GST_WASAPI2_ENDPOINT_CLASS_LOOPBACK_CAPTURE;
+      wasapi2_dev = GST_WASAPI2_DEVICE (device);
+      wasapi2_dev->factory_name = "wasapi2src";
+      wasapi2_dev->device_class = GST_WASAPI2_ENDPOINT_CLASS_LOOPBACK_CAPTURE;
+      wasapi2_dev->is_default = entry->is_default;
 
       devices = g_list_append (devices, device);
     }
@@ -334,6 +393,63 @@ gst_wasapi2_device_is_in_list (GList * list, GstDevice * device)
   return found;
 }
 
+static gboolean
+dump_structure_field (const GstIdStr * fieldname, const GValue * value,
+    gpointer user_data)
+{
+  auto str = (GString *) user_data;
+  gchar *val;
+
+  if (G_VALUE_HOLDS_UINT (value)) {
+    val = g_strdup_printf ("%u (0x%08x)", g_value_get_uint (value),
+        g_value_get_uint (value));
+  } else if (G_VALUE_HOLDS_STRING (value)) {
+    val = g_value_dup_string (value);
+  } else {
+    val = gst_value_serialize (value);
+  }
+
+  if (val) {
+    g_string_append_printf (str,
+        "\t%s = %s\n", gst_id_str_as_str (fieldname), val);
+  }
+
+  g_free (val);
+
+  return TRUE;
+}
+
+static gchar *
+gst_wasapi2_dump_devices (GList * device_list)
+{
+#ifndef GST_DISABLE_GST_DEBUG
+  if (gst_debug_category_get_threshold (GST_CAT_DEFAULT) < GST_LEVEL_LOG ||
+      !device_list) {
+    return nullptr;
+  }
+
+  auto str = g_string_new (nullptr);
+  GList *iter;
+  for (iter = device_list; iter; iter = g_list_next (iter)) {
+    auto device = GST_DEVICE (iter->data);
+    auto name = gst_device_get_display_name (device);
+    auto device_class = gst_device_get_device_class (device);
+    auto prop = gst_device_get_properties (device);
+    g_string_append_printf (str, "%s (%s)\n", name, device_class);
+    gst_structure_foreach_id_str (prop, dump_structure_field, str);
+    g_string_append_c (str, '\n');
+
+    g_free (name);
+    g_free (device_class);
+    gst_structure_free (prop);
+  }
+
+  return g_string_free (str, FALSE);
+#else
+  return nullptr;
+#endif
+}
+
 static void
 gst_wasapi2_device_provider_update_devices (GstWasapi2DeviceProvider * self)
 {
@@ -342,7 +458,7 @@ gst_wasapi2_device_provider_update_devices (GstWasapi2DeviceProvider * self)
   GList *new_devices = nullptr;
   GList *to_add = nullptr;
   GList *to_remove = nullptr;
-  GList *iter;
+  GList *iter, *walk;
 
   GST_OBJECT_LOCK (self);
   prev_devices = g_list_copy_deep (provider->devices,
@@ -371,6 +487,70 @@ gst_wasapi2_device_provider_update_devices (GstWasapi2DeviceProvider * self)
     }
   }
 
+  iter = to_remove;
+  while (iter) {
+    auto prev_dev = GST_WASAPI2_DEVICE (iter->data);
+
+    if (!prev_dev->is_default) {
+      iter = g_list_next (iter);
+      continue;
+    }
+
+    walk = to_add;
+    bool found = false;
+    while (walk) {
+      auto new_dev = GST_WASAPI2_DEVICE (walk->data);
+
+      if (!new_dev->is_default ||
+          prev_dev->device_class != new_dev->device_class) {
+        walk = g_list_next (walk);
+        continue;
+      }
+
+      gst_device_provider_device_changed (provider, GST_DEVICE (new_dev),
+          GST_DEVICE (prev_dev));
+      gst_object_unref (new_dev);
+      to_add = g_list_delete_link (to_add, walk);
+      found = true;
+      break;
+    }
+
+    if (found) {
+      gst_object_unref (prev_dev);
+      auto next = iter->next;
+      to_remove = g_list_delete_link (to_remove, iter);
+      iter = next;
+    } else {
+      iter = g_list_next (iter);
+    }
+  }
+
+  if (to_add || to_remove) {
+    auto dump = gst_wasapi2_dump_devices (prev_devices);
+    if (dump) {
+      GST_LOG_OBJECT (self, "Previous devices:\n%s", dump);
+      g_free (dump);
+    }
+
+    dump = gst_wasapi2_dump_devices (new_devices);
+    if (dump) {
+      GST_LOG_OBJECT (self, "Probed devices:\n%s", dump);
+      g_free (dump);
+    }
+
+    dump = gst_wasapi2_dump_devices (to_add);
+    if (dump) {
+      GST_LOG_OBJECT (self, "New devices:\n%s", dump);
+      g_free (dump);
+    }
+
+    dump = gst_wasapi2_dump_devices (to_remove);
+    if (dump) {
+      GST_LOG_OBJECT (self, "Removed devices:\n%s", dump);
+      g_free (dump);
+    }
+  }
+
   for (iter = to_remove; iter; iter = g_list_next (iter))
     gst_device_provider_device_remove (provider, GST_DEVICE (iter->data));
 
diff --git a/sys/wasapi2/gstwasapi2enumerator.cpp b/sys/wasapi2/gstwasapi2enumerator.cpp
index 2e0d9da..aaf4eb2 100644
--- a/sys/wasapi2/gstwasapi2enumerator.cpp
+++ b/sys/wasapi2/gstwasapi2enumerator.cpp
@@ -28,17 +28,64 @@
 #include <wrl.h>
 #include <functiondiscoverykeys_devpkey.h>
 #include <string>
+#include <atomic>
 
 /* *INDENT-OFF* */
 using namespace Microsoft::WRL;
 
-GST_DEBUG_CATEGORY_EXTERN (gst_wasapi2_debug);
-#define GST_CAT_DEFAULT gst_wasapi2_debug
+#ifndef GST_DISABLE_GST_DEBUG
+#define GST_CAT_DEFAULT ensure_debug_category()
+static GstDebugCategory *
+ensure_debug_category (void)
+{
+  static GstDebugCategory *cat = nullptr;
+
+  GST_WASAPI2_CALL_ONCE_BEGIN {
+    cat = _gst_debug_category_new ("wasapi2enumerator", 0, "wasapi2enumerator");
+  } GST_WASAPI2_CALL_ONCE_END;
 
-static GstStaticCaps template_caps = GST_STATIC_CAPS (GST_WASAPI2_STATIC_CAPS);
+  return cat;
+}
+#endif
 
 static void gst_wasapi2_on_device_updated (GstWasapi2Enumerator * object);
 
+static std::string
+device_state_to_string (DWORD state)
+{
+  std::string ret;
+  bool is_first = true;
+  if ((state & DEVICE_STATE_ACTIVE) == DEVICE_STATE_ACTIVE) {
+    if (!is_first)
+      ret += "|";
+    ret += "ACTIVE";
+    is_first = false;
+  }
+
+  if ((state & DEVICE_STATE_DISABLED) == DEVICE_STATE_DISABLED) {
+    if (!is_first)
+      ret += "|";
+    ret += "DISABLED";
+    is_first = false;
+  }
+
+  if ((state & DEVICE_STATE_NOTPRESENT) == DEVICE_STATE_NOTPRESENT) {
+    if (!is_first)
+      ret += "|";
+    ret += "NOTPRESENT";
+    is_first = false;
+  }
+
+  if ((state & DEVICE_STATE_UNPLUGGED) == DEVICE_STATE_UNPLUGGED) {
+    if (!is_first)
+      ret += "|";
+    ret += "UNPLUGGED";
+    is_first = false;
+  }
+
+  return ret;
+}
+
 /* IMMNotificationClient implementation */
 class IWasapi2NotificationClient : public IMMNotificationClient
 {
@@ -77,7 +124,6 @@ public:
   STDMETHODIMP_ (ULONG)
   AddRef (void)
   {
-    GST_TRACE ("%p, %d", this, (guint) ref_count_);
     return InterlockedIncrement (&ref_count_);
   }
 
@@ -105,6 +151,12 @@ public:
     if (!object)
       return S_OK;
 
+    auto id = g_utf16_to_utf8 ((gunichar2 *) device_id,
+          -1, nullptr, nullptr, nullptr);
+    auto state = device_state_to_string (new_state);
+    GST_LOG ("%s, %s (0x%x)", id, state.c_str (), (guint) new_state);
+    g_free (id);
+
     gst_wasapi2_on_device_updated (object);
     gst_object_unref (object);
 
@@ -118,6 +170,11 @@ public:
     if (!object)
       return S_OK;
 
+    auto id = g_utf16_to_utf8 ((gunichar2 *) device_id,
+          -1, nullptr, nullptr, nullptr);
+    GST_LOG ("%s", id);
+    g_free (id);
+
     gst_wasapi2_on_device_updated (object);
     gst_object_unref (object);
 
@@ -131,6 +188,11 @@ public:
     if (!object)
       return S_OK;
 
+    auto id = g_utf16_to_utf8 ((gunichar2 *) device_id,
+          -1, nullptr, nullptr, nullptr);
+    GST_LOG ("%s", id);
+    g_free (id);
+
     gst_wasapi2_on_device_updated (object);
     gst_object_unref (object);
 
@@ -138,12 +200,19 @@ public:
   }
 
   STDMETHODIMP
-  OnDefaultDeviceChanged (EDataFlow flow, ERole role, LPCWSTR default_device_id)
+  OnDefaultDeviceChanged (EDataFlow flow, ERole role, LPCWSTR device_id)
   {
     auto object = (GstWasapi2Enumerator *) g_weak_ref_get (&obj_);
     if (!object)
       return S_OK;
 
+    auto id = g_utf16_to_utf8 ((gunichar2 *) device_id,
+          -1, nullptr, nullptr, nullptr);
+    GST_LOG ("%s, flow: %s, role: %s", id,
+        gst_wasapi2_data_flow_to_string (flow),
+        gst_wasapi2_role_to_string (role));
+    g_free (id);
+
     gst_wasapi2_on_device_updated (object);
     gst_object_unref (object);
 
@@ -188,6 +257,20 @@ static guint wasapi2_device_signals[SIGNAL_LAST] = { };
 
 struct GstWasapi2EnumeratorPrivate
 {
+  GstWasapi2EnumeratorPrivate ()
+  {
+    device_list = g_ptr_array_new_with_free_func ((GDestroyNotify)
+        gst_wasapi2_enumerator_entry_free);
+    endpoint_formats = g_ptr_array_new_with_free_func ((GDestroyNotify)
+        gst_wasapi2_free_wfx);
+  }
+
+  ~GstWasapi2EnumeratorPrivate ()
+  {
+    g_ptr_array_unref (device_list);
+    g_ptr_array_unref (endpoint_formats);
+  }
+
   ComPtr<IMMDeviceEnumerator> handle;
   std::mutex lock;
   std::condition_variable cond;
@@ -195,6 +278,9 @@ struct GstWasapi2EnumeratorPrivate
   ComPtr<IMMNotificationClient> client;
   Wasapi2ActivationHandler *capture_activator = nullptr;
   Wasapi2ActivationHandler *render_activator = nullptr;
+  std::atomic<int> notify_count = { 0 };
+  GPtrArray *device_list;
+  GPtrArray *endpoint_formats;
 
   void ClearCOM ()
   {
@@ -272,12 +358,26 @@ static void
 gst_wasapi2_on_device_updated (GstWasapi2Enumerator * object)
 {
   /* *INDENT-OFF* */
-  g_main_context_invoke_full (object->context, G_PRIORITY_DEFAULT,
+  auto priv = object->priv;
+
+  auto count = priv->notify_count.fetch_add (1);
+  GST_LOG ("notify count before scheduling %d", count);
+
+  auto source = g_timeout_source_new (100);
+  g_source_set_callback (source,
       [] (gpointer obj) -> gboolean {
-        g_signal_emit (obj, wasapi2_device_signals[SIGNAL_UPDATED], 0);
+        auto self = GST_WASAPI2_ENUMERATOR (obj);
+        auto priv = self->priv;
+        auto count = priv->notify_count.fetch_sub (1);
+        GST_LOG ("scheduled notify count %d", count);
+        if (count == 1)
+          g_signal_emit (obj, wasapi2_device_signals[SIGNAL_UPDATED], 0);
         return G_SOURCE_REMOVE;
       },
       gst_object_ref (object), (GDestroyNotify) gst_object_unref);
+
+  g_source_attach (source, object->context);
+  g_source_unref (source);
   /* *INDENT-ON* */
 }
 
@@ -433,10 +533,7 @@ gst_wasapi2_enumerator_activate_notification (GstWasapi2Enumerator * object,
 void
 gst_wasapi2_enumerator_entry_free (GstWasapi2EnumeratorEntry * entry)
 {
-  g_free (entry->device_id);
-  g_free (entry->device_name);
-  gst_clear_caps (&entry->caps);
-  g_free (entry);
+  delete entry;
 }
 
 /* *INDENT-OFF* */
@@ -458,68 +555,120 @@ struct EnumerateData
 };
 /* *INDENT-ON* */
 
+static GstWasapi2EnumeratorEntry *
+gst_wasapi2_enumerator_build_entry (GstWasapi2Enumerator * self,
+    GstCaps * caps, EDataFlow flow, gboolean is_default,
+    gchar * device_id, gchar * device_name,
+    gchar * actual_device_id, gchar * actual_device_name,
+    GstWasapi2DeviceProps * device_props)
+{
+  auto entry = new GstWasapi2EnumeratorEntry ();
+
+  entry->device_id = device_id;
+  entry->device_name = device_name;
+  entry->caps = caps;
+  entry->flow = flow;
+  entry->is_default = is_default;
+  if (actual_device_id)
+    entry->actual_device_id = actual_device_id;
+  if (actual_device_name)
+    entry->actual_device_name = actual_device_name;
+
+  if (device_props) {
+    entry->device_props.form_factor = device_props->form_factor;
+    entry->device_props.enumerator_name = device_props->enumerator_name;
+  }
+
+  GST_LOG_OBJECT (self, "Adding entry %s (%s), flow %d, caps %" GST_PTR_FORMAT,
+      device_id, device_name, flow, caps);
+  g_free (device_id);
+  g_free (device_name);
+  g_free (actual_device_id);
+  g_free (actual_device_name);
+
+  return entry;
+}
+
 static void
-gst_wasapi2_enumerator_add_entry (GstWasapi2Enumerator * self,
-    IAudioClient * client,
-    GstCaps * static_caps, EDataFlow flow, gboolean is_default,
-    gchar * device_id, gchar * device_name, GPtrArray * device_list)
+gst_wasapi2_enumerator_probe_props (IPropertyStore * store,
+    GstWasapi2DeviceProps * props)
 {
-  WAVEFORMATEX *mix_format = nullptr;
-  GstCaps *supported_caps = nullptr;
+  PROPVARIANT var;
+  PropVariantInit (&var);
 
-  client->GetMixFormat (&mix_format);
-  if (!mix_format) {
-    g_free (device_id);
-    g_free (device_name);
-    return;
+  auto hr = store->GetValue (PKEY_AudioEndpoint_FormFactor, &var);
+  if (SUCCEEDED (hr) && var.vt == VT_UI4)
+    props->form_factor = (EndpointFormFactor) var.ulVal;
+
+  PropVariantClear (&var);
+
+  hr = store->GetValue (PKEY_Device_EnumeratorName, &var);
+  if (SUCCEEDED (hr) && var.vt == VT_LPWSTR) {
+    auto name = g_utf16_to_utf8 ((gunichar2 *) var.pwszVal,
+        -1, nullptr, nullptr, nullptr);
+    props->enumerator_name = name;
+    g_free (name);
   }
 
-  gst_wasapi2_util_parse_waveformatex (mix_format,
-      static_caps, &supported_caps, nullptr);
-  CoTaskMemFree (mix_format);
+  PropVariantClear (&var);
+}
+
+static void
+get_default_device (GstWasapi2Enumerator * self, EDataFlow flow,
+    IMMDevice ** device, IPropertyStore ** prop, gchar ** actual_device_id,
+    gchar ** actual_device_name)
+{
+  auto priv = self->priv;
+  ComPtr < IMMDevice > rst_device;
+  ComPtr < IPropertyStore > rst_prop;
+
+  *actual_device_id = nullptr;
+  *actual_device_name = nullptr;
 
-  if (!supported_caps) {
-    g_free (device_id);
-    g_free (device_name);
+  auto hr = priv->handle->GetDefaultAudioEndpoint (flow,
+      eConsole, &rst_device);
+  if (FAILED (hr))
     return;
-  }
 
-  auto entry = g_new0 (GstWasapi2EnumeratorEntry, 1);
+  hr = rst_device->OpenPropertyStore (STGM_READ, &rst_prop);
+  if (FAILED (hr))
+    return;
 
-  entry->device_id = device_id;
-  entry->device_name = device_name;
-  entry->caps = supported_caps;
-  entry->flow = flow;
-  entry->is_default = is_default;
+  LPWSTR wid = nullptr;
+  hr = rst_device->GetId (&wid);
+  if (!gst_wasapi2_result (hr))
+    return;
 
-  GST_LOG_OBJECT (self, "Adding entry %s (%s), flow %d, caps %" GST_PTR_FORMAT,
-      device_id, device_name, flow, supported_caps);
+  *actual_device_id = g_utf16_to_utf8 ((gunichar2 *) wid,
+      -1, nullptr, nullptr, nullptr);
+  CoTaskMemFree (wid);
 
-  g_ptr_array_add (device_list, entry);
+  PROPVARIANT var;
+  PropVariantInit (&var);
+  hr = rst_prop->GetValue (PKEY_Device_FriendlyName, &var);
+  if (gst_wasapi2_result (hr)) {
+    *actual_device_name = g_utf16_to_utf8 ((gunichar2 *) var.pwszVal,
+        -1, nullptr, nullptr, nullptr);
+    PropVariantClear (&var);
+  }
+
+  *device = rst_device.Detach ();
+  *prop = rst_prop.Detach ();
+  return;
 }
 
 static gboolean
-gst_wasapi2_enumerator_enumerate_internal (EnumerateData * data)
+gst_wasapi2_enumerator_execute (GstWasapi2Enumerator * self,
+    IMMDeviceCollection * collection, gboolean ignore_error)
 {
-  auto self = data->self;
   auto priv = self->priv;
-  ComPtr < IMMDeviceCollection > collection;
 
-  auto hr = priv->handle->EnumAudioEndpoints (eAll, DEVICE_STATE_ACTIVE,
-      &collection);
-  if (!gst_wasapi2_result (hr)) {
-    SetEvent (data->event);
-    return G_SOURCE_REMOVE;
-  }
+  GST_DEBUG_OBJECT (self, "Start enumerate");
 
   UINT count = 0;
-  hr = collection->GetCount (&count);
-  if (!gst_wasapi2_result (hr) || count == 0) {
-    SetEvent (data->event);
-    return G_SOURCE_REMOVE;
-  }
-
-  auto scaps = gst_static_caps_get (&template_caps);
+  auto hr = collection->GetCount (&count);
+  if (!gst_wasapi2_result (hr) || count == 0)
+    return TRUE;
 
   ComPtr < IAudioClient > default_capture_client;
   ComPtr < IAudioClient > default_render_client;
@@ -528,18 +677,86 @@ gst_wasapi2_enumerator_enumerate_internal (EnumerateData * data)
   if (priv->render_activator)
     priv->render_activator->GetClient (&default_render_client, 10000);
 
+  ComPtr < IMMDevice > default_capture_device;
+  ComPtr < IPropertyStore > default_capture_prop;
+  gchar *default_capture_device_id = nullptr;
+  gchar *default_capture_device_name = nullptr;
+
+  ComPtr < IMMDevice > default_render_device;
+  ComPtr < IPropertyStore > default_render_prop;
+  gchar *default_render_device_id = nullptr;
+  gchar *default_render_device_name = nullptr;
+
+  get_default_device (self, eCapture, &default_capture_device,
+      &default_capture_prop,
+      &default_capture_device_id, &default_capture_device_name);
+  get_default_device (self, eRender, &default_render_device,
+      &default_render_prop,
+      &default_render_device_id, &default_render_device_name);
+
+  if (priv->capture_activator && !default_capture_client &&
+      default_capture_device) {
+    default_capture_device->Activate (__uuidof (IAudioClient), CLSCTX_ALL,
+        nullptr, &default_capture_client);
+  }
+
+  if (priv->render_activator && !default_render_client && default_render_device) {
+    default_render_device->Activate (__uuidof (IAudioClient), CLSCTX_ALL,
+        nullptr, &default_render_client);
+  }
+
   if (default_capture_client) {
-    gst_wasapi2_enumerator_add_entry (self, default_capture_client.Get (),
-        scaps, eCapture, TRUE,
-        g_strdup (gst_wasapi2_get_default_device_id (eCapture)),
-        g_strdup ("Default Audio Capture Device"), data->device_list);
+    GstWasapi2DeviceProps props;
+    props.form_factor = UnknownFormFactor;
+    props.enumerator_name = "UNKNOWN";
+
+    if (default_capture_prop)
+      gst_wasapi2_enumerator_probe_props (default_capture_prop.Get (), &props);
+
+    g_ptr_array_set_size (priv->endpoint_formats, 0);
+    gst_wasapi2_get_shared_mode_formats (default_capture_client.Get (),
+        priv->endpoint_formats);
+    auto caps = gst_wasapi2_wfx_list_to_caps (priv->endpoint_formats);
+    g_ptr_array_set_size (priv->endpoint_formats, 0);
+
+    if (caps) {
+      auto entry = gst_wasapi2_enumerator_build_entry (self,
+          caps, eCapture, TRUE,
+          g_strdup (gst_wasapi2_get_default_device_id (eCapture)),
+          g_strdup ("Default Audio Capture Device"),
+          g_strdup (default_capture_device_id),
+          g_strdup (default_capture_device_name), &props);
+
+      if (entry)
+        g_ptr_array_add (priv->device_list, entry);
+    }
   }
 
   if (default_render_client) {
-    gst_wasapi2_enumerator_add_entry (self, default_render_client.Get (),
-        scaps, eRender, TRUE,
-        g_strdup (gst_wasapi2_get_default_device_id (eRender)),
-        g_strdup ("Default Audio Render Device"), data->device_list);
+    GstWasapi2DeviceProps props;
+    props.form_factor = UnknownFormFactor;
+    props.enumerator_name = "UNKNOWN";
+
+    if (default_render_prop)
+      gst_wasapi2_enumerator_probe_props (default_render_prop.Get (), &props);
+
+    g_ptr_array_set_size (priv->endpoint_formats, 0);
+    gst_wasapi2_get_shared_mode_formats (default_render_client.Get (),
+        priv->endpoint_formats);
+    auto caps = gst_wasapi2_wfx_list_to_caps (priv->endpoint_formats);
+    g_ptr_array_set_size (priv->endpoint_formats, 0);
+
+    if (caps) {
+      auto entry = gst_wasapi2_enumerator_build_entry (self,
+          caps, eRender, TRUE,
+          g_strdup (gst_wasapi2_get_default_device_id (eRender)),
+          g_strdup ("Default Audio Render Device"),
+          g_strdup (default_render_device_id),
+          g_strdup (default_render_device_name), &props);
+
+      if (entry)
+        g_ptr_array_add (priv->device_list, entry);
+    }
   }
 
   for (UINT i = 0; i < count; i++) {
@@ -547,6 +764,10 @@ gst_wasapi2_enumerator_enumerate_internal (EnumerateData * data)
     ComPtr < IMMEndpoint > endpoint;
     EDataFlow flow;
 
+    GstWasapi2DeviceProps props;
+    props.form_factor = UnknownFormFactor;
+    props.enumerator_name = "UNKNOWN";
+
     hr = collection->Item (i, &device);
     if (!gst_wasapi2_result (hr))
       continue;
@@ -588,17 +809,129 @@ gst_wasapi2_enumerator_enumerate_internal (EnumerateData * data)
     ComPtr < IAudioClient > client;
     hr = device->Activate (__uuidof (IAudioClient), CLSCTX_ALL, nullptr,
         &client);
+
     if (!gst_wasapi2_result (hr)) {
+      /* Requested active devices via DEVICE_STATE_ACTIVE but activate fail here.
+       * That means devices were changed while we were enumerating.
+       * Need retry here */
+      GST_DEBUG_OBJECT (self, "Couldn't activate device %s (%s)",
+          device_id, desc);
       g_free (device_id);
       g_free (desc);
-      continue;
+
+      if (!ignore_error && hr == AUDCLNT_E_DEVICE_INVALIDATED)
+        return FALSE;
     }
 
-    gst_wasapi2_enumerator_add_entry (self, client.Get (), scaps, flow, FALSE,
-        device_id, desc, data->device_list);
+    gst_wasapi2_enumerator_probe_props (prop.Get (), &props);
+
+    g_ptr_array_set_size (priv->endpoint_formats, 0);
+    gst_wasapi2_get_shared_mode_formats (client.Get (), priv->endpoint_formats);
+    auto caps = gst_wasapi2_wfx_list_to_caps (priv->endpoint_formats);
+    g_ptr_array_set_size (priv->endpoint_formats, 0);
+
+    if (caps) {
+      auto entry = gst_wasapi2_enumerator_build_entry (self, caps, flow,
+          FALSE, device_id, desc, nullptr, nullptr, &props);
+      if (entry) {
+        g_ptr_array_set_size (priv->endpoint_formats, 0);
+        gst_wasapi2_get_exclusive_mode_formats (client.Get (),
+            prop.Get (), priv->endpoint_formats);
+        auto exclusive_caps =
+            gst_wasapi2_wfx_list_to_caps (priv->endpoint_formats);
+        g_ptr_array_set_size (priv->endpoint_formats, 0);
+        entry->exclusive_caps = exclusive_caps;
+
+        REFERENCE_TIME default_period = 0;
+        REFERENCE_TIME min_period = 0;
+        WAVEFORMATEX *mix_format = nullptr;
+
+        hr = client->GetDevicePeriod (&default_period, &min_period);
+        if (SUCCEEDED (hr)) {
+          entry->default_device_period_us = default_period / 10;
+          entry->min_device_period_us = min_period / 10;
+        }
+
+        client->GetMixFormat (&mix_format);
+        if (mix_format) {
+          ComPtr < IAudioClient3 > client3;
+          hr = client.As (&client3);
+          if (SUCCEEDED (hr)) {
+            UINT32 default_period_frame = 0;
+            UINT32 fundamental_period_frame = 0;
+            UINT32 min_period_frame = 0;
+            UINT32 max_period_frame = 0;
+
+            hr = client3->GetSharedModeEnginePeriod (mix_format,
+                &default_period_frame, &fundamental_period_frame,
+                &min_period_frame, &max_period_frame);
+            if (SUCCEEDED (hr)) {
+              entry->shared_mode_engine_default_period_us =
+                  (default_period_frame * 1000000ULL) /
+                  mix_format->nSamplesPerSec;
+              entry->shared_mode_engine_fundamental_period_us =
+                  (fundamental_period_frame * 1000000ULL) /
+                  mix_format->nSamplesPerSec;
+              entry->shared_mode_engine_min_period_us =
+                  (min_period_frame * 1000000ULL) / mix_format->nSamplesPerSec;
+              entry->shared_mode_engine_max_period_us =
+                  (max_period_frame * 1000000ULL) / mix_format->nSamplesPerSec;
+            }
+          }
+
+          CoTaskMemFree (mix_format);
+        }
+
+        g_ptr_array_add (priv->device_list, entry);
+      }
+    }
+  }
+
+  g_free (default_capture_device_id);
+  g_free (default_capture_device_name);
+  g_free (default_render_device_id);
+  g_free (default_render_device_name);
+
+  return TRUE;
+}
+
+static gboolean
+gst_wasapi2_enumerator_enumerate_internal (EnumerateData * data)
+{
+  auto self = data->self;
+  auto priv = self->priv;
+  /* Upto 3 times retry */
+  const guint num_retry = 5;
+
+  for (guint i = 0; i < num_retry; i++) {
+    ComPtr < IMMDeviceCollection > collection;
+    gboolean is_last = FALSE;
+
+    if (i + 1 == num_retry)
+      is_last = TRUE;
+
+    g_ptr_array_set_size (priv->device_list, 0);
+
+    auto hr = priv->handle->EnumAudioEndpoints (eAll, DEVICE_STATE_ACTIVE,
+        &collection);
+    if (!gst_wasapi2_result (hr)) {
+      SetEvent (data->event);
+      return G_SOURCE_REMOVE;
+    }
+
+    if (gst_wasapi2_enumerator_execute (self, collection.Get (), is_last))
+      break;
+
+    if (!is_last) {
+      GST_DEBUG_OBJECT (self, "Sleep for retrying");
+      Sleep (50);
+    }
   }
 
-  gst_caps_unref (scaps);
+  while (priv->device_list->len > 0) {
+    g_ptr_array_add (data->device_list,
+        g_ptr_array_steal_index (priv->device_list, 0));
+  }
 
   SetEvent (data->event);
   return G_SOURCE_REMOVE;
@@ -618,3 +951,31 @@ gst_wasapi2_enumerator_enumerate_devices (GstWasapi2Enumerator * object,
 
   WaitForSingleObject (data.event, INFINITE);
 }
+
+const gchar *
+gst_wasapi2_form_factor_to_string (EndpointFormFactor form_factor)
+{
+  switch (form_factor) {
+    case RemoteNetworkDevice:
+      return "RemoteNetworkDevice";
+    case Speakers:
+      return "Speakers";
+    case LineLevel:
+      return "LineLevel";
+    case Microphone:
+      return "Microphone";
+    case Headset:
+      return "Headset";
+    case Handset:
+      return "Handset";
+    case UnknownDigitalPassthrough:
+      return "UnknownDigitalPassthrough";
+    case SPDIF:
+      return "SPDIF";
+    case DigitalAudioDisplayDevice:
+      return "DigitalAudioDisplayDevice";
+    case UnknownFormFactor:
+    default:
+      return "UnknownFormFactor";
+  }
+}
diff --git a/sys/wasapi2/gstwasapi2enumerator.h b/sys/wasapi2/gstwasapi2enumerator.h
index cd9ccba..f8a594c 100644
--- a/sys/wasapi2/gstwasapi2enumerator.h
+++ b/sys/wasapi2/gstwasapi2enumerator.h
@@ -21,6 +21,7 @@
 
 #include <gst/gst.h>
 #include "gstwasapi2util.h"
+#include <string>
 
 G_BEGIN_DECLS
 
@@ -28,14 +29,40 @@ G_BEGIN_DECLS
 G_DECLARE_FINAL_TYPE (GstWasapi2Enumerator, gst_wasapi2_enumerator,
     GST, WASAPI2_ENUMERATOR, GstObject);
 
-typedef struct _GstWasapi2EnumeratorEntry
+G_END_DECLS
+
+struct GstWasapi2DeviceProps
+{
+  EndpointFormFactor form_factor;
+  std::string enumerator_name;
+};
+
+struct GstWasapi2EnumeratorEntry
 {
-  gchar *device_id;
-  gchar *device_name;
-  gboolean is_default;
-  GstCaps *caps;
+  ~GstWasapi2EnumeratorEntry()
+  {
+    gst_clear_caps (&caps);
+    gst_clear_caps (&exclusive_caps);
+  }
+
+  std::string device_id;
+  std::string device_name;
+  std::string actual_device_id;
+  std::string actual_device_name;
+  gboolean is_default = FALSE;
+  GstCaps *caps = nullptr;
+  GstCaps *exclusive_caps = nullptr;
   EDataFlow flow;
-} GstWasapi2EnumeratorEntry;
+  GstWasapi2DeviceProps device_props = { };
+
+  gint64 shared_mode_engine_default_period_us = 0;
+  gint64 shared_mode_engine_fundamental_period_us = 0;
+  gint64 shared_mode_engine_min_period_us = 0;
+  gint64 shared_mode_engine_max_period_us = 0;
+
+  gint64 default_device_period_us = 0;
+  gint64 min_device_period_us = 0;
+};
 
 GstWasapi2Enumerator * gst_wasapi2_enumerator_new (void);
 
@@ -47,5 +74,5 @@ void gst_wasapi2_enumerator_entry_free (GstWasapi2EnumeratorEntry * entry);
 void gst_wasapi2_enumerator_enumerate_devices (GstWasapi2Enumerator * object,
                                                GPtrArray * entry);
 
-G_END_DECLS
+const gchar * gst_wasapi2_form_factor_to_string (EndpointFormFactor form_factor);
 
diff --git a/sys/wasapi2/gstwasapi2rbuf.cpp b/sys/wasapi2/gstwasapi2rbuf.cpp
new file mode 100644
index 0000000..7babb9a
--- /dev/null
+++ b/sys/wasapi2/gstwasapi2rbuf.cpp
@@ -0,0 +1,3231 @@
+/* GStreamer
+ * Copyright (C) 2025 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+/*
+ * This module implements a GstAudioRingBuffer subclass using
+ * Windows Audio Session API (WASAPI).
+ *
+ * Major Components:
+ *
+ * - RbufCtx: Encapsulates WASAPI objects such as IAudioClient,
+ *   IAudioRenderClient/IAudioCaptureClient, volume/mute interfaces, and events.
+ *
+ * - Wasapi2DeviceManager: Handles IMMDevice activation and RbufCtx creation
+ *   in a dedicated COM thread. This avoids blocking the main I/O thread.
+ *
+ * - CommandData and command queue: All user-triggered operations (open, start,
+ *   stop, volume changes, etc.) are serialized through a command queue.
+ *
+ * - gst_wasapi2_rbuf_loop_thread: The main loop that processes WASAPI I/O events
+ *   and executes queued commands.
+ *
+ * Design Highlights:
+ *
+ * 1) The Wasapi2DeviceManager and GstWasapi2Rbuf classes are decoupled to manage
+ *    device initialization efficiently. Creating and initializing an IAudioClient
+ *    can take significant time due to format negotiation or endpoint activation.
+ *
+ * - During a normal open/start sequence, the main I/O thread (gst_wasapi2_rbuf_loop_thread)
+ *   synchronously waits for Wasapi2DeviceManager to finish device activation and
+ *   RbufCtx creation before proceeding.
+ *
+ * - In contrast, when a device is already open and a dynamic device change
+ *   is requested, device creation is delegated to Wasapi2DeviceManager
+ *   asynchronously in the background. Once initialization succeeds,
+ *   newly created RbufCtx is returned back to the I/O thread via the
+ *   command queue and swapped in without interrupting ongoing I/O.
+ *
+ *   This separation allows for seamless device transitions without blocking audio streaming.
+ *
+ * 2) All user-triggered events (such as open, close, start, stop, volume/mute changes)
+ *    are serialized through a command queue and processed exclusively by the main I/O thread.
+ *    This ensures thread-safe and ordered execution of state changes, avoiding race conditions.
+ */
+
+#include "gstwasapi2rbuf.h"
+#include "gstwasapi2activator.h"
+#include <endpointvolume.h>
+#include <memory>
+#include <atomic>
+#include <vector>
+#include <mutex>
+#include <condition_variable>
+#include <wrl.h>
+#include <string>
+#include <string.h>
+#include <queue>
+#include <avrt.h>
+
+#if defined(__SSE2__) || (defined(_MSC_VER) && (defined(_M_X64) || (_M_IX86_FP >= 2)))
+#include <emmintrin.h>
+#define GST_WASAPI2_HAVE_SSE2
+#endif
+
+GST_DEBUG_CATEGORY_STATIC (gst_wasapi2_rbuf_debug);
+#define GST_CAT_DEFAULT gst_wasapi2_rbuf_debug
+
+/* Defined for _WIN32_WINNT >= _NT_TARGET_VERSION_WIN10_RS4 */
+#ifndef CREATE_WAITABLE_TIMER_HIGH_RESOLUTION
+#define CREATE_WAITABLE_TIMER_HIGH_RESOLUTION 0x00000002
+#endif
+
+/* *INDENT-OFF* */
+using namespace Microsoft::WRL;
+
+static gpointer device_manager_com_thread (gpointer manager);
+
+struct RbufCtx
+{
+  RbufCtx () = delete;
+  RbufCtx (const std::string & id) : device_id (id)
+  {
+    capture_event = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+    render_event = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+    formats = g_ptr_array_new_with_free_func ((GDestroyNotify)
+        gst_wasapi2_free_wfx);
+  }
+
+  ~RbufCtx ()
+  {
+    Stop ();
+
+    if (volume_callback && endpoint_volume)
+      endpoint_volume->UnregisterControlChangeNotify (volume_callback.Get ());
+
+    if (mix_format)
+      CoTaskMemFree (mix_format);
+    gst_clear_caps (&caps);
+    gst_clear_caps (&supported_caps);
+
+    if (conv)
+      gst_audio_converter_free (conv);
+
+    CloseHandle (capture_event);
+    CloseHandle (render_event);
+
+    g_ptr_array_unref (formats);
+  }
+
+  HRESULT Start ()
+  {
+    if (running)
+      return S_OK;
+
+    auto hr = client->Start ();
+    if (!gst_wasapi2_result (hr))
+      return hr;
+
+    if (dummy_client) {
+      hr = dummy_client->Start ();
+      if (!gst_wasapi2_result (hr)) {
+        client->Stop ();
+        client->Reset ();
+
+        return hr;
+      }
+    }
+
+    running = true;
+
+    return S_OK;
+  }
+
+  HRESULT Stop ()
+  {
+    HRESULT hr = S_OK;
+    if (client) {
+      hr = client->Stop ();
+      if (gst_wasapi2_result (hr))
+        client->Reset ();
+    }
+
+    if (dummy_client) {
+      auto dummy_hr = dummy_client->Stop ();
+      if (gst_wasapi2_result (dummy_hr))
+        dummy_client->Reset ();
+    }
+
+    running = false;
+
+    return hr;
+  }
+
+  HRESULT SetVolume (float vol)
+  {
+    if (!stream_volume)
+      return S_OK;
+
+    UINT32 count = 0;
+    auto hr = stream_volume->GetChannelCount (&count);
+    if (!gst_wasapi2_result (hr) || count == 0)
+      return hr;
+
+    volumes.resize (count);
+
+    for (size_t i = 0; i < volumes.size (); i++)
+      volumes[i] = vol;
+
+    return stream_volume->SetAllVolumes ((UINT32) volumes.size (),
+        volumes.data ());
+  }
+
+  BOOL IsEndpointMuted ()
+  {
+    return endpoint_muted.load (std::memory_order_acquire);
+  }
+
+  GstWasapi2EndpointClass endpoint_class;
+  ComPtr<IMMDevice> device;
+  ComPtr<IAudioClient> client;
+  ComPtr<IAudioClient> dummy_client;
+  ComPtr<IAudioCaptureClient> capture_client;
+  ComPtr<IAudioRenderClient> render_client;
+  ComPtr<IAudioStreamVolume> stream_volume;
+  ComPtr<IAudioEndpointVolume> endpoint_volume;
+  ComPtr<IAudioEndpointVolumeCallback> volume_callback;
+  std::string device_id;
+  std::vector<float> volumes;
+  std::atomic<bool> endpoint_muted = { false };
+  HANDLE capture_event;
+  HANDLE render_event;
+  GstCaps *caps = nullptr;
+  GstCaps *supported_caps = nullptr;
+  WAVEFORMATEX *mix_format = nullptr;
+  std::vector<guint8> exclusive_staging;
+  size_t exclusive_staging_filled = 0;
+  size_t exclusive_period_bytes = 0;
+  GstAudioInfo device_info;
+  GstAudioInfo host_info;
+  std::vector<guint8> device_fifo;
+  std::vector<guint8> host_fifo;
+  size_t device_fifo_bytes = 0;
+  size_t host_fifo_bytes = 0;
+  GstAudioConverter *conv = nullptr;
+  GPtrArray *formats = nullptr;
+
+  UINT32 period = 0;
+  UINT32 client_buf_size = 0;
+  UINT32 dummy_buf_size = 0;
+  bool is_default = false;
+  bool running = false;
+  bool error_posted = false;
+  bool is_exclusive = false;
+  bool is_s24in32 = false;
+  bool init_done = false;
+  bool low_latency = false;
+  gint64 latency_time = 0;
+  gint64 buffer_time = 0;
+};
+
+typedef std::shared_ptr<RbufCtx> RbufCtxPtr;
+
+enum class CommandType
+{
+  Shutdown,
+  SetDevice,
+  UpdateDevice,
+  Open,
+  Close,
+  Acquire,
+  Release,
+  Start,
+  Stop,
+  GetCaps,
+  UpdateVolume,
+};
+
+static inline const gchar *
+command_type_to_string (CommandType type)
+{
+  switch (type) {
+    case CommandType::Shutdown:
+      return "Shutdown";
+    case CommandType::SetDevice:
+      return "SetDevice";
+    case CommandType::UpdateDevice:
+      return "UpdateDevice";
+    case CommandType::Open:
+      return "Open";
+    case CommandType::Close:
+      return "Close";
+    case CommandType::Acquire:
+      return "Acquire";
+    case CommandType::Release:
+      return "Release";
+    case CommandType::Start:
+      return "Start";
+    case CommandType::Stop:
+      return "Stop";
+    case CommandType::GetCaps:
+      return "GetCaps";
+    case CommandType::UpdateVolume:
+      return "UpdateVolume";
+    default:
+      return "Unknown";
+  }
+}
+
+struct CommandData
+{
+  CommandData (const CommandData &) = delete;
+  CommandData& operator= (const CommandData &) = delete;
+  CommandData () = delete;
+  CommandData (CommandType ctype) : type (ctype)
+  {
+    event_handle = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+  }
+
+  virtual ~CommandData ()
+  {
+    CloseHandle (event_handle);
+  }
+
+  CommandType type;
+
+  HRESULT hr = S_OK;
+  HANDLE event_handle;
+};
+
+struct CommandSetDevice : public CommandData
+{
+  CommandSetDevice () : CommandData (CommandType::SetDevice) {}
+
+  std::string device_id;
+  GstWasapi2EndpointClass endpoint_class;
+  guint pid = 0;
+  gboolean low_latency = FALSE;
+  gboolean exclusive = FALSE;
+};
+
+struct CommandUpdateDevice : public CommandData
+{
+  CommandUpdateDevice (const std::string & id)
+    : CommandData (CommandType::UpdateDevice), device_id (id) {}
+  std::shared_ptr<RbufCtx> ctx;
+  std::string device_id;
+};
+
+struct CommandGetCaps : public CommandData
+{
+  CommandGetCaps () : CommandData (CommandType::GetCaps) { }
+
+  GstCaps *caps = nullptr;
+};
+
+struct CommandAcquire : public CommandData
+{
+  CommandAcquire (GstAudioRingBufferSpec * s) :
+      CommandData (CommandType::Acquire), spec (s) {}
+
+  GstAudioRingBufferSpec *spec = nullptr;
+};
+
+static void gst_wasapi2_rbuf_push_command (GstWasapi2Rbuf * self,
+    std::shared_ptr<CommandData> cmd);
+
+
+DEFINE_GUID (IID_Wasapi2EndpointVolumeCallback, 0x21ba991f, 0x4d78,
+    0x418c, 0xa1, 0xea, 0x8a, 0xc7, 0xdd, 0xa2, 0xdc, 0x39);
+class Wasapi2EndpointVolumeCallback : public IAudioEndpointVolumeCallback
+{
+public:
+  static void CreateInstance (IAudioEndpointVolumeCallback ** iface,
+      RbufCtxPtr & ctx)
+  {
+    auto self = new Wasapi2EndpointVolumeCallback ();
+    self->ctx_ = ctx;
+    *iface = static_cast<IAudioEndpointVolumeCallback *>(
+        static_cast<Wasapi2EndpointVolumeCallback*>(self));
+  }
+
+  STDMETHODIMP_ (ULONG)
+  AddRef (void)
+  {
+    return InterlockedIncrement (&refcount_);
+  }
+
+  STDMETHODIMP_ (ULONG)
+  Release (void)
+  {
+    ULONG ref_count;
+
+    ref_count = InterlockedDecrement (&refcount_);
+
+    if (ref_count == 0)
+      delete this;
+
+    return ref_count;
+  }
+
+  STDMETHODIMP
+  QueryInterface (REFIID riid, void ** object)
+  {
+    if (riid == __uuidof(IUnknown) || riid == __uuidof(IAgileObject)) {
+      *object = static_cast<IUnknown *>(
+          static_cast<Wasapi2EndpointVolumeCallback*>(this));
+    } else if (riid == __uuidof(IAudioEndpointVolumeCallback)) {
+      *object = static_cast<IAudioEndpointVolumeCallback *>(
+          static_cast<Wasapi2EndpointVolumeCallback*>(this));
+    } else if (riid == IID_Wasapi2EndpointVolumeCallback) {
+      *object = static_cast<Wasapi2EndpointVolumeCallback *> (this);
+    } else {
+      *object = nullptr;
+      return E_NOINTERFACE;
+    }
+
+    AddRef ();
+
+    return S_OK;
+  }
+
+  STDMETHODIMP
+  OnNotify (AUDIO_VOLUME_NOTIFICATION_DATA * notify)
+  {
+    auto ctx = ctx_.lock ();
+    if (!ctx)
+      return S_OK;
+
+    ctx->endpoint_muted.store (notify->bMuted, std::memory_order_release);
+
+    return S_OK;
+  }
+
+private:
+  Wasapi2EndpointVolumeCallback () {}
+  virtual ~Wasapi2EndpointVolumeCallback () {}
+
+private:
+  ULONG refcount_ = 1;
+  std::weak_ptr<RbufCtx> ctx_;
+};
+
+struct RbufCtxDesc
+{
+  RbufCtxDesc ()
+  {
+    event_handle = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+  }
+
+  ~RbufCtxDesc ()
+  {
+    CloseHandle (event_handle);
+  }
+
+  GstWasapi2Rbuf *rbuf = nullptr;
+  GstWasapi2EndpointClass endpoint_class;
+  std::string device_id;
+  guint pid;
+  RbufCtxPtr ctx;
+  gint64 buffer_time;
+  gint64 latency_time;
+  WAVEFORMATEX *mix_format = nullptr;
+  gboolean low_latency = FALSE;
+  gboolean exclusive = FALSE;
+  HANDLE event_handle;
+};
+
+static gboolean
+is_equal_device_id (const gchar * a, const gchar * b)
+{
+  auto len_a = strlen (a);
+  auto len_b = strlen (b);
+
+  if (len_a != len_b)
+    return FALSE;
+
+#ifdef _MSC_VER
+  return _strnicmp (a, b, len_a) == 0;
+#else
+  return strncasecmp (a, b, len_a) == 0;
+#endif
+}
+
+static HRESULT
+initialize_audio_client_exclusive (IMMDevice * device,
+    ComPtr<IAudioClient> & client, WAVEFORMATEX * wfx, guint * period,
+    bool low_latency, gint64 latency_time)
+{
+  /* Format must be validated by caller */
+  auto hr = client->IsFormatSupported (AUDCLNT_SHAREMODE_EXCLUSIVE,
+      wfx, nullptr);
+  if (hr != S_OK)
+    return E_FAIL;
+
+  REFERENCE_TIME min_hns = 0;
+  REFERENCE_TIME max_hns = 0;
+  REFERENCE_TIME default_period = 0;
+  REFERENCE_TIME min_hns_period = 0;
+
+  {
+    ComPtr<IAudioClient2> client2;
+    hr = client->QueryInterface (IID_PPV_ARGS (&client2));
+    if (SUCCEEDED (hr)) {
+      hr = client2->GetBufferSizeLimits (wfx, TRUE, &min_hns, &max_hns);
+      if (FAILED (hr) || min_hns == 0 || max_hns == 0) {
+        min_hns = 0;
+        max_hns = 0;
+      } else {
+        auto min_gst = static_cast <GstClockTime> (min_hns) * 100;
+        auto max_gst = static_cast <GstClockTime> (max_hns) * 100;
+        GST_DEBUG ("GetBufferSizeLimits - min: %" GST_TIME_FORMAT ", max: %"
+            GST_TIME_FORMAT, GST_TIME_ARGS (min_gst), GST_TIME_ARGS (max_gst));
+      }
+    }
+  }
+
+  hr = client->GetDevicePeriod (&default_period, &min_hns_period);
+  if (!gst_wasapi2_result (hr))
+    return hr;
+
+  auto min_gst = static_cast <GstClockTime> (min_hns_period) * 100;
+  auto default_gst = static_cast <GstClockTime> (default_period) * 100;
+  GST_DEBUG ("GetDevicePeriod - default: %" GST_TIME_FORMAT ", min: %"
+      GST_TIME_FORMAT, GST_TIME_ARGS (default_gst), GST_TIME_ARGS (min_gst));
+
+  min_hns = MAX (min_hns, min_hns_period);
+
+  if (max_hns == 0)
+    max_hns = default_period;
+
+  REFERENCE_TIME target = min_hns;
+  if (!low_latency && latency_time > 0)
+    target = latency_time * 10;
+
+  if (target < min_hns)
+    target = min_hns;
+  if (target > max_hns)
+    target = max_hns;
+
+  DWORD flags = AUDCLNT_STREAMFLAGS_EVENTCALLBACK |
+      AUDCLNT_STREAMFLAGS_NOPERSIST ;
+
+  hr = client->Initialize (AUDCLNT_SHAREMODE_EXCLUSIVE, flags,
+      target, target, wfx, nullptr);
+  if (hr == AUDCLNT_E_BUFFER_SIZE_NOT_ALIGNED) {
+    UINT32 buffer_size = 0;
+
+    GST_DEBUG ("Buffer size not aligned, opening device again");
+
+    hr = client->GetBufferSize (&buffer_size);
+    if (!gst_wasapi2_result (hr) || buffer_size == 0)
+      return E_FAIL;
+
+    client.Reset ();
+    hr = device->Activate (__uuidof (IAudioClient), CLSCTX_ALL, nullptr,
+        &client);
+    if (!gst_wasapi2_result (hr))
+      return hr;
+
+    target = (GST_SECOND / 100) * buffer_size / wfx->nSamplesPerSec;
+    hr = client->Initialize (AUDCLNT_SHAREMODE_EXCLUSIVE,
+      flags, target, target, wfx, nullptr);
+  }
+
+  if (!gst_wasapi2_result (hr))
+    return hr;
+
+  UINT32 buffer_size = 0;
+  hr = client->GetBufferSize (&buffer_size);
+  if (!gst_wasapi2_result (hr) || buffer_size == 0) {
+    client.Reset ();
+    return E_FAIL;
+  }
+
+  GST_DEBUG ("Configured exclusive mode period: %d frames", buffer_size);
+
+  if (period)
+    *period = buffer_size;
+
+  GST_DEBUG ("Opened in exclusive mode");
+
+  return S_OK;
+}
+
+static HRESULT
+initialize_audio_client (IAudioClient * client_handle,
+    WAVEFORMATEX * mix_format, guint * period,
+    DWORD extra_flags, GstWasapi2EndpointClass device_class,
+    bool low_latency, gint64 latency_time, gint64 buffer_time)
+{
+  REFERENCE_TIME default_period, min_period;
+  DWORD stream_flags =
+      AUDCLNT_STREAMFLAGS_EVENTCALLBACK | AUDCLNT_STREAMFLAGS_NOPERSIST;
+  HRESULT hr;
+  REFERENCE_TIME buf_dur = 0;
+
+  stream_flags |= extra_flags;
+
+  if (!gst_wasapi2_is_process_loopback_class (device_class)) {
+    hr = client_handle->GetDevicePeriod (&default_period, &min_period);
+    if (!gst_wasapi2_result (hr)) {
+      GST_WARNING ("Couldn't get device period info");
+      return hr;
+    }
+
+    GST_INFO ("wasapi2 default period: %" G_GINT64_FORMAT
+        ", min period: %" G_GINT64_FORMAT, default_period, min_period);
+
+    /* https://learn.microsoft.com/en-us/windows/win32/api/audioclient/nf-audioclient-iaudioclient-initialize
+     * For a shared-mode stream that uses event-driven buffering,
+     * the caller must set both hnsPeriodicity and hnsBufferDuration to 0
+     *
+     * The above MS documentation does not seem to correct. By setting
+     * zero hnsBufferDuration, we can use audio engine determined buffer size
+     * but it seems to cause glitch depending on device. Calculate buffer size
+     * like wasapi plugin does. Note that MS example code uses non-zero
+     * buffer duration for event-driven shared-mode case as well.
+     */
+    if (low_latency && latency_time > 0 && buffer_time > 0) {
+      /* Ensure that the period (latency_time) used is an integral multiple of
+       * either the default period or the minimum period */
+      guint64 factor = (latency_time * 10) / default_period;
+      REFERENCE_TIME period = default_period * MAX (factor, 1);
+
+      buf_dur = buffer_time * 10;
+      if (buf_dur < 2 * period)
+        buf_dur = 2 * period;
+    }
+
+    hr = client_handle->Initialize (AUDCLNT_SHAREMODE_SHARED, stream_flags,
+        buf_dur,
+        /* This must always be 0 in shared mode */
+        0, mix_format, nullptr);
+  } else {
+    /* XXX: virtual device will not report device period.
+     * Use hardcoded period 20ms, same as Microsoft sample code
+     * https://github.com/microsoft/windows-classic-samples/tree/main/Samples/ApplicationLoopback
+     */
+    default_period = (20 * GST_MSECOND) / 100;
+    hr = client_handle->Initialize (AUDCLNT_SHAREMODE_SHARED,
+        AUDCLNT_STREAMFLAGS_LOOPBACK | AUDCLNT_STREAMFLAGS_EVENTCALLBACK |
+        AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM,
+        default_period, 0, mix_format, nullptr);
+  }
+
+  if (!gst_wasapi2_result (hr)) {
+    GST_WARNING ("Couldn't initialize audioclient");
+    return hr;
+  }
+
+  if (period) {
+    *period = gst_util_uint64_scale_round (default_period * 100,
+        mix_format->nSamplesPerSec, GST_SECOND);
+  }
+
+  return S_OK;
+}
+
+static gboolean
+gst_wasapi2_rbuf_ctx_init (RbufCtxPtr & ctx, WAVEFORMATEX * selected_format)
+{
+  if (ctx->init_done) {
+    GST_DEBUG ("Already initialized");
+    return TRUE;
+  }
+
+  if (!selected_format) {
+    GST_ERROR ("No selected format");
+    return FALSE;
+  }
+
+  HRESULT hr;
+  if (ctx->is_exclusive) {
+    bool need_format_conv = false;
+    /* Try current format */
+    hr = ctx->client->IsFormatSupported (AUDCLNT_SHAREMODE_EXCLUSIVE,
+      selected_format, nullptr);
+    if (hr == S_OK) {
+      ctx->mix_format = gst_wasapi2_copy_wfx (selected_format);
+    } else {
+      /* Use closest format */
+      gst_wasapi2_sort_wfx (ctx->formats, selected_format);;
+
+      auto format = (WAVEFORMATEX *) g_ptr_array_index (ctx->formats, 0);
+
+      GstCaps *old_caps = nullptr;
+      GstCaps *new_caps = nullptr;
+
+      gst_wasapi2_util_parse_waveformatex (selected_format,
+          &old_caps, nullptr);
+      gst_wasapi2_util_parse_waveformatex (format,
+          &new_caps, nullptr);
+
+      if (!new_caps || !old_caps) {
+        GST_ERROR ("Couldn't get caps from format");
+        gst_clear_caps (&new_caps);
+        gst_clear_caps (&old_caps);
+        return FALSE;
+      }
+
+      if (!gst_caps_is_equal (new_caps, old_caps)) {
+        GST_INFO ("Closest caps is different, old: %" GST_PTR_FORMAT
+            ", new : %" GST_PTR_FORMAT, old_caps, new_caps);
+        need_format_conv = true;
+        gst_audio_info_from_caps (&ctx->host_info, old_caps);
+      }
+
+      gst_caps_unref (new_caps);
+      gst_caps_unref (old_caps);
+
+      ctx->mix_format = gst_wasapi2_copy_wfx (format);
+    }
+
+    gst_wasapi2_util_parse_waveformatex (ctx->mix_format, &ctx->caps, nullptr);
+    gst_audio_info_from_caps (&ctx->device_info, ctx->caps);
+    if (!need_format_conv)
+      ctx->host_info = ctx->device_info;
+
+    hr = initialize_audio_client_exclusive (ctx->device.Get (), ctx->client,
+        ctx->mix_format, &ctx->period, ctx->low_latency, ctx->latency_time);
+    if (FAILED (hr)) {
+      ctx->is_exclusive = false;
+      ctx->client = nullptr;
+      gst_wasapi2_clear_wfx (&ctx->mix_format);
+      gst_clear_caps (&ctx->caps);
+
+      hr = ctx->device->Activate (__uuidof (IAudioClient), CLSCTX_ALL,
+          nullptr, &ctx->client);
+      if (!gst_wasapi2_result (hr)) {
+        GST_WARNING ("Couldn't get IAudioClient from IMMDevice");
+        return FALSE;
+      }
+    } else if (need_format_conv) {
+      GstAudioInfo *in_info, *out_info;
+      if (ctx->endpoint_class == GST_WASAPI2_ENDPOINT_CLASS_CAPTURE) {
+        in_info = &ctx->device_info;
+        out_info = &ctx->host_info;
+      } else {
+        in_info = &ctx->host_info;
+        out_info = &ctx->device_info;
+      }
+
+      auto config = gst_structure_new_static_str ("converter-config",
+          GST_AUDIO_CONVERTER_OPT_DITHER_METHOD, GST_TYPE_AUDIO_DITHER_METHOD,
+          GST_AUDIO_DITHER_TPDF,
+          GST_AUDIO_CONVERTER_OPT_RESAMPLER_METHOD,
+          GST_TYPE_AUDIO_RESAMPLER_METHOD, GST_AUDIO_RESAMPLER_METHOD_KAISER,
+          nullptr);
+
+      gst_audio_resampler_options_set_quality (GST_AUDIO_RESAMPLER_METHOD_KAISER,
+          GST_AUDIO_RESAMPLER_QUALITY_DEFAULT, GST_AUDIO_INFO_RATE (in_info),
+            GST_AUDIO_INFO_RATE (out_info), config);
+
+      ctx->conv = gst_audio_converter_new (GST_AUDIO_CONVERTER_FLAG_NONE,
+          in_info, out_info, config);
+      if (!ctx->conv) {
+        GST_ERROR ("Couldn't create converter");
+        ctx->is_exclusive = false;
+        ctx->client = nullptr;
+        gst_wasapi2_clear_wfx (&ctx->mix_format);
+        gst_clear_caps (&ctx->caps);
+
+        hr = ctx->device->Activate (__uuidof (IAudioClient), CLSCTX_ALL,
+            nullptr, &ctx->client);
+        if (!gst_wasapi2_result (hr)) {
+          GST_WARNING ("Couldn't get IAudioClient from IMMDevice");
+          return FALSE;
+        }
+      } else {
+        GST_INFO ("converter configured");
+      }
+    }
+  }
+
+  if (!ctx->is_exclusive) {
+    DWORD stream_flags = 0;
+    /* Check format support */
+    WAVEFORMATEX *closest = nullptr;
+    hr = ctx->client->IsFormatSupported (AUDCLNT_SHAREMODE_SHARED,
+        selected_format, &closest);
+    if (hr == S_OK) {
+      ctx->mix_format = gst_wasapi2_copy_wfx (selected_format);
+      /* format supported */
+    } else if (hr == S_FALSE) {
+      if (!closest) {
+        GST_ERROR ("Couldn't get closest format");
+        return FALSE;
+      }
+
+      GstCaps *old_caps = nullptr;
+      GstCaps *new_caps = nullptr;
+
+      gst_wasapi2_util_parse_waveformatex (selected_format,
+          &old_caps, nullptr);
+      gst_wasapi2_util_parse_waveformatex (closest,
+          &new_caps, nullptr);
+
+      if (!new_caps || !old_caps) {
+        GST_ERROR ("Couldn't get caps from format");
+        gst_clear_caps (&new_caps);
+        gst_clear_caps (&old_caps);
+        CoTaskMemFree (closest);
+        return FALSE;
+      }
+
+      if (!gst_caps_is_equal (new_caps, old_caps)) {
+        GST_INFO ("Closest caps is different, old: %" GST_PTR_FORMAT
+            ", new : %" GST_PTR_FORMAT, old_caps, new_caps);
+        /* Hope OS mixer can convert the format */
+        gst_caps_unref (new_caps);
+        gst_caps_unref (old_caps);
+        CoTaskMemFree (closest);
+        ctx->mix_format = gst_wasapi2_copy_wfx (selected_format);
+        stream_flags = AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM |
+            AUDCLNT_STREAMFLAGS_SRC_DEFAULT_QUALITY;
+      } else {
+        gst_caps_unref (new_caps);
+        gst_caps_unref (old_caps);
+
+        ctx->mix_format = closest;
+      }
+    } else {
+      ctx->mix_format = gst_wasapi2_copy_wfx (selected_format);
+      stream_flags = AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM |
+          AUDCLNT_STREAMFLAGS_SRC_DEFAULT_QUALITY;
+    }
+
+    gst_wasapi2_util_parse_waveformatex (ctx->mix_format, &ctx->caps, nullptr);
+
+    bool client3_init_done = false;
+    if (!gst_wasapi2_is_loopback_class (ctx->endpoint_class) &&
+        !gst_wasapi2_is_process_loopback_class (ctx->endpoint_class)) {
+      /* Use IAudioClient3::InitializeSharedAudioStream if
+       * - low-latency is requested
+       * - device actually supports shared-mode low-latency streaming
+       *   (i.e., min-period < default-period) and user requested latency-time
+       *   is smaller than default-period */
+      ComPtr<IAudioClient3> client3;
+      hr = ctx->client.As (&client3);
+      if (SUCCEEDED (hr)) {
+        UINT32 default_period, fundamental_period, min_period, max_period;
+        hr = client3->GetSharedModeEnginePeriod (ctx->mix_format,
+            &default_period, &fundamental_period, &min_period, &max_period);
+
+        if (SUCCEEDED (hr)) {
+          UINT32 target_period_frames = 0;
+          UINT32 latency_time_frames =
+            static_cast<UINT32>(ctx->latency_time *
+              ctx->mix_format->nSamplesPerSec / 1000000.0);
+          if (ctx->low_latency) {
+            target_period_frames = min_period;
+          } else if (min_period < default_period &&
+              latency_time_frames < default_period) {
+            UINT32 cand = MAX (min_period, latency_time_frames);
+            if (fundamental_period > 0) {
+              /* period should be multiple of fundamental period */
+              cand = ((cand + fundamental_period - 1) / fundamental_period)
+                * fundamental_period;
+            }
+
+            cand = MAX (cand, min_period);
+            cand = MIN (cand, max_period);
+
+            /* Use audioclient3 only if calculated target period is
+             * smaller than default period */
+            if (cand < default_period)
+              target_period_frames = cand;
+          }
+
+          if (target_period_frames > 0) {
+            DWORD flags = stream_flags |
+                AUDCLNT_STREAMFLAGS_EVENTCALLBACK;
+            hr = client3->InitializeSharedAudioStream (flags,
+                target_period_frames, ctx->mix_format, nullptr);
+            if (SUCCEEDED (hr)) {
+              GST_INFO ("Using IAudioClient3, default period %d frames, "
+                "fundamental period %d frames, minimum period %d frames, "
+                "maximum period %d frames, requested latency time %d frames, "
+                "target period %d frames", default_period,
+                fundamental_period, min_period, max_period, latency_time_frames,
+                target_period_frames);
+              client3_init_done = true;
+              ctx->period = target_period_frames;
+            }
+          }
+        }
+      }
+    }
+
+    if (!client3_init_done) {
+      DWORD extra_flags = stream_flags;
+      if (gst_wasapi2_is_loopback_class (ctx->endpoint_class))
+        extra_flags = AUDCLNT_STREAMFLAGS_LOOPBACK;
+
+      hr = initialize_audio_client (ctx->client.Get (), ctx->mix_format,
+          &ctx->period, extra_flags, ctx->endpoint_class, ctx->low_latency,
+          ctx->latency_time, ctx->buffer_time);
+    }
+
+    if (FAILED (hr))
+      return FALSE;
+  }
+
+  if (ctx->endpoint_class == GST_WASAPI2_ENDPOINT_CLASS_RENDER) {
+    hr = ctx->client->SetEventHandle (ctx->render_event);
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't set event handle");
+      return FALSE;
+    }
+
+    hr = ctx->client->GetService (IID_PPV_ARGS (&ctx->render_client));
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't get render client handle");
+      return FALSE;
+    }
+  } else {
+    hr = ctx->client->SetEventHandle (ctx->capture_event);
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't set event handle");
+      return FALSE;
+    }
+
+    hr = ctx->client->GetService (IID_PPV_ARGS (&ctx->capture_client));
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't get capture client handle");
+      return FALSE;
+    }
+  }
+
+  if (!ctx->is_exclusive) {
+    hr = ctx->client->GetService (IID_PPV_ARGS (&ctx->stream_volume));
+    if (!gst_wasapi2_result (hr))
+      GST_WARNING ("Couldn't get ISimpleAudioVolume interface");
+  }
+
+  hr = ctx->client->GetBufferSize (&ctx->client_buf_size);
+  if (!gst_wasapi2_result (hr)) {
+    GST_ERROR ("Couldn't get buffer size");
+    return FALSE;
+  }
+
+  /* Activate silence feed client */
+  if (ctx->dummy_client) {
+    WAVEFORMATEX *mix_format = nullptr;
+    hr = ctx->dummy_client->GetMixFormat (&mix_format);
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't get mix format");
+      return FALSE;
+    }
+
+    hr = initialize_audio_client (ctx->dummy_client.Get (), mix_format, nullptr,
+        0, GST_WASAPI2_ENDPOINT_CLASS_RENDER, false, 0, 0);
+    CoTaskMemFree (mix_format);
+
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't initialize dummy client");
+      return FALSE;
+    }
+
+    hr = ctx->dummy_client->SetEventHandle (ctx->render_event);
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't set event handle");
+      return FALSE;
+    }
+
+    hr = ctx->dummy_client->GetBufferSize (&ctx->dummy_buf_size);
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't get buffer size");
+      return FALSE;
+    }
+
+    hr = ctx->dummy_client->GetService (IID_PPV_ARGS (&ctx->render_client));
+    if (!gst_wasapi2_result (hr)) {
+      GST_ERROR ("Couldn't get render client");
+      return FALSE;
+    }
+
+    if (ctx->device) {
+      hr = ctx->device->Activate (__uuidof (IAudioEndpointVolume),
+          CLSCTX_ALL, nullptr, &ctx->endpoint_volume);
+      if (gst_wasapi2_result (hr)) {
+        Wasapi2EndpointVolumeCallback::CreateInstance (&ctx->volume_callback,
+            ctx);
+
+        hr = ctx->endpoint_volume->RegisterControlChangeNotify (
+            ctx->volume_callback.Get ());
+        if (!gst_wasapi2_result (hr)) {
+          ctx->volume_callback = nullptr;
+        } else {
+          BOOL muted = FALSE;
+          hr = ctx->endpoint_volume->GetMute (&muted);
+          if (gst_wasapi2_result (hr))
+            ctx->endpoint_muted = muted;
+        }
+      }
+    }
+  }
+
+  /* Preroll data with silent data */
+  if (ctx->render_client && !ctx->dummy_client) {
+    if (ctx->is_exclusive) {
+      BYTE *data;
+      hr = ctx->render_client->GetBuffer (ctx->client_buf_size, &data);
+      if (SUCCEEDED (hr)) {
+        GST_DEBUG ("Prefill %u frames", ctx->client_buf_size);
+        ctx->render_client->ReleaseBuffer (ctx->client_buf_size,
+            AUDCLNT_BUFFERFLAGS_SILENT);
+      }
+    } else {
+      UINT32 padding = 0;
+      auto hr = ctx->client->GetCurrentPadding (&padding);
+      if (SUCCEEDED (hr) && padding < ctx->client_buf_size) {
+        auto can_write = ctx->client_buf_size - padding;
+        if (can_write > ctx->period)
+          can_write = ctx->period;
+
+        BYTE *data;
+        hr = ctx->render_client->GetBuffer (can_write, &data);
+        if (SUCCEEDED (hr)) {
+          GST_DEBUG ("Prefill %u frames", can_write);
+          ctx->render_client->ReleaseBuffer (can_write,
+              AUDCLNT_BUFFERFLAGS_SILENT);
+        }
+      }
+    }
+  }
+
+  /* Warm up device, first Start() call may take long if device is in idle state */
+  if (ctx->capture_client && !ctx->dummy_client) {
+    ctx->client->Start ();
+    ctx->client->Stop ();
+    ctx->client->Reset ();
+  }
+
+  GstAudioInfo info;
+  gst_audio_info_from_caps (&info, ctx->caps);
+
+  /* Due to format mismatch between Windows and GStreamer,
+   * we need to convert format */
+  if (GST_AUDIO_INFO_FORMAT (&info) == GST_AUDIO_FORMAT_S24_32LE)
+    ctx->is_s24in32 = true;
+
+  /* Allocates staging buffer for exclusive mode, since we should fill
+   * endpoint buffer at once */
+  if (ctx->is_exclusive && ctx->render_client) {
+    ctx->exclusive_period_bytes = ctx->period * GST_AUDIO_INFO_BPF (&info);
+    ctx->exclusive_staging.resize (ctx->exclusive_period_bytes);
+    ctx->exclusive_staging_filled = 0;
+  }
+
+  ctx->init_done = true;
+
+  return TRUE;
+}
+
+static void
+gst_wasapi2_device_manager_create_ctx (IMMDeviceEnumerator * enumerator,
+    RbufCtxDesc * desc)
+{
+  HRESULT hr = S_OK;
+  Wasapi2ActivationHandler *activator = nullptr;
+  Wasapi2ActivationHandler *dummy_activator = nullptr;
+  ComPtr<IMMDevice> device;
+  bool is_default = false;
+
+  if (!enumerator)
+    return;
+
+  auto endpoint_class = desc->endpoint_class;
+
+  if ((endpoint_class == GST_WASAPI2_ENDPOINT_CLASS_LOOPBACK_CAPTURE ||
+      gst_wasapi2_is_process_loopback_class (endpoint_class)) &&
+    desc->exclusive) {
+    GST_WARNING ("Loopback + exclusive is not supported configuration");
+    desc->exclusive = FALSE;
+  }
+
+  switch (endpoint_class) {
+    case GST_WASAPI2_ENDPOINT_CLASS_CAPTURE:
+      if (desc->device_id.empty () ||
+          is_equal_device_id (desc->device_id.c_str (),
+              gst_wasapi2_get_default_device_id (eCapture))) {
+        if (gst_wasapi2_can_automatic_stream_routing () && !desc->exclusive) {
+          Wasapi2ActivationHandler::CreateInstance (&activator,
+              gst_wasapi2_get_default_device_id_wide (eCapture), nullptr);
+          GST_LOG ("Creating default capture device");
+        }
+
+        GST_LOG ("Creating default capture MMdevice");
+        hr = enumerator->GetDefaultAudioEndpoint (eCapture,
+            eConsole, &device);
+      } else {
+        auto wstr = g_utf8_to_utf16 (desc->device_id.c_str (),
+            -1, nullptr, nullptr, nullptr);
+        hr = enumerator->GetDevice ((LPCWSTR) wstr, &device);
+        g_free (wstr);
+      }
+      break;
+    case GST_WASAPI2_ENDPOINT_CLASS_RENDER:
+    case GST_WASAPI2_ENDPOINT_CLASS_LOOPBACK_CAPTURE:
+      if (desc->device_id.empty () ||
+          is_equal_device_id (desc->device_id.c_str (),
+              gst_wasapi2_get_default_device_id (eRender))) {
+        if (gst_wasapi2_can_automatic_stream_routing () && !desc->exclusive) {
+          Wasapi2ActivationHandler::CreateInstance (&activator,
+              gst_wasapi2_get_default_device_id_wide (eRender), nullptr);
+          GST_LOG ("Creating default render device");
+
+          if (endpoint_class == GST_WASAPI2_ENDPOINT_CLASS_LOOPBACK_CAPTURE) {
+            /* Create another client to send dummy audio data to endpoint */
+             Wasapi2ActivationHandler::CreateInstance (&dummy_activator,
+                gst_wasapi2_get_default_device_id_wide (eRender), nullptr);
+          }
+        }
+
+        hr = enumerator->GetDefaultAudioEndpoint (eRender,
+            eConsole, &device);
+      } else {
+        auto wstr = g_utf8_to_utf16 (desc->device_id.c_str (),
+            -1, nullptr, nullptr, nullptr);
+        hr = enumerator->GetDevice ((LPCWSTR) wstr, &device);
+        g_free (wstr);
+      }
+      break;
+    case GST_WASAPI2_ENDPOINT_CLASS_INCLUDE_PROCESS_LOOPBACK_CAPTURE:
+    case GST_WASAPI2_ENDPOINT_CLASS_EXCLUDE_PROCESS_LOOPBACK_CAPTURE:
+    {
+      AUDIOCLIENT_ACTIVATION_PARAMS params = { };
+      params.ActivationType = AUDIOCLIENT_ACTIVATION_TYPE_PROCESS_LOOPBACK;
+      params.ProcessLoopbackParams.TargetProcessId = desc->pid;
+      if (desc->endpoint_class ==
+          GST_WASAPI2_ENDPOINT_CLASS_INCLUDE_PROCESS_LOOPBACK_CAPTURE) {
+        params.ProcessLoopbackParams.ProcessLoopbackMode =
+            PROCESS_LOOPBACK_MODE_INCLUDE_TARGET_PROCESS_TREE;
+      } else {
+        params.ProcessLoopbackParams.ProcessLoopbackMode =
+            PROCESS_LOOPBACK_MODE_EXCLUDE_TARGET_PROCESS_TREE;
+      }
+
+      GST_LOG ("Creating process loopback capture device");
+
+      Wasapi2ActivationHandler::CreateInstance (&activator,
+          VIRTUAL_AUDIO_DEVICE_PROCESS_LOOPBACK, &params);
+      break;
+    }
+    default:
+      g_assert_not_reached ();
+      return;
+  }
+
+  /* For debug */
+  gst_wasapi2_result (hr);
+
+  auto ctx = std::make_shared<RbufCtx> (desc->device_id);
+  if (activator) {
+    is_default = true;
+    activator->ActivateAsync ();
+    activator->GetClient (&ctx->client, INFINITE);
+    activator->Release ();
+    if (dummy_activator) {
+      dummy_activator->ActivateAsync ();
+      dummy_activator->GetClient (&ctx->dummy_client, INFINITE);
+      dummy_activator->Release ();
+
+      if (!ctx->dummy_client) {
+        GST_WARNING ("Couldn't get dummy audio client");
+        ctx->client = nullptr;
+      }
+    }
+  }
+
+  if (!ctx->client) {
+    if (!device) {
+      GST_WARNING ("Couldn't get IMMDevice");
+      return;
+    }
+
+    hr = device->Activate (__uuidof (IAudioClient), CLSCTX_ALL,
+          nullptr, &ctx->client);
+    if (!gst_wasapi2_result (hr)) {
+      GST_WARNING ("Couldn't get IAudioClient from IMMDevice");
+      return;
+    }
+
+    if (endpoint_class == GST_WASAPI2_ENDPOINT_CLASS_LOOPBACK_CAPTURE) {
+      hr = device->Activate (__uuidof (IAudioClient), CLSCTX_ALL,
+          nullptr, &ctx->dummy_client);
+      if (!gst_wasapi2_result (hr)) {
+        GST_WARNING ("Couldn't get IAudioClient from IMMDevice");
+        return;
+      }
+    }
+  }
+
+  if (desc->exclusive) {
+    if (!device) {
+      GST_WARNING ("IMMDevice is unavailable");
+      return;
+    }
+
+    ComPtr < IPropertyStore > prop;
+    hr = device->OpenPropertyStore (STGM_READ, &prop);
+    if (!gst_wasapi2_result (hr))
+      return;
+
+    g_ptr_array_set_size (ctx->formats, 0);
+    gst_wasapi2_get_exclusive_mode_formats (ctx->client.Get (), prop.Get (),
+        ctx->formats);
+    if (ctx->formats->len == 0) {
+      GST_WARNING ("Couldn't get exclusive mode formats");
+      desc->exclusive = false;
+    }
+  }
+
+  if (!desc->exclusive) {
+    gst_wasapi2_get_shared_mode_formats (ctx->client.Get (), ctx->formats);
+    if (ctx->formats->len == 0) {
+      if (gst_wasapi2_is_process_loopback_class (endpoint_class)) {
+        g_ptr_array_add (ctx->formats, gst_wasapi2_get_default_mix_format ());
+      } else {
+        GST_ERROR ("Couldn't find supported formats");
+        return;
+      }
+    }
+  }
+
+  ctx->supported_caps = gst_wasapi2_wfx_list_to_caps (ctx->formats);
+  if (!ctx->supported_caps) {
+    GST_ERROR ("Couldn't build caps from format");
+    return;
+  }
+
+  ctx->is_default = is_default;
+  ctx->endpoint_class = endpoint_class;
+  ctx->is_exclusive = desc->exclusive;
+  ctx->device = device;
+  ctx->low_latency = desc->low_latency;
+  ctx->latency_time = desc->latency_time;
+  ctx->buffer_time = desc->buffer_time;
+
+  if (!desc->mix_format) {
+    /* format not fixated, return ctx without init */
+    desc->ctx = ctx;
+    return;
+  }
+
+  if (gst_wasapi2_rbuf_ctx_init (ctx, desc->mix_format))
+    desc->ctx = ctx;
+}
+
+struct Wasapi2DeviceManager
+{
+  Wasapi2DeviceManager (const Wasapi2DeviceManager &) = delete;
+  Wasapi2DeviceManager& operator= (const Wasapi2DeviceManager &) = delete;
+
+  static Wasapi2DeviceManager * GetInstance()
+  {
+    static Wasapi2DeviceManager *inst = nullptr;
+    GST_WASAPI2_CALL_ONCE_BEGIN {
+      inst = new Wasapi2DeviceManager ();
+    } GST_WASAPI2_CALL_ONCE_END;
+
+    return inst;
+  }
+
+  Wasapi2DeviceManager ()
+  {
+    shutdown_handle = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+    interrupt_handle = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+    com_thread = g_thread_new ("Wasapi2DeviceManager",
+        (GThreadFunc) device_manager_com_thread, this);
+  }
+
+  ~Wasapi2DeviceManager ()
+  {
+    CloseHandle (shutdown_handle);
+    CloseHandle (interrupt_handle);
+  }
+
+  RbufCtxPtr
+  CreateCtx (const std::string & device_id,
+      GstWasapi2EndpointClass endpoint_class, guint pid, gint64 buffer_time,
+      gint64 latency_time, gboolean low_latency, gboolean exclusive,
+      WAVEFORMATEX * mix_format)
+  {
+    auto desc = std::make_shared<RbufCtxDesc> ();
+    desc->device_id = device_id;
+    desc->endpoint_class = endpoint_class;
+    desc->pid = pid;
+    desc->buffer_time = buffer_time;
+    desc->latency_time = latency_time;
+    desc->low_latency = low_latency;
+    desc->exclusive = exclusive;
+    if (mix_format)
+      desc->mix_format = gst_wasapi2_copy_wfx (mix_format);
+
+    {
+      std::lock_guard <std::mutex> lk (lock);
+      queue.push (desc);
+    }
+    SetEvent (interrupt_handle);
+
+    WaitForSingleObject (desc->event_handle, INFINITE);
+
+    return desc->ctx;
+  }
+
+  void
+  CreateCtxAsync (GstWasapi2Rbuf * rbuf, const std::string & device_id,
+      GstWasapi2EndpointClass endpoint_class, guint pid, gint64 buffer_time,
+      gint64 latency_time, gboolean low_latency, gboolean exclusive,
+      WAVEFORMATEX * mix_format)
+  {
+    auto desc = std::make_shared<RbufCtxDesc> ();
+    desc->rbuf = (GstWasapi2Rbuf *) gst_object_ref (rbuf);
+    desc->device_id = device_id;
+    desc->endpoint_class = endpoint_class;
+    desc->pid = pid;
+    desc->buffer_time = buffer_time;
+    desc->latency_time = latency_time;
+    desc->low_latency = low_latency;
+    desc->exclusive = exclusive;
+    if (mix_format)
+      desc->mix_format = gst_wasapi2_copy_wfx (mix_format);
+
+    {
+      std::lock_guard <std::mutex> lk (lock);
+      queue.push (desc);
+    }
+    SetEvent (interrupt_handle);
+  }
+
+  std::mutex lock;
+  std::queue<std::shared_ptr<RbufCtxDesc>> queue;
+  HANDLE shutdown_handle;
+  HANDLE interrupt_handle;
+  GThread *com_thread;
+};
+
+static gpointer
+device_manager_com_thread (gpointer manager)
+{
+  auto self = (Wasapi2DeviceManager *) manager;
+  CoInitializeEx (nullptr, COINIT_MULTITHREADED);
+
+  ComPtr<IMMDeviceEnumerator> enumerator;
+  CoCreateInstance (__uuidof (MMDeviceEnumerator),
+      nullptr, CLSCTX_ALL, IID_PPV_ARGS (&enumerator));
+
+  HANDLE waitables[] = { self->shutdown_handle, self->interrupt_handle };
+  bool running = true;
+  while (running) {
+    auto wait_ret = WaitForMultipleObjects (G_N_ELEMENTS (waitables),
+        waitables, FALSE, INFINITE);
+
+    switch (wait_ret) {
+      case WAIT_OBJECT_0:
+        running = false;
+        break;
+      case WAIT_OBJECT_0 + 1:
+      {
+        std::unique_lock <std::mutex> lk (self->lock);
+        while (!self->queue.empty ()) {
+          auto desc = self->queue.front ();
+          self->queue.pop ();
+          lk.unlock ();
+          GST_LOG ("Creating new context");
+
+          gst_wasapi2_device_manager_create_ctx (enumerator.Get (), desc.get ());
+
+          if (desc->mix_format)
+            CoTaskMemFree (desc->mix_format);
+
+          SetEvent (desc->event_handle);
+
+          if (desc->rbuf) {
+            auto cmd = std::make_shared < CommandUpdateDevice > (desc->device_id);
+            cmd->ctx = std::move (desc->ctx);
+
+            gst_wasapi2_rbuf_push_command (desc->rbuf, cmd);
+            WaitForSingleObject (cmd->event_handle, INFINITE);
+
+            gst_object_unref (desc->rbuf);
+          }
+
+          lk.lock ();
+        }
+        break;
+      }
+      default:
+        GST_ERROR ("Unexpected wait return 0x%x", (guint) wait_ret);
+        running = false;
+        break;
+    }
+  }
+
+  enumerator = nullptr;
+
+  CoUninitialize ();
+
+  return nullptr;
+}
+
+struct GstWasapi2RbufPrivate
+{
+  GstWasapi2RbufPrivate ()
+  {
+    command_handle = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+    g_weak_ref_init (&parent, nullptr);
+
+    QueryPerformanceFrequency (&qpc_freq);
+  }
+
+  ~GstWasapi2RbufPrivate ()
+  {
+    CloseHandle (command_handle);
+    gst_clear_caps (&caps);
+    g_weak_ref_set (&parent, nullptr);
+  }
+
+  std::string device_id;
+  GstWasapi2EndpointClass endpoint_class;
+  guint pid;
+  gboolean low_latency = FALSE;
+  gboolean exclusive = FALSE;
+
+  std::shared_ptr<RbufCtx> ctx;
+  std::atomic<bool> monitor_device_mute = { false };
+  GThread *thread = nullptr;
+  HANDLE command_handle;
+  GstCaps *caps = nullptr;
+
+  std::mutex lock;
+  std::condition_variable cond;
+  WAVEFORMATEX *mix_format = nullptr;
+  std::queue<std::shared_ptr<CommandData>> cmd_queue;
+  bool opened = false;
+  bool running = false;
+
+  std::atomic<float> volume = { 1.0 };
+  std::atomic<bool> mute = { false };
+  std::atomic<bool> allow_dummy = { false };
+
+  bool is_first = true;
+  gint segoffset = 0;
+  guint64 write_frame_offset = 0;
+  guint64 expected_position = 0;
+
+  HANDLE fallback_timer = nullptr;
+  bool fallback_timer_armed = false;
+  UINT64 fallback_frames_processed = 0;
+  bool configured_allow_dummy = false;
+
+  LARGE_INTEGER qpc_freq;
+  LARGE_INTEGER fallback_qpc_base;
+
+  HANDLE monitor_timer = nullptr;
+  bool monitor_timer_armed = false;
+
+  std::vector<guint8> temp_data;
+
+  GWeakRef parent;
+  GstWasapi2RbufCallback invalidated_cb;
+};
+/* *INDENT-ON* */
+
+struct _GstWasapi2Rbuf
+{
+  GstAudioRingBuffer parent;
+
+  GstWasapi2RbufPrivate *priv;
+};
+
+static void gst_wasapi2_rbuf_finalize (GObject * object);
+
+static gboolean gst_wasapi2_rbuf_open_device (GstAudioRingBuffer * buf);
+static gboolean gst_wasapi2_rbuf_close_device (GstAudioRingBuffer * buf);
+static gboolean gst_wasapi2_rbuf_acquire (GstAudioRingBuffer * buf,
+    GstAudioRingBufferSpec * spec);
+static gboolean gst_wasapi2_rbuf_release (GstAudioRingBuffer * buf);
+static gboolean gst_wasapi2_rbuf_start (GstAudioRingBuffer * buf);
+static gboolean gst_wasapi2_rbuf_resume (GstAudioRingBuffer * buf);
+static gboolean gst_wasapi2_rbuf_pause (GstAudioRingBuffer * buf);
+static gboolean gst_wasapi2_rbuf_stop (GstAudioRingBuffer * buf);
+static guint gst_wasapi2_rbuf_delay (GstAudioRingBuffer * buf);
+static gpointer gst_wasapi2_rbuf_loop_thread (GstWasapi2Rbuf * self);
+
+#define gst_wasapi2_rbuf_parent_class parent_class
+G_DEFINE_TYPE (GstWasapi2Rbuf, gst_wasapi2_rbuf, GST_TYPE_AUDIO_RING_BUFFER);
+
+static void
+gst_wasapi2_rbuf_class_init (GstWasapi2RbufClass * klass)
+{
+  GObjectClass *gobject_class = G_OBJECT_CLASS (klass);
+  GstAudioRingBufferClass *ring_buffer_class =
+      GST_AUDIO_RING_BUFFER_CLASS (klass);
+
+  gobject_class->finalize = gst_wasapi2_rbuf_finalize;
+
+  ring_buffer_class->open_device =
+      GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_open_device);
+  ring_buffer_class->close_device =
+      GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_close_device);
+  ring_buffer_class->acquire = GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_acquire);
+  ring_buffer_class->release = GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_release);
+  ring_buffer_class->start = GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_start);
+  ring_buffer_class->resume = GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_resume);
+  ring_buffer_class->pause = GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_pause);
+  ring_buffer_class->stop = GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_stop);
+  ring_buffer_class->delay = GST_DEBUG_FUNCPTR (gst_wasapi2_rbuf_delay);
+
+  GST_DEBUG_CATEGORY_INIT (gst_wasapi2_rbuf_debug,
+      "wasapi2ringbuffer", 0, "wasapi2ringbuffer");
+}
+
+static void
+gst_wasapi2_rbuf_init (GstWasapi2Rbuf * self)
+{
+  self->priv = new GstWasapi2RbufPrivate ();
+}
+
+static void
+gst_wasapi2_rbuf_push_command (GstWasapi2Rbuf * self,
+    std::shared_ptr < CommandData > cmd)
+{
+  auto priv = self->priv;
+
+  {
+    std::lock_guard < std::mutex > lk (priv->lock);
+    priv->cmd_queue.push (cmd);
+  }
+  SetEvent (priv->command_handle);
+}
+
+static void
+gst_wasapi2_rbuf_finalize (GObject * object)
+{
+  auto self = GST_WASAPI2_RBUF (object);
+  auto priv = self->priv;
+
+  GST_LOG_OBJECT (self, "Finalize");
+
+  auto cmd = std::make_shared < CommandData > (CommandType::Shutdown);
+  gst_wasapi2_rbuf_push_command (self, cmd);
+
+  g_thread_join (priv->thread);
+
+  delete priv;
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+gst_wasapi2_rbuf_post_open_error (GstWasapi2Rbuf * self,
+    const gchar * device_id)
+{
+  auto priv = self->priv;
+  auto parent = g_weak_ref_get (&priv->parent);
+
+  if (!parent)
+    return;
+
+  priv->invalidated_cb (parent);
+
+  if (priv->configured_allow_dummy) {
+    GST_ELEMENT_WARNING (parent, RESOURCE, OPEN_READ_WRITE,
+        (nullptr), ("Failed to open device %s", GST_STR_NULL (device_id)));
+  } else {
+    GST_ELEMENT_ERROR (parent, RESOURCE, OPEN_READ_WRITE,
+        (nullptr), ("Failed to open device %s", GST_STR_NULL (device_id)));
+  }
+
+  g_object_unref (parent);
+}
+
+static void
+gst_wasapi2_rbuf_post_io_error (GstWasapi2Rbuf * self, HRESULT hr,
+    gboolean is_write)
+{
+  auto priv = self->priv;
+  auto parent = g_weak_ref_get (&priv->parent);
+
+  auto error_msg = gst_wasapi2_util_get_error_message (hr);
+  GST_ERROR_OBJECT (self, "Posting I/O error %s (hr: 0x%x)", error_msg,
+      (guint) hr);
+
+  priv->invalidated_cb (parent);
+
+  if (is_write) {
+    if (priv->configured_allow_dummy) {
+      GST_ELEMENT_WARNING (parent, RESOURCE, WRITE,
+          ("Failed to write to device"), ("%s, hr: 0x%x", error_msg,
+              (guint) hr));
+    } else {
+      GST_ELEMENT_ERROR (parent, RESOURCE, WRITE,
+          ("Failed to write to device"), ("%s, hr: 0x%x", error_msg,
+              (guint) hr));
+    }
+  } else {
+    if (priv->configured_allow_dummy) {
+      GST_ELEMENT_WARNING (parent, RESOURCE, READ,
+          ("Failed to read from device"), ("%s hr: 0x%x", error_msg,
+              (guint) hr));
+    } else {
+      GST_ELEMENT_ERROR (parent, RESOURCE, READ,
+          ("Failed to read from device"), ("%s hr: 0x%x", error_msg,
+              (guint) hr));
+    }
+  }
+
+  g_free (error_msg);
+  g_object_unref (parent);
+}
+
+static RbufCtxPtr
+gst_wasapi2_rbuf_create_ctx (GstWasapi2Rbuf * self)
+{
+  auto priv = self->priv;
+  auto parent = g_weak_ref_get (&priv->parent);
+
+  if (!parent) {
+    GST_ERROR_OBJECT (self, "No parent");
+    return nullptr;
+  }
+
+  gint64 buffer_time = 0;
+  gint64 latency_time = 0;
+  g_object_get (parent, "buffer-time", &buffer_time, "latency-time",
+      &latency_time, nullptr);
+  g_object_unref (parent);
+
+  auto inst = Wasapi2DeviceManager::GetInstance ();
+
+  return inst->CreateCtx (priv->device_id, priv->endpoint_class,
+      priv->pid, buffer_time, latency_time, priv->low_latency,
+      priv->exclusive, priv->mix_format);
+}
+
+static void
+gst_wasapi2_rbuf_create_ctx_async (GstWasapi2Rbuf * self)
+{
+  auto priv = self->priv;
+  auto parent = g_weak_ref_get (&priv->parent);
+
+  if (!parent) {
+    GST_ERROR_OBJECT (self, "No parent");
+    return;
+  }
+
+  gint64 buffer_time = 0;
+  gint64 latency_time = 0;
+  g_object_get (parent, "buffer-time", &buffer_time, "latency-time",
+      &latency_time, nullptr);
+  g_object_unref (parent);
+
+  auto inst = Wasapi2DeviceManager::GetInstance ();
+
+  inst->CreateCtxAsync (self, priv->device_id, priv->endpoint_class,
+      priv->pid, buffer_time, latency_time, priv->low_latency,
+      priv->exclusive, priv->mix_format);
+}
+
+static gboolean
+gst_wasapi2_rbuf_open_device (GstAudioRingBuffer * buf)
+{
+  auto self = GST_WASAPI2_RBUF (buf);
+
+  GST_DEBUG_OBJECT (self, "Open");
+
+  auto cmd = std::make_shared < CommandData > (CommandType::Open);
+  gst_wasapi2_rbuf_push_command (self, cmd);
+
+  WaitForSingleObject (cmd->event_handle, INFINITE);
+
+  return gst_wasapi2_result (cmd->hr);
+}
+
+static gboolean
+gst_wasapi2_rbuf_close_device (GstAudioRingBuffer * buf)
+{
+  auto self = GST_WASAPI2_RBUF (buf);
+
+  GST_DEBUG_OBJECT (self, "Close device");
+
+  auto cmd = std::make_shared < CommandData > (CommandType::Close);
+
+  gst_wasapi2_rbuf_push_command (self, cmd);
+
+  WaitForSingleObject (cmd->event_handle, INFINITE);
+
+  return TRUE;
+}
+
+static gboolean
+gst_wasapi2_rbuf_acquire (GstAudioRingBuffer * buf,
+    GstAudioRingBufferSpec * spec)
+{
+  auto self = GST_WASAPI2_RBUF (buf);
+
+  auto cmd = std::make_shared < CommandAcquire > (spec);
+
+  gst_wasapi2_rbuf_push_command (self, cmd);
+
+  WaitForSingleObject (cmd->event_handle, INFINITE);
+
+  return gst_wasapi2_result (cmd->hr);
+}
+
+static gboolean
+gst_wasapi2_rbuf_release (GstAudioRingBuffer * buf)
+{
+  auto self = GST_WASAPI2_RBUF (buf);
+
+  GST_DEBUG_OBJECT (self, "Release");
+
+  auto cmd = std::make_shared < CommandData > (CommandType::Release);
+
+  gst_wasapi2_rbuf_push_command (self, cmd);
+
+  WaitForSingleObject (cmd->event_handle, INFINITE);
+
+  return TRUE;
+}
+
+static gboolean
+gst_wasapi2_rbuf_start_internal (GstWasapi2Rbuf * self)
+{
+  auto cmd = std::make_shared < CommandData > (CommandType::Start);
+  gst_wasapi2_rbuf_push_command (self, cmd);
+
+  WaitForSingleObject (cmd->event_handle, INFINITE);
+
+  return gst_wasapi2_result (cmd->hr);
+}
+
+static gboolean
+gst_wasapi2_rbuf_start (GstAudioRingBuffer * buf)
+{
+  auto self = GST_WASAPI2_RBUF (buf);
+
+  GST_DEBUG_OBJECT (self, "Start");
+
+  return gst_wasapi2_rbuf_start_internal (self);
+}
+
+static gboolean
+gst_wasapi2_rbuf_resume (GstAudioRingBuffer * buf)
+{
+  auto self = GST_WASAPI2_RBUF (buf);
+
+  GST_DEBUG_OBJECT (self, "Resume");
+
+  return gst_wasapi2_rbuf_start_internal (self);
+}
+
+static gboolean
+gst_wasapi2_rbuf_stop_internal (GstWasapi2Rbuf * self)
+{
+  auto cmd = std::make_shared < CommandData > (CommandType::Stop);
+  gst_wasapi2_rbuf_push_command (self, cmd);
+
+  WaitForSingleObject (cmd->event_handle, INFINITE);
+
+  return TRUE;
+}
+
+static gboolean
+gst_wasapi2_rbuf_stop (GstAudioRingBuffer * buf)
+{
+  auto self = GST_WASAPI2_RBUF (buf);
+
+  GST_DEBUG_OBJECT (self, "Stop");
+
+  return gst_wasapi2_rbuf_stop_internal (self);
+}
+
+static gboolean
+gst_wasapi2_rbuf_pause (GstAudioRingBuffer * buf)
+{
+  auto self = GST_WASAPI2_RBUF (buf);
+
+  GST_DEBUG_OBJECT (self, "Pause");
+
+  return gst_wasapi2_rbuf_stop_internal (self);
+}
+
+static inline gint32
+rshift8_32 (gint32 x)
+{
+  guint32 s = ((guint32) x) >> 8;
+  guint32 signmask = (x < 0) ? 0xff000000u : 0u;
+
+  return (gint32) (s | signmask);
+}
+
+static inline void
+shift32_right8_copy (const gint32 * src, gint32 * dst, size_t n)
+{
+#ifdef GST_WASAPI2_HAVE_SSE2
+  size_t i = 0;
+  size_t step = 4;
+  for (; i + step <= n; i += step) {
+    __m128i v = _mm_loadu_si128 ((const __m128i *) (src + i));
+    __m128i y = _mm_srai_epi32 (v, 8);
+    _mm_storeu_si128 ((__m128i *) (dst + i), y);
+  }
+
+  for (; i < n; i++)
+    dst[i] = rshift8_32 (src[i]);
+#else
+  for (size_t i = 0; i < n; i++)
+    dst[i] = rshift8_32 (src[i]);
+#endif
+}
+
+static inline void
+shift32_left8_copy (const gint32 * src, gint32 * dst, size_t n)
+{
+#ifdef GST_WASAPI2_HAVE_SSE2
+  size_t i = 0;
+  size_t step = 4;
+  for (; i + step <= n; i += 4) {
+    __m128i v = _mm_loadu_si128 ((const __m128i *) (src + i));
+    __m128i y = _mm_slli_epi32 (v, 8);
+    _mm_storeu_si128 ((__m128i *) (dst + i), y);
+  }
+
+  for (; i < n; i++)
+    dst[i] = (gint32) ((guint32) src[i] << 8);
+#else
+  for (size_t i = 0; i < n; i++)
+    dst[i] = (gint32) ((guint32) src[i] << 8);
+#endif
+}
+
+static inline void
+s24_msb_to_s24lsb (guint8 * dst, const guint8 * src, size_t bytes)
+{
+  if ((bytes & 3) == 0)
+    shift32_right8_copy ((const gint32 *) src, (gint32 *) dst, bytes >> 2);
+  else
+    memcpy (dst, src, bytes);
+}
+
+static inline void
+s24lsb_to_s24_msb (guint8 * dst, const guint8 * src, size_t bytes)
+{
+  if ((bytes & 3) == 0)
+    shift32_left8_copy ((const gint32 *) src, (gint32 *) dst, bytes >> 2);
+  else
+    memcpy (dst, src, bytes);
+}
+
+static HRESULT
+gst_wasapi2_rbuf_process_read (GstWasapi2Rbuf * self)
+{
+  auto rb = GST_AUDIO_RING_BUFFER_CAST (self);
+  auto priv = self->priv;
+  BYTE *data = nullptr;
+  UINT32 to_read_frames = 0;
+  DWORD flags = 0;
+  guint64 position = 0;
+  UINT64 qpc_pos = 0;
+  GstClockTime qpc_time;
+
+  if (!priv->ctx || !priv->ctx->capture_client) {
+    GST_ERROR_OBJECT (self, "IAudioCaptureClient is not available");
+    return E_FAIL;
+  }
+
+  auto & ctx = priv->ctx;
+  auto client = priv->ctx->capture_client;
+
+  auto hr =
+      client->GetBuffer (&data, &to_read_frames, &flags, &position, &qpc_pos);
+  /* 100 ns unit */
+  qpc_time = qpc_pos * 100;
+
+  GST_LOG_OBJECT (self, "Reading %d frames offset at %" G_GUINT64_FORMAT
+      ", expected position %" G_GUINT64_FORMAT ", qpc-time %"
+      GST_TIME_FORMAT "(%" G_GUINT64_FORMAT "), flags 0x%x", to_read_frames,
+      position, priv->expected_position, GST_TIME_ARGS (qpc_time), qpc_pos,
+      (guint) flags);
+
+  if (hr == AUDCLNT_S_BUFFER_EMPTY || to_read_frames == 0) {
+    GST_LOG_OBJECT (self, "Empty buffer");
+    return S_OK;
+  }
+
+  if (!gst_wasapi2_result (hr))
+    return hr;
+
+  guint gap_dev_frames = 0;
+  if (!gst_wasapi2_is_process_loopback_class (priv->ctx->endpoint_class)) {
+    /* XXX: position might not be increased in case of process loopback  */
+    if (priv->is_first) {
+      priv->expected_position = position + to_read_frames;
+      priv->is_first = false;
+    } else {
+      if (position > priv->expected_position) {
+        gap_dev_frames = (guint) (position - priv->expected_position);
+        GST_WARNING_OBJECT (self, "Found %u frames gap", gap_dev_frames);
+      }
+
+      priv->expected_position = position + to_read_frames;
+    }
+  }
+
+  if (priv->mute) {
+    /* volume clinet might not be available in case of process loopback */
+    flags |= AUDCLNT_BUFFERFLAGS_SILENT;
+  }
+
+  gboolean device_muted =
+      priv->monitor_device_mute.load (std::memory_order_acquire) &&
+      priv->ctx->IsEndpointMuted ();
+  gboolean force_silence =
+      ((flags & AUDCLNT_BUFFERFLAGS_SILENT) == AUDCLNT_BUFFERFLAGS_SILENT) ||
+      device_muted;
+
+  gsize host_bpf = (gsize) GST_AUDIO_INFO_BPF (&rb->spec.info);
+  gsize device_bpf = (ctx->conv)
+      ? (gsize) GST_AUDIO_INFO_BPF (&ctx->device_info)
+      : (gsize) GST_AUDIO_INFO_BPF (&rb->spec.info);
+
+  /* Fill gap data if any */
+  if (gap_dev_frames > 0) {
+    if (ctx->conv) {
+      auto gap_bytes = (gsize) gap_dev_frames * device_bpf;
+      auto old = ctx->device_fifo_bytes;
+      ctx->device_fifo.resize (old + gap_bytes);
+      gst_audio_format_info_fill_silence (ctx->device_info.finfo,
+          ctx->device_fifo.data () + old, (gint) gap_bytes);
+      ctx->device_fifo_bytes += gap_bytes;
+    } else {
+      auto gap_bytes = (gsize) gap_dev_frames * host_bpf;
+      while (gap_bytes > 0) {
+        gint segment;
+        guint8 *dstptr;
+        gint len;
+
+        if (!gst_audio_ring_buffer_prepare_read (rb, &segment, &dstptr, &len))
+          break;
+
+        len -= priv->segoffset;
+        if (len <= 0)
+          break;
+
+        gsize to_write = MIN ((gsize) len, gap_bytes);
+        gst_audio_format_info_fill_silence (rb->spec.info.finfo,
+            dstptr + priv->segoffset, (gint) to_write);
+
+        priv->segoffset += (gint) to_write;
+        gap_bytes -= to_write;
+
+        if (priv->segoffset == rb->spec.segsize) {
+          gst_audio_ring_buffer_advance (rb, 1);
+          priv->segoffset = 0;
+        }
+      }
+    }
+  }
+
+  if (ctx->conv) {
+    /* push device data to device_fifo */
+    const size_t in_bytes = (size_t) to_read_frames * device_bpf;
+    if (in_bytes > 0) {
+      const size_t old = ctx->device_fifo_bytes;
+      ctx->device_fifo.resize (old + in_bytes);
+      if (force_silence) {
+        gst_audio_format_info_fill_silence (ctx->device_info.finfo,
+            ctx->device_fifo.data () + old, (gint) in_bytes);
+      } else {
+        if (ctx->is_s24in32) {
+          s24_msb_to_s24lsb (ctx->device_fifo.data () + old, data, in_bytes);
+        } else {
+          memcpy (ctx->device_fifo.data () + old, data, in_bytes);
+        }
+      }
+      ctx->device_fifo_bytes += in_bytes;
+    }
+
+    /* convert device_fifo -> host_fifo */
+    while (ctx->device_fifo_bytes >= device_bpf) {
+      auto in_frames_avail = (gsize) (ctx->device_fifo_bytes / device_bpf);
+      auto out_frames = gst_audio_converter_get_out_frames (ctx->conv,
+          (gint) in_frames_avail);
+      if (out_frames == 0)
+        break;
+
+      auto out_bytes = (size_t) (out_frames * host_bpf);
+      priv->temp_data.resize (out_bytes);
+
+      gpointer in_planes[1] = { ctx->device_fifo.data () };
+      gpointer out_planes[1] = { priv->temp_data.data () };
+
+      if (!gst_audio_converter_samples (ctx->conv,
+              GST_AUDIO_CONVERTER_FLAG_NONE,
+              in_planes, (gint) in_frames_avail,
+              out_planes, (gint) out_frames)) {
+        GST_ERROR_OBJECT (self, "Couldn't convert sample");
+        client->ReleaseBuffer (to_read_frames);
+        return E_FAIL;
+      }
+
+      auto consumed_in = (size_t) (in_frames_avail * device_bpf);
+      if (consumed_in < ctx->device_fifo_bytes) {
+        memmove (ctx->device_fifo.data (),
+            ctx->device_fifo.data () + consumed_in,
+            ctx->device_fifo_bytes - consumed_in);
+      }
+      ctx->device_fifo_bytes -= consumed_in;
+      ctx->device_fifo.resize (ctx->device_fifo_bytes);
+
+      /* Push converted data to host_fifo */
+      if (out_bytes > 0) {
+        auto hold = ctx->host_fifo_bytes;
+        ctx->host_fifo.resize (hold + out_bytes);
+        memcpy (ctx->host_fifo.data () + hold, priv->temp_data.data (),
+            out_bytes);
+        ctx->host_fifo_bytes += out_bytes;
+      }
+
+      if (ctx->device_fifo_bytes < device_bpf)
+        break;
+    }
+
+    /* host_fifo -> ringbuffer */
+    while (ctx->host_fifo_bytes > 0) {
+      gint segment;
+      guint8 *dstptr;
+      gint len;
+
+      if (!gst_audio_ring_buffer_prepare_read (rb, &segment, &dstptr, &len))
+        break;
+
+      len -= priv->segoffset;
+      if (len <= 0)
+        break;
+
+      auto to_copy = MIN ((size_t) len, ctx->host_fifo_bytes);
+      memcpy (dstptr + priv->segoffset, ctx->host_fifo.data (), to_copy);
+
+      priv->segoffset += (gint) to_copy;
+
+      if (to_copy < ctx->host_fifo_bytes) {
+        memmove (ctx->host_fifo.data (),
+            ctx->host_fifo.data () + to_copy, ctx->host_fifo_bytes - to_copy);
+      }
+      ctx->host_fifo_bytes -= to_copy;
+      ctx->host_fifo.resize (ctx->host_fifo_bytes);
+
+      if (priv->segoffset == rb->spec.segsize) {
+        gst_audio_ring_buffer_advance (rb, 1);
+        priv->segoffset = 0;
+      }
+
+      if (to_copy == 0)
+        break;
+    }
+  } else {
+    gsize remain = (gsize) to_read_frames * device_bpf;
+    gsize offset = 0;
+
+    while (remain > 0) {
+      gint segment;
+      guint8 *dstptr;
+      gint len;
+
+      if (!gst_audio_ring_buffer_prepare_read (rb, &segment, &dstptr, &len)) {
+        GST_INFO_OBJECT (self, "No segment available");
+        break;
+      }
+
+      len -= priv->segoffset;
+      if (len <= 0)
+        break;
+
+      auto to_write = MIN ((gsize) len, remain);
+      if (force_silence) {
+        gst_audio_format_info_fill_silence (rb->spec.info.finfo,
+            dstptr + priv->segoffset, (gint) to_write);
+      } else {
+        if (ctx->is_s24in32)
+          s24_msb_to_s24lsb (dstptr + priv->segoffset, data + offset, to_write);
+        else
+          memcpy (dstptr + priv->segoffset, data + offset, to_write);
+      }
+
+      priv->segoffset += (gint) to_write;
+      offset += to_write;
+      remain -= to_write;
+
+      if (priv->segoffset == rb->spec.segsize) {
+        gst_audio_ring_buffer_advance (rb, 1);
+        priv->segoffset = 0;
+      }
+    }
+  }
+
+  hr = client->ReleaseBuffer (to_read_frames);
+  gst_wasapi2_result (hr);
+
+  return S_OK;
+}
+
+static HRESULT
+gst_wasapi2_rbuf_process_write (GstWasapi2Rbuf * self)
+{
+  auto rb = GST_AUDIO_RING_BUFFER_CAST (self);
+  auto priv = self->priv;
+  HRESULT hr;
+  guint32 padding_frames = 0;
+  guint32 can_write;
+  guint32 can_write_bytes;
+  gint segment;
+  guint8 *readptr;
+  gint len;
+  BYTE *data = nullptr;
+
+  if (!priv->ctx || !priv->ctx->render_client) {
+    GST_ERROR_OBJECT (self, "IAudioRenderClient is not available");
+    return E_FAIL;
+  }
+
+  auto client = priv->ctx->client;
+  auto render_client = priv->ctx->render_client;
+  bool force_silence = priv->mute;
+
+  hr = client->GetCurrentPadding (&padding_frames);
+  if (!gst_wasapi2_result (hr))
+    return hr;
+
+  if (padding_frames >= priv->ctx->client_buf_size) {
+    GST_INFO_OBJECT (self,
+        "Padding size %d is larger than or equal to buffer size %d",
+        padding_frames, priv->ctx->client_buf_size);
+    return S_OK;
+  }
+
+  can_write = priv->ctx->client_buf_size - padding_frames;
+  can_write_bytes = can_write * GST_AUDIO_INFO_BPF (&rb->spec.info);
+
+  GST_LOG_OBJECT (self, "Writing %d frames offset at %" G_GUINT64_FORMAT,
+      can_write, priv->write_frame_offset);
+  priv->write_frame_offset += can_write;
+
+  while (can_write_bytes > 0) {
+    if (!gst_audio_ring_buffer_prepare_read (rb, &segment, &readptr, &len)) {
+      GST_INFO_OBJECT (self, "No segment available, fill silence");
+
+      /* This would be case where in the middle of PAUSED state change.
+       * Just fill silent buffer to avoid immediate I/O callback after
+       * we return here */
+      hr = render_client->GetBuffer (can_write, &data);
+      if (!gst_wasapi2_result (hr))
+        return hr;
+
+      hr = render_client->ReleaseBuffer (can_write, AUDCLNT_BUFFERFLAGS_SILENT);
+      /* for debugging */
+      gst_wasapi2_result (hr);
+      return hr;
+    }
+
+    len -= priv->segoffset;
+
+    if (len > (gint) can_write_bytes)
+      len = can_write_bytes;
+
+    can_write = len / GST_AUDIO_INFO_BPF (&rb->spec.info);
+    if (can_write == 0)
+      break;
+
+    hr = render_client->GetBuffer (can_write, &data);
+    if (!gst_wasapi2_result (hr))
+      return hr;
+
+    if (force_silence) {
+      hr = render_client->ReleaseBuffer (can_write, AUDCLNT_BUFFERFLAGS_SILENT);
+    } else {
+      if (priv->ctx->is_s24in32)
+        s24lsb_to_s24_msb (data, readptr + priv->segoffset, len);
+      else
+        memcpy (data, readptr + priv->segoffset, len);
+
+      hr = render_client->ReleaseBuffer (can_write, 0);
+    }
+
+    priv->segoffset += len;
+    can_write_bytes -= len;
+
+    if (priv->segoffset == rb->spec.segsize) {
+      gst_audio_ring_buffer_clear (rb, segment);
+      gst_audio_ring_buffer_advance (rb, 1);
+      priv->segoffset = 0;
+    }
+
+    if (!gst_wasapi2_result (hr)) {
+      GST_WARNING_OBJECT (self, "Failed to release buffer");
+      break;
+    }
+  }
+
+  return S_OK;
+}
+
+static HRESULT
+gst_wasapi2_rbuf_process_write_exclusive (GstWasapi2Rbuf * self)
+{
+  auto rb = GST_AUDIO_RING_BUFFER_CAST (self);
+  auto priv = self->priv;
+  HRESULT hr;
+  BYTE *data = nullptr;
+
+  if (!priv->ctx || !priv->ctx->render_client) {
+    GST_ERROR_OBJECT (self, "IAudioRenderClient is not available");
+    return E_FAIL;
+  }
+
+  auto & ctx = priv->ctx;
+  auto client = priv->ctx->client;
+  auto render_client = priv->ctx->render_client;
+
+  auto period_bytes = ctx->exclusive_period_bytes;
+
+  if (ctx->conv) {
+    auto host_bpf = (gsize) GST_AUDIO_INFO_BPF (&ctx->host_info);
+    auto device_bpf = (gsize) GST_AUDIO_INFO_BPF (&ctx->device_info);
+
+    while (ctx->exclusive_staging_filled < period_bytes) {
+      bool processed_any = false;
+      gint segment;
+      guint8 *readptr;
+      gint len;
+
+      /* read data from ringbuffer */
+      if (gst_audio_ring_buffer_prepare_read (rb, &segment, &readptr, &len)) {
+        len -= priv->segoffset;
+        if (len > 0) {
+          auto old = ctx->host_fifo_bytes;
+          ctx->host_fifo.resize (old + (size_t) len);
+          memcpy (ctx->host_fifo.data () + old, readptr + priv->segoffset,
+              (size_t) len);
+          ctx->host_fifo_bytes += (size_t) len;
+          processed_any = true;
+
+          priv->segoffset += len;
+          if (priv->segoffset == rb->spec.segsize) {
+            gst_audio_ring_buffer_clear (rb, segment);
+            gst_audio_ring_buffer_advance (rb, 1);
+            priv->segoffset = 0;
+          }
+        }
+      }
+
+      /* do conversion */
+      {
+        auto host_frames_avail = (gsize) (ctx->host_fifo_bytes / host_bpf);
+        if (host_frames_avail > 0) {
+          auto out_frames =
+              gst_audio_converter_get_out_frames (ctx->conv, host_frames_avail);
+          if (out_frames > 0) {
+            auto out_bytes = (size_t) (out_frames * device_bpf);
+            priv->temp_data.resize (out_bytes);
+
+            gpointer in_planes[1] = { ctx->host_fifo.data () };
+            gpointer out_planes[1] = { priv->temp_data.data () };
+
+            if (!gst_audio_converter_samples (ctx->conv,
+                    GST_AUDIO_CONVERTER_FLAG_NONE,
+                    in_planes, host_frames_avail, out_planes, out_frames)) {
+              GST_ERROR_OBJECT (self, "gst_audio_converter_samples() failed");
+              return E_FAIL;
+            }
+
+            auto consumed_host = (size_t) (host_frames_avail * host_bpf);
+            if (consumed_host < ctx->host_fifo_bytes) {
+              memmove (ctx->host_fifo.data (),
+                  ctx->host_fifo.data () + consumed_host,
+                  ctx->host_fifo_bytes - consumed_host);
+            }
+            ctx->host_fifo_bytes -= consumed_host;
+            ctx->host_fifo.resize (ctx->host_fifo_bytes);
+
+            auto old_dev = ctx->device_fifo_bytes;
+            ctx->device_fifo.resize (old_dev + out_bytes);
+
+            if (ctx->is_s24in32) {
+              s24lsb_to_s24_msb (ctx->device_fifo.data () +
+                  old_dev, priv->temp_data.data (), out_bytes);
+            } else {
+              memcpy (ctx->device_fifo.data () + old_dev,
+                  priv->temp_data.data (), out_bytes);
+            }
+
+            ctx->device_fifo_bytes += out_bytes;
+
+            processed_any = true;
+          }
+        }
+      }
+
+      /* move device fifo to staging */
+      if (ctx->device_fifo_bytes > 0 &&
+          ctx->exclusive_staging_filled < period_bytes) {
+        auto need = period_bytes - ctx->exclusive_staging_filled;
+        auto to_copy = MIN (need, ctx->device_fifo_bytes);
+
+        memcpy (ctx->exclusive_staging.data () + ctx->exclusive_staging_filled,
+            ctx->device_fifo.data (), to_copy);
+        ctx->exclusive_staging_filled += to_copy;
+
+        if (to_copy < ctx->device_fifo_bytes) {
+          memmove (ctx->device_fifo.data (),
+              ctx->device_fifo.data () + to_copy,
+              ctx->device_fifo_bytes - to_copy);
+        }
+
+        ctx->device_fifo_bytes -= to_copy;
+        ctx->device_fifo.resize (ctx->device_fifo_bytes);
+
+        if (to_copy > 0)
+          processed_any = true;
+      }
+
+      if (!processed_any)
+        break;
+
+      if (ctx->exclusive_staging_filled >= period_bytes)
+        break;
+    }
+  } else {
+    while (ctx->exclusive_staging_filled < period_bytes) {
+      gint segment;
+      guint8 *readptr;
+      gint len;
+
+      if (!gst_audio_ring_buffer_prepare_read (rb, &segment, &readptr, &len))
+        break;
+
+      len -= priv->segoffset;
+      if (len <= 0)
+        break;
+
+      auto remain = period_bytes - ctx->exclusive_staging_filled;
+      auto to_copy = (size_t) MIN ((gsize) len, (gsize) remain);
+
+      if (ctx->is_s24in32) {
+        s24lsb_to_s24_msb (ctx->exclusive_staging.data () +
+            ctx->exclusive_staging_filled, readptr + priv->segoffset, to_copy);
+      } else {
+        memcpy (ctx->exclusive_staging.data () + ctx->exclusive_staging_filled,
+            readptr + priv->segoffset, to_copy);
+      }
+
+      priv->segoffset += (gint) to_copy;
+      ctx->exclusive_staging_filled += to_copy;
+
+      if (priv->segoffset == rb->spec.segsize) {
+        gst_audio_ring_buffer_clear (rb, segment);
+        gst_audio_ring_buffer_advance (rb, 1);
+        priv->segoffset = 0;
+      }
+
+      if (ctx->exclusive_staging_filled >= period_bytes)
+        break;
+    }
+  }
+
+  hr = render_client->GetBuffer (ctx->period, &data);
+  if (!gst_wasapi2_result (hr))
+    return hr;
+
+  GST_LOG_OBJECT (self, "Writing %d frames offset at %" G_GUINT64_FORMAT,
+      (guint) ctx->period, priv->write_frame_offset);
+  priv->write_frame_offset += ctx->period;
+
+  if (ctx->exclusive_staging_filled < ctx->exclusive_period_bytes) {
+    GST_LOG_OBJECT (self, "Staging buffer not filled %d < %d",
+        (guint) ctx->exclusive_staging_filled,
+        (guint) ctx->exclusive_period_bytes);
+    hr = render_client->ReleaseBuffer (ctx->period, AUDCLNT_BUFFERFLAGS_SILENT);
+    gst_wasapi2_result (hr);
+  } else {
+    if (priv->mute) {
+      hr = ctx->render_client->ReleaseBuffer (ctx->period,
+          AUDCLNT_BUFFERFLAGS_SILENT);
+    } else {
+      memcpy (data, ctx->exclusive_staging.data (),
+          ctx->exclusive_period_bytes);
+      hr = ctx->render_client->ReleaseBuffer (ctx->period, 0);
+    }
+
+    gst_wasapi2_result (hr);
+    ctx->exclusive_staging_filled = 0;
+  }
+
+  return S_OK;
+}
+
+static HRESULT
+fill_loopback_silence (GstWasapi2Rbuf * self)
+{
+  auto priv = self->priv;
+  HRESULT hr;
+  guint32 padding_frames = 0;
+  guint32 can_write;
+  BYTE *data = nullptr;
+
+  if (!priv->ctx || !priv->ctx->dummy_client || !priv->ctx->render_client) {
+    GST_ERROR_OBJECT (self, "IAudioRenderClient is not available");
+    return E_FAIL;
+  }
+
+  auto client = priv->ctx->dummy_client;
+  auto render_client = priv->ctx->render_client;
+
+  hr = client->GetCurrentPadding (&padding_frames);
+  if (!gst_wasapi2_result (hr))
+    return hr;
+
+  if (padding_frames >= priv->ctx->dummy_buf_size) {
+    GST_INFO_OBJECT (self,
+        "Padding size %d is larger than or equal to buffer size %d",
+        padding_frames, priv->ctx->dummy_buf_size);
+    return S_OK;
+  }
+
+  can_write = priv->ctx->dummy_buf_size - padding_frames;
+
+  GST_TRACE_OBJECT (self, "Writing %d silent frames", can_write);
+
+  hr = render_client->GetBuffer (can_write, &data);
+  if (!gst_wasapi2_result (hr))
+    return hr;
+
+  hr = render_client->ReleaseBuffer (can_write, AUDCLNT_BUFFERFLAGS_SILENT);
+  return gst_wasapi2_result (hr);
+}
+
+static gboolean
+gst_wasapi2_rbuf_process_acquire (GstWasapi2Rbuf * self,
+    GstAudioRingBufferSpec * spec)
+{
+  auto buf = GST_AUDIO_RING_BUFFER (self);
+  auto priv = self->priv;
+
+  guint client_buf_size = 0;
+  gint period_frames = 480;
+
+  auto rbuf_caps = gst_audio_info_to_caps (&spec->info);
+  if (!rbuf_caps) {
+    GST_ERROR_OBJECT (self, "Couldn't get caps from info");
+    return FALSE;
+  }
+
+  GST_DEBUG_OBJECT (self, "Acquire with caps %" GST_PTR_FORMAT, rbuf_caps);
+
+  gst_wasapi2_clear_wfx (&priv->mix_format);
+
+  if (priv->ctx) {
+    if (!priv->ctx->init_done) {
+      WAVEFORMATEX *matching = nullptr;
+      for (guint i = 0; i < priv->ctx->formats->len && !matching; i++) {
+        GstCaps *format_caps = nullptr;
+        auto format =
+            (WAVEFORMATEX *) g_ptr_array_index (priv->ctx->formats, i);
+        gst_wasapi2_util_parse_waveformatex (format, &format_caps, nullptr);
+        if (!format_caps)
+          continue;
+
+        if (gst_caps_can_intersect (rbuf_caps, format_caps))
+          matching = gst_wasapi2_copy_wfx (format);
+
+        gst_caps_unref (format_caps);
+      }
+
+      if (!matching)
+        matching = gst_wasapi2_audio_info_to_wfx (&spec->info);
+
+      if (!matching) {
+        GST_ERROR_OBJECT (self, "Couldn't build wave format from caps %"
+            GST_PTR_FORMAT, rbuf_caps);
+        gst_clear_caps (&rbuf_caps);
+        return FALSE;
+      }
+
+      auto ret = gst_wasapi2_rbuf_ctx_init (priv->ctx, matching);
+      gst_wasapi2_free_wfx (matching);
+
+      if (!ret) {
+        GST_WARNING_OBJECT (self, "Couldn't initialize ctx");
+        gst_wasapi2_rbuf_post_open_error (self, priv->device_id.c_str ());
+
+        if (!priv->configured_allow_dummy)
+          return FALSE;
+
+        priv->ctx = nullptr;
+      } else {
+        client_buf_size = priv->ctx->client_buf_size;
+        period_frames = priv->ctx->period;
+      }
+    } else {
+      client_buf_size = priv->ctx->client_buf_size;
+      period_frames = priv->ctx->period;
+    }
+  }
+
+  if (priv->ctx)
+    priv->mix_format = gst_wasapi2_copy_wfx (priv->ctx->mix_format);
+  else
+    priv->mix_format = gst_wasapi2_audio_info_to_wfx (&spec->info);
+
+  gst_clear_caps (&rbuf_caps);
+
+  gint bpf = GST_AUDIO_INFO_BPF (&buf->spec.info);
+  gint rate = GST_AUDIO_INFO_RATE (&buf->spec.info);
+  gint target_frames = rate / 2;        /* 500ms duration */
+
+  gint segtotal = (target_frames + period_frames - 1) / period_frames;
+  spec->segsize = period_frames * bpf;
+  spec->segtotal = MAX (segtotal, 2);
+
+  /* Since we allocates large buffer (large segtotal) for device switching,
+   * update seglatency to reasonable value */
+  spec->seglatency = 2;
+
+  GST_INFO_OBJECT (self,
+      "Buffer size: %d frames, period: %d frames, segsize: %d bytes, "
+      "segtotal: %d", client_buf_size, period_frames,
+      spec->segsize, spec->segtotal);
+
+  GstAudioChannelPosition *position = nullptr;
+  gst_wasapi2_util_waveformatex_to_channel_mask (priv->mix_format, &position);
+  if (position)
+    gst_audio_ring_buffer_set_channel_positions (buf, position);
+  g_free (position);
+
+  buf->size = spec->segtotal * spec->segsize;
+  buf->memory = (guint8 *) g_malloc (buf->size);
+  gst_audio_format_info_fill_silence (buf->spec.info.finfo,
+      buf->memory, buf->size);
+
+  return TRUE;
+}
+
+static HRESULT
+gst_wasapi2_rbuf_process_release (GstWasapi2Rbuf * self)
+{
+  auto buf = GST_AUDIO_RING_BUFFER (self);
+
+  g_clear_pointer (&buf->memory, g_free);
+
+  return S_OK;
+}
+
+static void
+gst_wasapi2_rbuf_start_fallback_timer (GstWasapi2Rbuf * self)
+{
+  auto rb = GST_AUDIO_RING_BUFFER_CAST (self);
+  auto priv = self->priv;
+
+  if (priv->fallback_timer_armed || !priv->configured_allow_dummy)
+    return;
+
+  GST_DEBUG_OBJECT (self, "Start fallback timer");
+
+  auto period_frames = rb->spec.segsize / GST_AUDIO_INFO_BPF (&rb->spec.info);
+  UINT64 period_100ns = (10000000ULL * period_frames) /
+      GST_AUDIO_INFO_RATE (&rb->spec.info);
+
+  LARGE_INTEGER due_time;
+  due_time.QuadPart = -static_cast < LONGLONG > (period_100ns);
+
+  SetWaitableTimer (priv->fallback_timer,
+      &due_time,
+      static_cast < LONG > (period_100ns / 10000), nullptr, nullptr, FALSE);
+
+  QueryPerformanceCounter (&priv->fallback_qpc_base);
+  priv->fallback_frames_processed = 0;
+  priv->fallback_timer_armed = true;
+}
+
+static void
+gst_wasapi2_rbuf_stop_fallback_timer (GstWasapi2Rbuf * self)
+{
+  auto priv = self->priv;
+
+  if (!priv->fallback_timer_armed)
+    return;
+
+  GST_DEBUG_OBJECT (self, "Stop fallback timer");
+
+  CancelWaitableTimer (priv->fallback_timer);
+  priv->fallback_timer_armed = false;
+}
+
+static void
+gst_wasapi2_rbuf_start_monitor_timer (GstWasapi2Rbuf * self)
+{
+  auto priv = self->priv;
+
+  if (priv->monitor_timer_armed)
+    return;
+
+  GST_DEBUG_OBJECT (self, "Start monitor timer");
+
+  /* Run 15ms timer to monitor device status */
+  LARGE_INTEGER due_time;
+  due_time.QuadPart = -1500000LL;
+
+  SetWaitableTimer (priv->monitor_timer,
+      &due_time, 15, nullptr, nullptr, FALSE);
+
+  priv->monitor_timer_armed = true;
+}
+
+static void
+gst_wasapi2_rbuf_stop_monitor_timer (GstWasapi2Rbuf * self)
+{
+  auto priv = self->priv;
+
+  if (!priv->monitor_timer_armed)
+    return;
+
+  GST_DEBUG_OBJECT (self, "Stop monitor timer");
+
+  CancelWaitableTimer (priv->monitor_timer);
+  priv->monitor_timer_armed = false;
+}
+
+static HRESULT
+gst_wasapi2_rbuf_process_start (GstWasapi2Rbuf * self, gboolean reset_offset)
+{
+  auto priv = self->priv;
+
+  if (!priv->ctx && !priv->configured_allow_dummy) {
+    GST_WARNING_OBJECT (self, "No context to start");
+    return E_FAIL;
+  }
+
+  if (priv->running)
+    return S_OK;
+
+  priv->is_first = true;
+  if (reset_offset)
+    priv->segoffset = 0;
+  priv->write_frame_offset = 0;
+  priv->expected_position = 0;
+
+  if (priv->ctx) {
+    priv->ctx->exclusive_staging_filled = 0;
+    priv->ctx->device_fifo_bytes = 0;
+    priv->ctx->host_fifo_bytes = 0;
+    priv->ctx->device_fifo.clear ();
+    priv->ctx->host_fifo.clear ();
+
+    if (priv->ctx->conv)
+      gst_audio_converter_reset (priv->ctx->conv);
+
+    auto hr = priv->ctx->Start ();
+
+    if (!gst_wasapi2_result (hr)) {
+      GST_WARNING_OBJECT (self, "Couldn't start device");
+      gst_wasapi2_rbuf_post_open_error (self, priv->ctx->device_id.c_str ());
+      if (!priv->configured_allow_dummy)
+        return hr;
+
+      gst_wasapi2_rbuf_start_fallback_timer (self);
+    }
+  } else {
+    gst_wasapi2_rbuf_start_fallback_timer (self);
+  }
+
+  gst_wasapi2_rbuf_start_monitor_timer (self);
+  priv->running = true;
+
+  return S_OK;
+}
+
+static HRESULT
+gst_wasapi2_rbuf_process_stop (GstWasapi2Rbuf * self)
+{
+  auto priv = self->priv;
+  HRESULT hr = S_OK;
+
+  if (priv->ctx)
+    hr = priv->ctx->Stop ();
+
+  priv->running = false;
+  priv->is_first = true;
+  priv->segoffset = 0;
+  priv->write_frame_offset = 0;
+  priv->expected_position = 0;
+
+  gst_wasapi2_rbuf_stop_fallback_timer (self);
+  gst_wasapi2_rbuf_stop_monitor_timer (self);
+
+  return hr;
+}
+
+static void
+gst_wasapi2_rbuf_discard_frames (GstWasapi2Rbuf * self, guint frames)
+{
+  auto rb = GST_AUDIO_RING_BUFFER_CAST (self);
+  auto priv = self->priv;
+  guint len = frames * GST_AUDIO_INFO_BPF (&rb->spec.info);
+
+  while (len > 0) {
+    gint seg;
+    guint8 *ptr;
+    gint avail;
+
+    if (!gst_audio_ring_buffer_prepare_read (rb, &seg, &ptr, &avail))
+      return;
+
+    avail -= priv->segoffset;
+    gint to_consume = MIN ((gint) len, avail);
+
+    priv->segoffset += to_consume;
+    len -= to_consume;
+
+    if (priv->segoffset == rb->spec.segsize) {
+      gst_audio_ring_buffer_clear (rb, seg);
+      gst_audio_ring_buffer_advance (rb, 1);
+      priv->segoffset = 0;
+    }
+  }
+}
+
+static void
+gst_wasapi2_rbuf_insert_silence_frames (GstWasapi2Rbuf * self, guint frames)
+{
+  auto rb = GST_AUDIO_RING_BUFFER_CAST (self);
+  auto priv = self->priv;
+  guint bpf = GST_AUDIO_INFO_BPF (&rb->spec.info);
+  guint len = frames * bpf;
+
+  while (len > 0) {
+    gint segment;
+    guint8 *writeptr;
+    gint avail;
+
+    if (!gst_audio_ring_buffer_prepare_read (rb, &segment, &writeptr, &avail))
+      break;
+
+    avail -= priv->segoffset;
+    gint to_write = MIN ((gint) len, avail);
+
+    gst_audio_format_info_fill_silence (rb->spec.info.finfo,
+        writeptr + priv->segoffset, to_write);
+
+    priv->segoffset += to_write;
+    len -= to_write;
+
+    if (priv->segoffset == rb->spec.segsize) {
+      gst_audio_ring_buffer_advance (rb, 1);
+      priv->segoffset = 0;
+    }
+  }
+}
+
+static gpointer
+gst_wasapi2_rbuf_loop_thread (GstWasapi2Rbuf * self)
+{
+  auto priv = self->priv;
+  DWORD task_idx = 0;
+  auto task_handle = AvSetMmThreadCharacteristicsW (L"Pro Audio", &task_idx);
+
+  CoInitializeEx (nullptr, COINIT_MULTITHREADED);
+
+  bool loop_running = true;
+
+  /* Dummy event handles for IO events can have higher priority than user commands */
+  auto dummy_render = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+  auto dummy_capture = CreateEvent (nullptr, FALSE, FALSE, nullptr);
+
+  priv->fallback_timer = CreateWaitableTimerExW (nullptr,
+      nullptr, CREATE_WAITABLE_TIMER_HIGH_RESOLUTION, TIMER_ALL_ACCESS);
+
+  if (!priv->fallback_timer) {
+    GST_WARNING_OBJECT (self,
+        "High-resolution timer not available, using default");
+    priv->fallback_timer = CreateWaitableTimer (nullptr, FALSE, nullptr);
+  }
+
+  /* Another timer to detect device-removed state, since I/O event
+   * would not be singalled on device-removed state */
+  priv->monitor_timer = CreateWaitableTimer (nullptr, FALSE, nullptr);
+
+  HANDLE waitables[] = { dummy_render, dummy_capture,
+    priv->fallback_timer, priv->monitor_timer, priv->command_handle
+  };
+
+  GST_DEBUG_OBJECT (self, "Entering loop");
+
+  auto default_format = gst_wasapi2_get_default_mix_format ();
+  GstCaps *default_caps;
+  gst_wasapi2_util_parse_waveformatex (default_format, &default_caps, nullptr);
+
+  while (loop_running) {
+    auto wait_ret = WaitForMultipleObjects (G_N_ELEMENTS (waitables),
+        waitables, FALSE, INFINITE);
+
+    switch (wait_ret) {
+      case WAIT_OBJECT_0:
+        if (priv->running) {
+          HRESULT hr = S_OK;
+          if (priv->ctx->endpoint_class ==
+              GST_WASAPI2_ENDPOINT_CLASS_LOOPBACK_CAPTURE) {
+            hr = fill_loopback_silence (self);
+            if (SUCCEEDED (hr))
+              hr = gst_wasapi2_rbuf_process_read (self);
+          } else {
+            if (priv->ctx->is_exclusive)
+              hr = gst_wasapi2_rbuf_process_write_exclusive (self);
+            else
+              hr = gst_wasapi2_rbuf_process_write (self);
+          }
+
+          if (FAILED (hr)) {
+            gst_wasapi2_rbuf_post_io_error (self, hr, TRUE);
+            gst_wasapi2_rbuf_start_fallback_timer (self);
+          }
+        }
+        break;
+      case WAIT_OBJECT_0 + 1:
+        if (priv->running) {
+          auto hr = gst_wasapi2_rbuf_process_read (self);
+          if ((hr == AUDCLNT_E_ENDPOINT_CREATE_FAILED ||
+                  hr == AUDCLNT_E_DEVICE_INVALIDATED) && priv->ctx->is_default
+              && !gst_wasapi2_is_loopback_class (priv->ctx->endpoint_class)) {
+            GST_WARNING_OBJECT (self,
+                "Device was unplugged but client can support automatic routing");
+            hr = S_OK;
+          }
+
+          if (FAILED (hr)) {
+            gst_wasapi2_rbuf_post_io_error (self, hr, FALSE);
+            gst_wasapi2_rbuf_start_fallback_timer (self);
+          }
+        }
+        break;
+      case WAIT_OBJECT_0 + 2:
+      {
+        if (!priv->running || !priv->fallback_timer_armed)
+          break;
+
+        LARGE_INTEGER qpc_now;
+        QueryPerformanceCounter (&qpc_now);
+
+        LONGLONG elapsed = qpc_now.QuadPart - priv->fallback_qpc_base.QuadPart;
+        UINT64 elapsed_100ns = elapsed * 10000000ULL / priv->qpc_freq.QuadPart;
+        auto rb = GST_AUDIO_RING_BUFFER_CAST (self);
+        UINT32 rate = GST_AUDIO_INFO_RATE (&rb->spec.info);
+        UINT64 expected_frames = (elapsed_100ns * rate) / 10000000ULL;
+        UINT64 delta = expected_frames - priv->fallback_frames_processed;
+
+        if (delta > 0) {
+          GST_TRACE_OBJECT (self,
+              "procssing fallback %u frames", (guint) delta);
+
+          if (priv->endpoint_class == GST_WASAPI2_ENDPOINT_CLASS_RENDER)
+            gst_wasapi2_rbuf_discard_frames (self, (guint) delta);
+          else
+            gst_wasapi2_rbuf_insert_silence_frames (self, (guint) delta);
+
+          priv->fallback_frames_processed += delta;
+        }
+
+        break;
+      }
+      case WAIT_OBJECT_0 + 3:
+      {
+        if (!priv->running || !priv->ctx || !priv->monitor_timer_armed)
+          break;
+
+        UINT32 dummy;
+        auto hr = priv->ctx->client->GetCurrentPadding (&dummy);
+        if (hr == AUDCLNT_E_DEVICE_INVALIDATED && !priv->ctx->error_posted) {
+          priv->ctx->error_posted = true;
+          gst_wasapi2_rbuf_post_io_error (self, AUDCLNT_E_DEVICE_INVALIDATED,
+              priv->endpoint_class == GST_WASAPI2_ENDPOINT_CLASS_RENDER);
+          gst_wasapi2_rbuf_start_fallback_timer (self);
+        }
+
+        break;
+      }
+      case WAIT_OBJECT_0 + 4:
+        /* Wakeup event for event processing */
+        break;
+      default:
+        GST_WARNING_OBJECT (self,
+            "Unexpected wait return 0x%x", (guint) wait_ret);
+        loop_running = false;
+        break;
+    }
+
+    /* Process events */
+    {
+      std::unique_lock < std::mutex > lk (priv->lock);
+      while (!priv->cmd_queue.empty ()) {
+        auto cmd = priv->cmd_queue.front ();
+        priv->cmd_queue.pop ();
+        lk.unlock ();
+
+        auto cmd_name = command_type_to_string (cmd->type);
+        GST_DEBUG_OBJECT (self, "Got command %s", cmd_name);
+        switch (cmd->type) {
+          case CommandType::Shutdown:
+            loop_running = false;
+            cmd->hr = S_OK;
+            SetEvent (cmd->event_handle);
+            break;
+          case CommandType::SetDevice:
+          {
+            auto scmd = std::dynamic_pointer_cast < CommandSetDevice > (cmd);
+            priv->device_id = scmd->device_id;
+            priv->endpoint_class = scmd->endpoint_class;
+            priv->pid = scmd->pid;
+            priv->low_latency = scmd->low_latency;
+            priv->exclusive = scmd->exclusive;
+
+            if (priv->opened) {
+              GST_DEBUG_OBJECT (self,
+                  "Have opened device, creating context asynchronously");
+              gst_wasapi2_rbuf_create_ctx_async (self);
+            }
+
+            cmd->hr = S_OK;
+            SetEvent (cmd->event_handle);
+            break;
+          }
+          case CommandType::UpdateDevice:
+          {
+            auto ucmd = std::dynamic_pointer_cast < CommandUpdateDevice > (cmd);
+            if (priv->opened) {
+              GST_DEBUG_OBJECT (self, "Updating device");
+
+              gst_wasapi2_rbuf_stop_fallback_timer (self);
+
+              priv->ctx = ucmd->ctx;
+
+              if (priv->ctx && !priv->ctx->init_done && priv->mix_format) {
+                if (!gst_wasapi2_rbuf_ctx_init (priv->ctx, priv->mix_format)) {
+                  GST_WARNING_OBJECT (self, "Couldn't initialize context");
+                  priv->ctx = nullptr;
+                }
+              }
+
+              if (priv->ctx) {
+                waitables[0] = priv->ctx->render_event;
+                waitables[1] = priv->ctx->capture_event;
+
+                if (priv->mute)
+                  priv->ctx->SetVolume (0);
+                else
+                  priv->ctx->SetVolume (priv->volume);
+              } else {
+                waitables[0] = dummy_render;
+                waitables[1] = dummy_capture;
+
+                gst_wasapi2_rbuf_post_open_error (self,
+                    ucmd->device_id.c_str ());
+                if (!priv->configured_allow_dummy) {
+                  SetEvent (cmd->event_handle);
+                  break;
+                }
+              }
+
+              if (priv->running) {
+                priv->running = false;
+                gst_wasapi2_rbuf_process_start (self, FALSE);
+              }
+            }
+            SetEvent (cmd->event_handle);
+            break;
+          }
+          case CommandType::Open:
+            priv->configured_allow_dummy = priv->allow_dummy;
+            gst_wasapi2_clear_wfx (&priv->mix_format);
+            priv->ctx = gst_wasapi2_rbuf_create_ctx (self);
+
+            if (priv->ctx) {
+              waitables[0] = priv->ctx->render_event;
+              waitables[1] = priv->ctx->capture_event;
+              gst_caps_replace (&priv->caps, priv->ctx->supported_caps);
+
+              priv->opened = true;
+              cmd->hr = S_OK;
+            } else {
+              gst_clear_caps (&priv->caps);
+              waitables[0] = dummy_render;
+              waitables[1] = dummy_capture;
+              gst_wasapi2_rbuf_post_open_error (self, priv->device_id.c_str ());
+
+              if (priv->configured_allow_dummy) {
+                gst_caps_replace (&priv->caps, default_caps);
+
+                priv->opened = true;
+                cmd->hr = S_OK;
+              } else {
+                cmd->hr = E_FAIL;
+              }
+            }
+            SetEvent (cmd->event_handle);
+            break;
+          case CommandType::Close:
+            waitables[0] = dummy_render;
+            waitables[1] = dummy_capture;
+            priv->ctx = nullptr;
+            gst_clear_caps (&priv->caps);
+            cmd->hr = S_OK;
+            SetEvent (cmd->event_handle);
+            priv->opened = false;
+            gst_wasapi2_clear_wfx (&priv->mix_format);
+            gst_wasapi2_rbuf_stop_fallback_timer (self);
+            break;
+          case CommandType::Acquire:
+          {
+            auto acquire_cmd =
+                std::dynamic_pointer_cast < CommandAcquire > (cmd);
+
+            if (!priv->ctx) {
+              priv->ctx = gst_wasapi2_rbuf_create_ctx (self);
+              if (!priv->ctx) {
+                GST_WARNING_OBJECT (self, "No context configured");
+                gst_wasapi2_rbuf_post_open_error (self,
+                    priv->device_id.c_str ());
+                if (!priv->configured_allow_dummy) {
+                  cmd->hr = E_FAIL;
+                  SetEvent (cmd->event_handle);
+                  break;
+                }
+              }
+            }
+
+            if (!gst_wasapi2_rbuf_process_acquire (self, acquire_cmd->spec)) {
+              cmd->hr = E_FAIL;
+              SetEvent (cmd->event_handle);
+              break;
+            }
+
+            priv->opened = true;
+
+            /* Since format selected now, use fixated one */
+            gst_clear_caps (&priv->caps);
+            gst_wasapi2_util_parse_waveformatex (priv->mix_format,
+                &priv->caps, nullptr);
+
+            if (priv->ctx) {
+              waitables[0] = priv->ctx->render_event;
+              waitables[1] = priv->ctx->capture_event;
+
+              if (priv->mute)
+                priv->ctx->SetVolume (0);
+              else
+                priv->ctx->SetVolume (priv->volume);
+            } else {
+              waitables[0] = dummy_render;
+              waitables[1] = dummy_capture;
+            }
+
+            cmd->hr = S_OK;
+            SetEvent (cmd->event_handle);
+            break;
+          }
+          case CommandType::Release:
+            cmd->hr = gst_wasapi2_rbuf_process_release (self);
+            gst_wasapi2_rbuf_stop_fallback_timer (self);
+            SetEvent (cmd->event_handle);
+            break;
+          case CommandType::Start:
+            cmd->hr = gst_wasapi2_rbuf_process_start (self, TRUE);
+            SetEvent (cmd->event_handle);
+            break;
+          case CommandType::Stop:
+            cmd->hr = gst_wasapi2_rbuf_process_stop (self);
+            SetEvent (cmd->event_handle);
+            break;
+          case CommandType::GetCaps:
+          {
+            auto caps_cmd = std::dynamic_pointer_cast < CommandGetCaps > (cmd);
+            if (priv->caps)
+              caps_cmd->caps = gst_caps_ref (priv->caps);
+
+            SetEvent (cmd->event_handle);
+            break;
+          }
+          case CommandType::UpdateVolume:
+            if (priv->ctx) {
+              if (priv->mute)
+                priv->ctx->SetVolume (0);
+              else
+                priv->ctx->SetVolume (priv->volume);
+            }
+            SetEvent (cmd->event_handle);
+            break;
+          default:
+            g_assert_not_reached ();
+            break;
+        }
+        GST_DEBUG_OBJECT (self, "command %s processed", cmd_name);
+        lk.lock ();
+      }
+    }
+  }
+
+  gst_wasapi2_free_wfx (default_format);
+  gst_clear_caps (&default_caps);
+  priv->ctx = nullptr;
+  priv->cmd_queue = { };
+  gst_wasapi2_clear_wfx (&priv->mix_format);
+
+  CoUninitialize ();
+
+  if (task_handle)
+    AvRevertMmThreadCharacteristics (task_handle);
+
+  GST_DEBUG_OBJECT (self, "Exit loop");
+
+  CloseHandle (dummy_render);
+  CloseHandle (dummy_capture);
+
+  CancelWaitableTimer (priv->monitor_timer);
+  CloseHandle (priv->monitor_timer);
+
+  CancelWaitableTimer (priv->fallback_timer);
+  CloseHandle (priv->fallback_timer);
+
+  return nullptr;
+}
+
+static guint
+gst_wasapi2_rbuf_delay (GstAudioRingBuffer * buf)
+{
+  /* NOTE: WASAPI supports GetCurrentPadding() method for querying
+   * currently unread buffer size, but it doesn't seem to be quite useful
+   * here because:
+   *
+   * In case of capture client, GetCurrentPadding() will return the number of
+   * unread frames which will be identical to pNumFramesToRead value of
+   * IAudioCaptureClient::GetBuffer()'s return. Since we are running on
+   * event-driven mode and whenever available, WASAPI will notify signal
+   * so it's likely zero at this moment. And there is a chance to
+   * return incorrect value here because our IO callback happens from
+   * other thread.
+   *
+   * And render client's padding size will return the total size of buffer
+   * which is likely larger than twice of our period. Which doesn't represent
+   * the amount queued frame size in device correctly
+   */
+  return 0;
+}
+
+GstWasapi2Rbuf *
+gst_wasapi2_rbuf_new (gpointer parent, GstWasapi2RbufCallback callback)
+{
+  auto self = (GstWasapi2Rbuf *) g_object_new (GST_TYPE_WASAPI2_RBUF, nullptr);
+  gst_object_ref_sink (self);
+
+  auto priv = self->priv;
+  priv->invalidated_cb = callback;
+  g_weak_ref_set (&priv->parent, parent);
+  priv->thread = g_thread_new ("GstWasapi2Rbuf",
+      (GThreadFunc) gst_wasapi2_rbuf_loop_thread, self);
+
+  return self;
+}
+
+void
+gst_wasapi2_rbuf_set_device (GstWasapi2Rbuf * rbuf, const gchar * device_id,
+    GstWasapi2EndpointClass endpoint_class, guint pid, gboolean low_latency,
+    gboolean exclusive)
+{
+  auto cmd = std::make_shared < CommandSetDevice > ();
+
+  if (device_id)
+    cmd->device_id = device_id;
+  cmd->endpoint_class = endpoint_class;
+  cmd->pid = pid;
+  cmd->low_latency = low_latency;
+  cmd->exclusive = exclusive;
+
+  gst_wasapi2_rbuf_push_command (rbuf, cmd);
+
+  WaitForSingleObject (cmd->event_handle, INFINITE);
+}
+
+GstCaps *
+gst_wasapi2_rbuf_get_caps (GstWasapi2Rbuf * rbuf)
+{
+  auto cmd = std::make_shared < CommandGetCaps > ();
+
+  gst_wasapi2_rbuf_push_command (rbuf, cmd);
+  WaitForSingleObject (cmd->event_handle, INFINITE);
+
+  return cmd->caps;
+}
+
+void
+gst_wasapi2_rbuf_set_mute (GstWasapi2Rbuf * rbuf, gboolean mute)
+{
+  auto priv = rbuf->priv;
+
+  priv->mute = mute;
+
+  auto cmd = std::make_shared < CommandData > (CommandType::UpdateVolume);
+
+  gst_wasapi2_rbuf_push_command (rbuf, cmd);
+}
+
+gboolean
+gst_wasapi2_rbuf_get_mute (GstWasapi2Rbuf * rbuf)
+{
+  auto priv = rbuf->priv;
+
+  return priv->mute.load ();
+}
+
+void
+gst_wasapi2_rbuf_set_volume (GstWasapi2Rbuf * rbuf, gdouble volume)
+{
+  auto priv = rbuf->priv;
+
+  priv->volume = (float) volume;
+
+  auto cmd = std::make_shared < CommandData > (CommandType::UpdateVolume);
+
+  gst_wasapi2_rbuf_push_command (rbuf, cmd);
+}
+
+gdouble
+gst_wasapi2_rbuf_get_volume (GstWasapi2Rbuf * rbuf)
+{
+  auto priv = rbuf->priv;
+
+  return (gdouble) priv->volume.load ();
+}
+
+void
+gst_wasapi2_rbuf_set_device_mute_monitoring (GstWasapi2Rbuf * rbuf,
+    gboolean value)
+{
+  auto priv = rbuf->priv;
+
+  priv->monitor_device_mute.store (value, std::memory_order_release);
+}
+
+void
+gst_wasapi2_rbuf_set_continue_on_error (GstWasapi2Rbuf * rbuf, gboolean value)
+{
+  auto priv = rbuf->priv;
+
+  priv->allow_dummy = value;
+}
diff --git a/sys/wasapi2/gstwasapi2rbuf.h b/sys/wasapi2/gstwasapi2rbuf.h
new file mode 100644
index 0000000..803315b
--- /dev/null
+++ b/sys/wasapi2/gstwasapi2rbuf.h
@@ -0,0 +1,63 @@
+/* GStreamer
+ * Copyright (C) 2025 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#pragma once
+
+#include <gst/gst.h>
+#include <gst/audio/audio.h>
+#include "gstwasapi2util.h"
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_WASAPI2_RBUF (gst_wasapi2_rbuf_get_type())
+G_DECLARE_FINAL_TYPE (GstWasapi2Rbuf, gst_wasapi2_rbuf,
+    GST, WASAPI2_RBUF, GstAudioRingBuffer);
+
+typedef void (*GstWasapi2RbufCallback) (gpointer elem);
+
+GstWasapi2Rbuf * gst_wasapi2_rbuf_new (gpointer parent,
+                                       GstWasapi2RbufCallback callback);
+
+void             gst_wasapi2_rbuf_set_device (GstWasapi2Rbuf * rbuf,
+                                              const gchar * device_id,
+                                              GstWasapi2EndpointClass endpoint_class,
+                                              guint pid,
+                                              gboolean low_latency,
+                                              gboolean exclusive);
+
+GstCaps *        gst_wasapi2_rbuf_get_caps (GstWasapi2Rbuf * rbuf);
+
+void             gst_wasapi2_rbuf_set_mute  (GstWasapi2Rbuf * rbuf,
+                                             gboolean mute);
+
+gboolean         gst_wasapi2_rbuf_get_mute  (GstWasapi2Rbuf * rbuf);
+
+void             gst_wasapi2_rbuf_set_volume (GstWasapi2Rbuf * rbuf,
+                                              gdouble volume);
+
+gdouble          gst_wasapi2_rbuf_get_volume (GstWasapi2Rbuf * rbuf);
+
+void             gst_wasapi2_rbuf_set_device_mute_monitoring (GstWasapi2Rbuf * rbuf,
+                                                              gboolean value);
+
+void             gst_wasapi2_rbuf_set_continue_on_error (GstWasapi2Rbuf * rbuf,
+                                                         gboolean value);
+
+G_END_DECLS
+
diff --git a/sys/wasapi2/gstwasapi2sink.cpp b/sys/wasapi2/gstwasapi2sink.cpp
new file mode 100644
index 0000000..fb4d519
--- /dev/null
+++ b/sys/wasapi2/gstwasapi2sink.cpp
@@ -0,0 +1,402 @@
+/*
+ * Copyright (C) 2008 Ole Andr Vadla Ravns <ole.andre.ravnas@tandberg.com>
+ * Copyright (C) 2013 Collabora Ltd.
+ *   Author: Sebastian Drge <sebastian.droege@collabora.co.uk>
+ * Copyright (C) 2018 Centricular Ltd.
+ *   Author: Nirbheek Chauhan <nirbheek@centricular.com>
+ * Copyright (C) 2020 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+/**
+ * SECTION:element-wasapi2sink
+ * @title: wasapi2sink
+ *
+ * Provides audio playback using the Windows Audio Session API available with
+ * Windows 10.
+ *
+ * ## Example pipelines
+ * |[
+ * gst-launch-1.0 -v audiotestsrc ! wasapi2sink
+ * ]| Generate audio test buffers and render to the default audio device.
+ *
+ * |[
+ * gst-launch-1.0 -v audiotestsink samplesperbuffer=160 ! wasapi2sink low-latency=true
+ * ]| Same as above, but with the minimum possible latency
+ *
+ */
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif
+
+#include "gstwasapi2sink.h"
+#include "gstwasapi2util.h"
+#include "gstwasapi2rbuf.h"
+#include <mutex>
+#include <atomic>
+
+GST_DEBUG_CATEGORY_STATIC (gst_wasapi2_sink_debug);
+#define GST_CAT_DEFAULT gst_wasapi2_sink_debug
+
+static GstStaticPadTemplate sink_template = GST_STATIC_PAD_TEMPLATE ("sink",
+    GST_PAD_SINK,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_WASAPI2_STATIC_CAPS));
+
+#define DEFAULT_LOW_LATENCY   FALSE
+#define DEFAULT_MUTE          FALSE
+#define DEFAULT_VOLUME        1.0
+#define DEFAULT_CONTINUE_ON_ERROR FALSE
+#define DEFAULT_EXCLUSIVE FALSE
+
+enum
+{
+  PROP_0,
+  PROP_DEVICE,
+  PROP_LOW_LATENCY,
+  PROP_MUTE,
+  PROP_VOLUME,
+  PROP_DISPATCHER,
+  PROP_CONTINUE_ON_ERROR,
+  PROP_EXCLUSIVE,
+};
+
+/* *INDENT-OFF* */
+struct GstWasapi2SinkPrivate
+{
+  ~GstWasapi2SinkPrivate ()
+  {
+    gst_object_unref (rbuf);
+    g_free (device_id);
+  }
+
+  GstWasapi2Rbuf *rbuf = nullptr;
+
+  std::mutex lock;
+  std::atomic<bool> device_invalidated = { false };
+
+  /* properties */
+  gchar *device_id = nullptr;;
+  gboolean low_latency = DEFAULT_LOW_LATENCY;
+  gboolean continue_on_error = DEFAULT_CONTINUE_ON_ERROR;
+  gboolean exclusive = DEFAULT_EXCLUSIVE;
+};
+/* *INDENT-ON* */
+
+struct _GstWasapi2Sink
+{
+  GstAudioBaseSink parent;
+
+  GstWasapi2SinkPrivate *priv;
+};
+
+static void gst_wasapi2_sink_finalize (GObject * object);
+static void gst_wasapi2_sink_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec);
+static void gst_wasapi2_sink_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec);
+
+static GstCaps *gst_wasapi2_sink_get_caps (GstBaseSink * bsink,
+    GstCaps * filter);
+static GstAudioRingBuffer *gst_wasapi2_sink_create_ringbuffer (GstAudioBaseSink
+    * sink);
+
+#define gst_wasapi2_sink_parent_class parent_class
+G_DEFINE_TYPE_WITH_CODE (GstWasapi2Sink, gst_wasapi2_sink,
+    GST_TYPE_AUDIO_BASE_SINK,
+    G_IMPLEMENT_INTERFACE (GST_TYPE_STREAM_VOLUME, nullptr));
+
+static void
+gst_wasapi2_sink_class_init (GstWasapi2SinkClass * klass)
+{
+  auto gobject_class = G_OBJECT_CLASS (klass);
+  auto element_class = GST_ELEMENT_CLASS (klass);
+  auto basesink_class = GST_BASE_SINK_CLASS (klass);
+  auto audiobasesink_class = GST_AUDIO_BASE_SINK_CLASS (klass);
+
+  gobject_class->finalize = gst_wasapi2_sink_finalize;
+  gobject_class->set_property = gst_wasapi2_sink_set_property;
+  gobject_class->get_property = gst_wasapi2_sink_get_property;
+
+  g_object_class_install_property (gobject_class, PROP_DEVICE,
+      g_param_spec_string ("device", "Device",
+          "Audio device ID as provided by "
+          "WASAPI device endpoint ID as provided by IMMDevice::GetId",
+          nullptr, (GParamFlags) (GST_PARAM_MUTABLE_READY | G_PARAM_READWRITE |
+              G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (gobject_class, PROP_LOW_LATENCY,
+      g_param_spec_boolean ("low-latency", "Low latency",
+          "Optimize all settings for lowest latency. Always safe to enable.",
+          DEFAULT_LOW_LATENCY, (GParamFlags) (GST_PARAM_MUTABLE_READY |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (gobject_class, PROP_MUTE,
+      g_param_spec_boolean ("mute", "Mute", "Mute state of this stream",
+          DEFAULT_MUTE, (GParamFlags) (GST_PARAM_MUTABLE_PLAYING |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (gobject_class, PROP_VOLUME,
+      g_param_spec_double ("volume", "Volume", "Volume of this stream",
+          0.0, 1.0, DEFAULT_VOLUME,
+          (GParamFlags) (GST_PARAM_MUTABLE_PLAYING | G_PARAM_READWRITE |
+              G_PARAM_STATIC_STRINGS)));
+
+  /**
+   * GstWasapi2Sink:dispatcher:
+   *
+   * ICoreDispatcher COM object used for activating device from UI thread.
+   *
+   * Since: 1.18
+   */
+  g_object_class_install_property (gobject_class, PROP_DISPATCHER,
+      g_param_spec_pointer ("dispatcher", "Dispatcher",
+          "ICoreDispatcher COM object to use. In order for application to ask "
+          "permission of audio device, device activation should be running "
+          "on UI thread via ICoreDispatcher. This element will increase "
+          "the reference count of given ICoreDispatcher and release it after "
+          "use. Therefore, caller does not need to consider additional "
+          "reference count management",
+          (GParamFlags) (GST_PARAM_MUTABLE_READY | G_PARAM_WRITABLE |
+              G_PARAM_STATIC_STRINGS)));
+
+  /**
+   * GstWasapi2Sink:continue-on-error:
+   *
+   * If enabled, wasapi2sink will post a warning message instead of an error,
+   * when device failures occur, such as open failure, I/O error,
+   * or device removal.
+   * The element will continue to consume audio buffers and behave as if
+   * a render device were active, allowing pipeline to keep running even when
+   * no audio endpoint is available
+   *
+   * Since: 1.28
+   */
+  g_object_class_install_property (gobject_class, PROP_CONTINUE_ON_ERROR,
+      g_param_spec_boolean ("continue-on-error", "Continue On Error",
+          "Continue running and consume buffers on device failure",
+          DEFAULT_CONTINUE_ON_ERROR, (GParamFlags) (GST_PARAM_MUTABLE_READY |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  /**
+   * GstWasapi2Sink:exclusive:
+   *
+   * Since: 1.28
+   */
+  g_object_class_install_property (gobject_class, PROP_EXCLUSIVE,
+      g_param_spec_boolean ("exclusive", "Exclusive",
+          "Open the device in exclusive mode",
+          DEFAULT_EXCLUSIVE,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  gst_element_class_add_static_pad_template (element_class, &sink_template);
+  gst_element_class_set_static_metadata (element_class, "Wasapi2Sink",
+      "Sink/Audio/Hardware",
+      "Stream audio to an audio capture device through WASAPI",
+      "Seungha Yang <seungha@centricular.com>");
+
+  basesink_class->get_caps = GST_DEBUG_FUNCPTR (gst_wasapi2_sink_get_caps);
+
+  audiobasesink_class->create_ringbuffer =
+      GST_DEBUG_FUNCPTR (gst_wasapi2_sink_create_ringbuffer);
+
+  GST_DEBUG_CATEGORY_INIT (gst_wasapi2_sink_debug, "wasapi2sink",
+      0, "Windows audio session API sink");
+}
+
+static void
+gst_wasapi2_sink_on_invalidated (gpointer elem)
+{
+  auto self = GST_WASAPI2_SINK (elem);
+  auto priv = self->priv;
+
+  GST_WARNING_OBJECT (self, "Device invalidated");
+
+  priv->device_invalidated = true;
+}
+
+static void
+gst_wasapi2_sink_init (GstWasapi2Sink * self)
+{
+  auto priv = new GstWasapi2SinkPrivate ();
+
+  priv->rbuf = gst_wasapi2_rbuf_new (self, gst_wasapi2_sink_on_invalidated);
+  gst_wasapi2_rbuf_set_device (priv->rbuf, nullptr,
+      GST_WASAPI2_ENDPOINT_CLASS_RENDER, 0, DEFAULT_LOW_LATENCY,
+      DEFAULT_EXCLUSIVE);
+
+  self->priv = priv;
+}
+
+static void
+gst_wasapi2_sink_finalize (GObject * object)
+{
+  auto self = GST_WASAPI2_SINK (object);
+
+  GST_LOG_OBJECT (self, "Finalize");
+
+  delete self->priv;
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+gst_wasapi2_sink_set_device (GstWasapi2Sink * self, bool updated)
+{
+  auto priv = self->priv;
+  bool expected = true;
+  bool set_device = priv->device_invalidated.compare_exchange_strong (expected,
+      false);
+
+  if (!set_device && !updated)
+    return;
+
+  gst_wasapi2_rbuf_set_device (priv->rbuf, priv->device_id,
+      GST_WASAPI2_ENDPOINT_CLASS_RENDER, 0, priv->low_latency, priv->exclusive);
+}
+
+static void
+gst_wasapi2_sink_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  auto self = GST_WASAPI2_SINK (object);
+  auto priv = self->priv;
+
+  std::lock_guard < std::mutex > lk (priv->lock);
+
+  switch (prop_id) {
+    case PROP_DEVICE:
+    {
+      auto new_val = g_value_get_string (value);
+      bool updated = false;
+      if (g_strcmp0 (new_val, priv->device_id) != 0) {
+        g_free (priv->device_id);
+        priv->device_id = g_strdup (new_val);
+        updated = true;
+      }
+
+      gst_wasapi2_sink_set_device (self, updated);
+      break;
+    }
+    case PROP_LOW_LATENCY:
+    {
+      auto new_val = g_value_get_boolean (value);
+      bool updated = false;
+      if (new_val != priv->low_latency) {
+        priv->low_latency = new_val;
+        updated = true;
+      }
+
+      gst_wasapi2_sink_set_device (self, updated);
+      break;
+    }
+    case PROP_MUTE:
+      gst_wasapi2_rbuf_set_mute (priv->rbuf, g_value_get_boolean (value));
+      break;
+    case PROP_VOLUME:
+      gst_wasapi2_rbuf_set_volume (priv->rbuf, g_value_get_double (value));
+      break;
+    case PROP_DISPATCHER:
+      /* Unused */
+      break;
+    case PROP_CONTINUE_ON_ERROR:
+      priv->continue_on_error = g_value_get_boolean (value);
+      gst_wasapi2_rbuf_set_continue_on_error (priv->rbuf,
+          priv->continue_on_error);
+      break;
+    case PROP_EXCLUSIVE:
+    {
+      auto new_val = g_value_get_boolean (value);
+      bool updated = false;
+      if (new_val != priv->exclusive) {
+        priv->exclusive = new_val;
+        updated = true;
+      }
+
+      gst_wasapi2_sink_set_device (self, updated);
+      break;
+    }
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_wasapi2_sink_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  auto self = GST_WASAPI2_SINK (object);
+  auto priv = self->priv;
+
+  std::lock_guard < std::mutex > lk (priv->lock);
+
+  switch (prop_id) {
+    case PROP_DEVICE:
+      g_value_set_string (value, priv->device_id);
+      break;
+    case PROP_LOW_LATENCY:
+      g_value_set_boolean (value, priv->low_latency);
+      break;
+    case PROP_MUTE:
+      g_value_set_boolean (value, gst_wasapi2_rbuf_get_mute (priv->rbuf));
+      break;
+    case PROP_VOLUME:
+      g_value_set_double (value, gst_wasapi2_rbuf_get_volume (priv->rbuf));
+      break;
+    case PROP_CONTINUE_ON_ERROR:
+      g_value_set_boolean (value, priv->continue_on_error);
+      break;
+    case PROP_EXCLUSIVE:
+      g_value_set_boolean (value, priv->exclusive);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static GstCaps *
+gst_wasapi2_sink_get_caps (GstBaseSink * bsink, GstCaps * filter)
+{
+  auto self = GST_WASAPI2_SINK (bsink);
+  auto priv = self->priv;
+  auto caps = gst_wasapi2_rbuf_get_caps (priv->rbuf);
+
+  if (!caps)
+    caps = gst_pad_get_pad_template_caps (bsink->sinkpad);
+
+  if (filter) {
+    GstCaps *filtered =
+        gst_caps_intersect_full (filter, caps, GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (caps);
+    caps = filtered;
+  }
+
+  GST_DEBUG_OBJECT (self, "returning caps %" GST_PTR_FORMAT, caps);
+
+  return caps;
+}
+
+static GstAudioRingBuffer *
+gst_wasapi2_sink_create_ringbuffer (GstAudioBaseSink * sink)
+{
+  auto self = GST_WASAPI2_SINK (sink);
+  auto priv = self->priv;
+
+  return GST_AUDIO_RING_BUFFER (priv->rbuf);
+}
diff --git a/sys/wasapi2/gstwasapi2src.cpp b/sys/wasapi2/gstwasapi2src.cpp
new file mode 100644
index 0000000..33242db
--- /dev/null
+++ b/sys/wasapi2/gstwasapi2src.cpp
@@ -0,0 +1,606 @@
+/*
+ * Copyright (C) 2008 Ole Andr Vadla Ravns <ole.andre.ravnas@tandberg.com>
+ * Copyright (C) 2018 Centricular Ltd.
+ *   Author: Nirbheek Chauhan <nirbheek@centricular.com>
+ * Copyright (C) 2020 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+/**
+ * SECTION:element-wasapi2src
+ * @title: wasapi2src
+ *
+ * Provides audio capture from the Windows Audio Session API available with
+ * Windows 10.
+ *
+ * ## Example pipelines
+ * |[
+ * gst-launch-1.0 -v wasapi2src ! fakesink
+ * ]| Capture from the default audio device and render to fakesink.
+ *
+ * |[
+ * gst-launch-1.0 -v wasapi2src low-latency=true ! fakesink
+ * ]| Capture from the default audio device with the minimum possible latency and render to fakesink.
+ *
+ */
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif
+
+#include "gstwasapi2src.h"
+#include "gstwasapi2util.h"
+#include "gstwasapi2rbuf.h"
+#include <mutex>
+#include <atomic>
+
+GST_DEBUG_CATEGORY_STATIC (gst_wasapi2_src_debug);
+#define GST_CAT_DEFAULT gst_wasapi2_src_debug
+
+static GstStaticPadTemplate src_template = GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_WASAPI2_STATIC_CAPS));
+
+/**
+ * GstWasapi2SrcLoopbackMode:
+ *
+ * Loopback capture mode
+ *
+ * Since: 1.22
+ */
+typedef enum
+{
+  /**
+   * GstWasapi2SrcLoopbackMode::default:
+   *
+   * Default loopback mode
+   *
+   * Since: 1.22
+   */
+  GST_WASAPI2_SRC_LOOPBACK_DEFAULT,
+
+  /**
+   * GstWasapi2SrcLoopbackMode::include-process-tree:
+   *
+   * Captures only specified process and its child process
+   *
+   * Since: 1.22
+   */
+  GST_WASAPI2_SRC_LOOPBACK_INCLUDE_PROCESS_TREE,
+
+  /**
+   * GstWasapi2SrcLoopbackMode::exclude-process-tree:
+   *
+   * Excludes specified process and its child process
+   *
+   * Since: 1.22
+   */
+  GST_WASAPI2_SRC_LOOPBACK_EXCLUDE_PROCESS_TREE,
+} GstWasapi2SrcLoopbackMode;
+
+#define GST_TYPE_WASAPI2_SRC_LOOPBACK_MODE (gst_wasapi2_src_loopback_mode_get_type ())
+static GType
+gst_wasapi2_src_loopback_mode_get_type (void)
+{
+  static GType loopback_type = 0;
+  static const GEnumValue types[] = {
+    {GST_WASAPI2_SRC_LOOPBACK_DEFAULT, "Default", "default"},
+    {GST_WASAPI2_SRC_LOOPBACK_INCLUDE_PROCESS_TREE,
+          "Include process and its child processes",
+        "include-process-tree"},
+    {GST_WASAPI2_SRC_LOOPBACK_EXCLUDE_PROCESS_TREE,
+          "Exclude process and its child processes",
+        "exclude-process-tree"},
+    {0, nullptr, nullptr}
+  };
+
+  GST_WASAPI2_CALL_ONCE_BEGIN {
+    loopback_type = g_enum_register_static ("GstWasapi2SrcLoopbackMode", types);
+  } GST_WASAPI2_CALL_ONCE_END;
+
+  return loopback_type;
+}
+
+#define DEFAULT_LOW_LATENCY   FALSE
+#define DEFAULT_MUTE          FALSE
+#define DEFAULT_VOLUME        1.0
+#define DEFAULT_LOOPBACK      FALSE
+#define DEFAULT_LOOPBACK_MODE GST_WASAPI2_SRC_LOOPBACK_DEFAULT
+#define DEFAULT_LOOPBACK_SILENCE_ON_DEVICE_MUTE FALSE
+#define DEFAULT_CONTINUE_ON_ERROR FALSE
+#define DEFAULT_EXCLUSIVE FALSE
+
+enum
+{
+  PROP_0,
+  PROP_DEVICE,
+  PROP_LOW_LATENCY,
+  PROP_MUTE,
+  PROP_VOLUME,
+  PROP_DISPATCHER,
+  PROP_LOOPBACK,
+  PROP_LOOPBACK_MODE,
+  PROP_LOOPBACK_TARGET_PID,
+  PROP_LOOPBACK_SILENCE_ON_DEVICE_MUTE,
+  PROP_CONTINUE_ON_ERROR,
+  PROP_EXCLUSIVE,
+};
+
+/* *INDENT-OFF* */
+struct GstWasapi2SrcPrivate
+{
+  ~GstWasapi2SrcPrivate ()
+  {
+    gst_object_unref (rbuf);
+    g_free (device_id);
+  }
+
+  GstWasapi2Rbuf *rbuf = nullptr;
+
+  std::mutex lock;
+  std::atomic<bool> device_invalidated = { false };
+
+  /* properties */
+  gchar *device_id = nullptr;
+  gboolean low_latency = DEFAULT_LOW_LATENCY;
+  gboolean loopback = DEFAULT_LOOPBACK;
+  GstWasapi2SrcLoopbackMode loopback_mode = DEFAULT_LOOPBACK_MODE;
+  guint loopback_pid = 0;
+  gboolean loopback_silence_on_device_mute =
+      DEFAULT_LOOPBACK_SILENCE_ON_DEVICE_MUTE;
+  gboolean continue_on_error = DEFAULT_CONTINUE_ON_ERROR;
+  gboolean exclusive = DEFAULT_EXCLUSIVE;
+};
+/* *INDENT-ON* */
+
+struct _GstWasapi2Src
+{
+  GstAudioBaseSrc parent;
+
+  GstWasapi2SrcPrivate *priv;
+};
+
+static void gst_wasapi2_src_finalize (GObject * object);
+static void gst_wasapi2_src_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec);
+static void gst_wasapi2_src_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec);
+
+static GstCaps *gst_wasapi2_src_get_caps (GstBaseSrc * bsrc, GstCaps * filter);
+static GstAudioRingBuffer *gst_wasapi2_src_create_ringbuffer (GstAudioBaseSrc *
+    src);
+
+#define gst_wasapi2_src_parent_class parent_class
+G_DEFINE_TYPE_WITH_CODE (GstWasapi2Src, gst_wasapi2_src,
+    GST_TYPE_AUDIO_BASE_SRC,
+    G_IMPLEMENT_INTERFACE (GST_TYPE_STREAM_VOLUME, nullptr));
+
+static void
+gst_wasapi2_src_class_init (GstWasapi2SrcClass * klass)
+{
+  auto gobject_class = G_OBJECT_CLASS (klass);
+  auto element_class = GST_ELEMENT_CLASS (klass);
+  auto basesrc_class = GST_BASE_SRC_CLASS (klass);
+  auto audiobasesrc_class = GST_AUDIO_BASE_SRC_CLASS (klass);
+
+  gobject_class->finalize = gst_wasapi2_src_finalize;
+  gobject_class->set_property = gst_wasapi2_src_set_property;
+  gobject_class->get_property = gst_wasapi2_src_get_property;
+
+  g_object_class_install_property (gobject_class, PROP_DEVICE,
+      g_param_spec_string ("device", "Device",
+          "Audio device ID as provided by "
+          "WASAPI device endpoint ID as provided by IMMDevice::GetId",
+          nullptr, (GParamFlags) (GST_PARAM_MUTABLE_PLAYING |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (gobject_class, PROP_LOW_LATENCY,
+      g_param_spec_boolean ("low-latency", "Low latency",
+          "Optimize all settings for lowest latency. Always safe to enable.",
+          DEFAULT_LOW_LATENCY, (GParamFlags) (GST_PARAM_MUTABLE_READY |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (gobject_class, PROP_MUTE,
+      g_param_spec_boolean ("mute", "Mute", "Mute state of this stream",
+          DEFAULT_MUTE, (GParamFlags) (GST_PARAM_MUTABLE_PLAYING |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (gobject_class, PROP_VOLUME,
+      g_param_spec_double ("volume", "Volume", "Volume of this stream",
+          0.0, 1.0, DEFAULT_VOLUME, (GParamFlags) (GST_PARAM_MUTABLE_PLAYING |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  /**
+   * GstWasapi2Src:dispatcher:
+   *
+   * ICoreDispatcher COM object used for activating device from UI thread.
+   *
+   * Since: 1.18
+   */
+  g_object_class_install_property (gobject_class, PROP_DISPATCHER,
+      g_param_spec_pointer ("dispatcher", "Dispatcher",
+          "ICoreDispatcher COM object to use. In order for application to ask "
+          "permission of audio device, device activation should be running "
+          "on UI thread via ICoreDispatcher. This element will increase "
+          "the reference count of given ICoreDispatcher and release it after "
+          "use. Therefore, caller does not need to consider additional "
+          "reference count management",
+          (GParamFlags) (GST_PARAM_MUTABLE_READY | G_PARAM_WRITABLE |
+              G_PARAM_STATIC_STRINGS)));
+
+  /**
+   * GstWasapi2Src:loopback:
+   *
+   * Open render device for loopback recording
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (gobject_class, PROP_LOOPBACK,
+      g_param_spec_boolean ("loopback", "Loopback recording",
+          "Open render device for loopback recording", DEFAULT_LOOPBACK,
+          (GParamFlags) (GST_PARAM_MUTABLE_READY | G_PARAM_READWRITE |
+              G_PARAM_STATIC_STRINGS)));
+
+  if (gst_wasapi2_can_process_loopback ()) {
+    /**
+     * GstWasapi2Src:loopback-mode:
+     *
+     * Loopback mode. "target-process-id" must be specified in case of
+     * process loopback modes.
+     *
+     * This feature requires "Windows 10 build 20348"
+     *
+     * Since: 1.22
+     */
+    g_object_class_install_property (gobject_class, PROP_LOOPBACK_MODE,
+        g_param_spec_enum ("loopback-mode", "Loopback Mode",
+            "Loopback mode to use", GST_TYPE_WASAPI2_SRC_LOOPBACK_MODE,
+            DEFAULT_LOOPBACK_MODE,
+            (GParamFlags) (GST_PARAM_CONDITIONALLY_AVAILABLE |
+                GST_PARAM_MUTABLE_READY | G_PARAM_READWRITE |
+                G_PARAM_STATIC_STRINGS)));
+
+    /**
+     * GstWasapi2Src:loopback-target-pid:
+     *
+     * Target process id to be recorded or excluded depending on loopback mode
+     *
+     * This feature requires "Windows 10 build 20348"
+     *
+     * Since: 1.22
+     */
+    g_object_class_install_property (gobject_class, PROP_LOOPBACK_TARGET_PID,
+        g_param_spec_uint ("loopback-target-pid", "Loopback Target PID",
+            "Process ID to be recorded or excluded for process loopback mode",
+            0, G_MAXUINT32, 0,
+            (GParamFlags) (GST_PARAM_CONDITIONALLY_AVAILABLE |
+                GST_PARAM_MUTABLE_READY | G_PARAM_READWRITE |
+                G_PARAM_STATIC_STRINGS)));
+  }
+
+  /**
+   * GstWasapi2Src:loopback-silence-on-device-mute:
+   *
+   * When loopback recording, if the device is muted, inject silence in the pipeline
+   *
+   * Since: 1.24
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_LOOPBACK_SILENCE_ON_DEVICE_MUTE,
+      g_param_spec_boolean ("loopback-silence-on-device-mute",
+          "Loopback Silence On Device Mute",
+          "When loopback recording, if the device is muted, inject silence in the pipeline",
+          DEFAULT_LOOPBACK_SILENCE_ON_DEVICE_MUTE,
+          (GParamFlags) (GST_PARAM_MUTABLE_PLAYING | G_PARAM_READWRITE |
+              G_PARAM_STATIC_STRINGS)));
+
+  /**
+   * GstWasapi2Src:continue-on-error:
+   *
+   * If enabled, wasapi2src will post a warning message instead of an error,
+   * when device failures occur, such as open failure, I/O error,
+   * or device removal.
+   * The element will continue to produce audio buffers and behave as if
+   * a capture device were active, allowing pipeline to keep running even when
+   * no audio endpoint is available
+   *
+   * Since: 1.28
+   */
+  g_object_class_install_property (gobject_class, PROP_CONTINUE_ON_ERROR,
+      g_param_spec_boolean ("continue-on-error", "Continue On Error",
+          "Continue running and produce buffers on device failure",
+          DEFAULT_CONTINUE_ON_ERROR, (GParamFlags) (GST_PARAM_MUTABLE_READY |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  /**
+   * GstWasapi2Src:exclusive:
+   *
+   * Since: 1.28
+   */
+  g_object_class_install_property (gobject_class, PROP_EXCLUSIVE,
+      g_param_spec_boolean ("exclusive", "Exclusive",
+          "Open the device in exclusive mode",
+          DEFAULT_EXCLUSIVE,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  gst_element_class_add_static_pad_template (element_class, &src_template);
+  gst_element_class_set_static_metadata (element_class, "Wasapi2Src",
+      "Source/Audio/Hardware",
+      "Stream audio from an audio capture device through WASAPI",
+      "Seungha Yang <seungha@centricular.com>");
+
+  basesrc_class->get_caps = GST_DEBUG_FUNCPTR (gst_wasapi2_src_get_caps);
+
+  audiobasesrc_class->create_ringbuffer =
+      GST_DEBUG_FUNCPTR (gst_wasapi2_src_create_ringbuffer);
+
+  GST_DEBUG_CATEGORY_INIT (gst_wasapi2_src_debug, "wasapi2src",
+      0, "Windows audio session API source");
+
+  if (gst_wasapi2_can_process_loopback ()) {
+    gst_type_mark_as_plugin_api (GST_TYPE_WASAPI2_SRC_LOOPBACK_MODE,
+        (GstPluginAPIFlags) 0);
+  }
+}
+
+static void
+gst_wasapi2_src_on_invalidated (gpointer elem)
+{
+  auto self = GST_WASAPI2_SRC (elem);
+  auto priv = self->priv;
+
+  GST_WARNING_OBJECT (self, "Device invalidated");
+
+  priv->device_invalidated = true;
+}
+
+static void
+gst_wasapi2_src_init (GstWasapi2Src * self)
+{
+  auto priv = new GstWasapi2SrcPrivate ();
+
+  priv->rbuf = gst_wasapi2_rbuf_new (self, gst_wasapi2_src_on_invalidated);
+  gst_wasapi2_rbuf_set_device (priv->rbuf, nullptr,
+      GST_WASAPI2_ENDPOINT_CLASS_CAPTURE, 0, DEFAULT_LOW_LATENCY,
+      DEFAULT_EXCLUSIVE);
+
+  self->priv = priv;
+}
+
+static void
+gst_wasapi2_src_finalize (GObject * object)
+{
+  auto self = GST_WASAPI2_SRC (object);
+
+  delete self->priv;
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+gst_wasapi2_src_set_device (GstWasapi2Src * self, bool updated)
+{
+  auto priv = self->priv;
+  GstWasapi2EndpointClass device_class = GST_WASAPI2_ENDPOINT_CLASS_CAPTURE;
+  bool expected = true;
+  bool set_device = priv->device_invalidated.compare_exchange_strong (expected,
+      false);
+
+  if (!set_device && !updated)
+    return;
+
+  if (priv->loopback_pid) {
+    if (priv->loopback_mode == GST_WASAPI2_SRC_LOOPBACK_INCLUDE_PROCESS_TREE) {
+      device_class =
+          GST_WASAPI2_ENDPOINT_CLASS_INCLUDE_PROCESS_LOOPBACK_CAPTURE;
+    } else if (priv->loopback_mode ==
+        GST_WASAPI2_SRC_LOOPBACK_EXCLUDE_PROCESS_TREE) {
+      device_class =
+          GST_WASAPI2_ENDPOINT_CLASS_EXCLUDE_PROCESS_LOOPBACK_CAPTURE;
+    }
+  } else if (priv->loopback) {
+    device_class = GST_WASAPI2_ENDPOINT_CLASS_LOOPBACK_CAPTURE;
+  }
+
+  gst_wasapi2_rbuf_set_device (priv->rbuf, priv->device_id, device_class,
+      priv->loopback_pid, priv->low_latency, priv->exclusive);
+}
+
+static void
+gst_wasapi2_src_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  auto self = GST_WASAPI2_SRC (object);
+  auto priv = self->priv;
+
+  std::lock_guard < std::mutex > lk (priv->lock);
+
+  switch (prop_id) {
+    case PROP_DEVICE:
+    {
+      auto new_val = g_value_get_string (value);
+      bool updated = false;
+      if (g_strcmp0 (new_val, priv->device_id) != 0) {
+        g_free (priv->device_id);
+        priv->device_id = g_strdup (new_val);
+        updated = true;
+      }
+
+      gst_wasapi2_src_set_device (self, updated);
+      break;
+    }
+    case PROP_LOW_LATENCY:
+    {
+      auto new_val = g_value_get_boolean (value);
+      bool updated = false;
+      if (new_val != priv->low_latency) {
+        priv->low_latency = new_val;
+        updated = true;
+      }
+
+      gst_wasapi2_src_set_device (self, updated);
+      break;
+    }
+    case PROP_MUTE:
+      gst_wasapi2_rbuf_set_mute (priv->rbuf, g_value_get_boolean (value));
+      break;
+    case PROP_VOLUME:
+      gst_wasapi2_rbuf_set_volume (priv->rbuf, g_value_get_double (value));
+      break;
+    case PROP_DISPATCHER:
+      /* Unused */
+      break;
+    case PROP_LOOPBACK:
+    {
+      auto new_val = g_value_get_boolean (value);
+      bool updated = false;
+      if (new_val != priv->loopback) {
+        priv->loopback = new_val;
+        updated = true;
+      }
+
+      gst_wasapi2_src_set_device (self, updated);
+      break;
+    }
+    case PROP_LOOPBACK_MODE:
+    {
+      auto new_val = (GstWasapi2SrcLoopbackMode) g_value_get_enum (value);
+      bool updated = false;
+      if (new_val != priv->loopback_mode) {
+        priv->loopback_mode = new_val;
+        updated = true;
+      }
+
+      gst_wasapi2_src_set_device (self, updated);
+      break;
+    }
+    case PROP_LOOPBACK_TARGET_PID:
+    {
+      auto new_val = g_value_get_uint (value);
+      bool updated = false;
+      if (new_val != priv->loopback_pid) {
+        priv->loopback_pid = new_val;
+        updated = true;
+      }
+
+      gst_wasapi2_src_set_device (self, updated);
+      break;
+    }
+    case PROP_LOOPBACK_SILENCE_ON_DEVICE_MUTE:
+      priv->loopback_silence_on_device_mute = g_value_get_boolean (value);
+      gst_wasapi2_rbuf_set_device_mute_monitoring (priv->rbuf,
+          priv->loopback_silence_on_device_mute);
+      break;
+    case PROP_CONTINUE_ON_ERROR:
+      priv->continue_on_error = g_value_get_boolean (value);
+      gst_wasapi2_rbuf_set_continue_on_error (priv->rbuf,
+          priv->continue_on_error);
+      break;
+    case PROP_EXCLUSIVE:
+    {
+      auto new_val = g_value_get_boolean (value);
+      bool updated = false;
+      if (new_val != priv->exclusive) {
+        priv->exclusive = new_val;
+        updated = true;
+      }
+
+      gst_wasapi2_src_set_device (self, updated);
+      break;
+    }
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_wasapi2_src_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  auto self = GST_WASAPI2_SRC (object);
+  auto priv = self->priv;
+
+  std::lock_guard < std::mutex > lk (priv->lock);
+
+  switch (prop_id) {
+    case PROP_DEVICE:
+      g_value_set_string (value, priv->device_id);
+      break;
+    case PROP_LOW_LATENCY:
+      g_value_set_boolean (value, priv->low_latency);
+      break;
+    case PROP_MUTE:
+      g_value_set_boolean (value, gst_wasapi2_rbuf_get_mute (priv->rbuf));
+      break;
+    case PROP_VOLUME:
+      g_value_set_double (value, gst_wasapi2_rbuf_get_volume (priv->rbuf));
+      break;
+    case PROP_LOOPBACK:
+      g_value_set_boolean (value, priv->loopback);
+      break;
+    case PROP_LOOPBACK_MODE:
+      g_value_set_enum (value, priv->loopback_mode);
+      break;
+    case PROP_LOOPBACK_TARGET_PID:
+      g_value_set_uint (value, priv->loopback_pid);
+      break;
+    case PROP_LOOPBACK_SILENCE_ON_DEVICE_MUTE:
+      g_value_set_boolean (value, priv->loopback_silence_on_device_mute);
+      break;
+    case PROP_CONTINUE_ON_ERROR:
+      g_value_set_boolean (value, priv->continue_on_error);
+      break;
+    case PROP_EXCLUSIVE:
+      g_value_set_boolean (value, priv->exclusive);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static GstCaps *
+gst_wasapi2_src_get_caps (GstBaseSrc * bsrc, GstCaps * filter)
+{
+  auto self = GST_WASAPI2_SRC (bsrc);
+  auto priv = self->priv;
+  auto caps = gst_wasapi2_rbuf_get_caps (priv->rbuf);
+
+  if (!caps)
+    caps = gst_pad_get_pad_template_caps (bsrc->srcpad);
+
+  if (filter) {
+    GstCaps *filtered =
+        gst_caps_intersect_full (filter, caps, GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (caps);
+    caps = filtered;
+  }
+
+  GST_DEBUG_OBJECT (self, "returning caps %" GST_PTR_FORMAT, caps);
+
+  return caps;
+}
+
+static GstAudioRingBuffer *
+gst_wasapi2_src_create_ringbuffer (GstAudioBaseSrc * src)
+{
+  auto self = GST_WASAPI2_SRC (src);
+  auto priv = self->priv;
+
+  return GST_AUDIO_RING_BUFFER (priv->rbuf);
+}
diff --git a/sys/wasapi2/gstwasapi2util.cpp b/sys/wasapi2/gstwasapi2util.cpp
index 95faebc..c59f052 100644
--- a/sys/wasapi2/gstwasapi2util.cpp
+++ b/sys/wasapi2/gstwasapi2util.cpp
@@ -29,10 +29,26 @@
 #include <winternl.h>
 #include <mutex>
 #include <string.h>
+#include <wrl.h>
+#include <vector>
+#include <math.h>
 
 GST_DEBUG_CATEGORY_EXTERN (gst_wasapi2_debug);
 #define GST_CAT_DEFAULT gst_wasapi2_debug
 
+static GstStaticCaps template_caps = GST_STATIC_CAPS (GST_WASAPI2_STATIC_CAPS);
+
+/* *INDENT-OFF* */
+using namespace Microsoft::WRL;
+/* *INDENT-ON* */
+
+/* Define GUIDs instead of linking ksuser.lib */
+DEFINE_GUID (GST_KSDATAFORMAT_SUBTYPE_PCM, 0x00000001, 0x0000, 0x0010,
+    0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71);
+
+DEFINE_GUID (GST_KSDATAFORMAT_SUBTYPE_IEEE_FLOAT, 0x00000003, 0x0000, 0x0010,
+    0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71);
+
 /* Desktop only defines */
 #ifndef KSAUDIO_SPEAKER_MONO
 #define KSAUDIO_SPEAKER_MONO            (SPEAKER_FRONT_CENTER)
@@ -379,10 +395,11 @@ gst_wasapi2_util_waveformatex_to_audio_format (WAVEFORMATEX * format)
     case WAVE_FORMAT_EXTENSIBLE:
     {
       WAVEFORMATEXTENSIBLE *ex = (WAVEFORMATEXTENSIBLE *) format;
-      if (IsEqualGUID (ex->SubFormat, KSDATAFORMAT_SUBTYPE_PCM)) {
+      if (IsEqualGUID (ex->SubFormat, GST_KSDATAFORMAT_SUBTYPE_PCM)) {
         fmt = gst_audio_format_build_integer (TRUE, G_LITTLE_ENDIAN,
             format->wBitsPerSample, ex->Samples.wValidBitsPerSample);
-      } else if (IsEqualGUID (ex->SubFormat, KSDATAFORMAT_SUBTYPE_IEEE_FLOAT)) {
+      } else if (IsEqualGUID (ex->SubFormat,
+              GST_KSDATAFORMAT_SUBTYPE_IEEE_FLOAT)) {
         if (format->wBitsPerSample == 32
             && ex->Samples.wValidBitsPerSample == 32)
           fmt = GST_AUDIO_FORMAT_F32LE;
@@ -404,8 +421,7 @@ gst_wasapi2_util_waveformatex_to_audio_format (WAVEFORMATEX * format)
 
 gboolean
 gst_wasapi2_util_parse_waveformatex (WAVEFORMATEX * format,
-    GstCaps * template_caps, GstCaps ** out_caps,
-    GstAudioChannelPosition ** out_positions)
+    GstCaps ** out_caps, GstAudioChannelPosition ** out_positions)
 {
   const gchar *afmt;
   guint64 channel_mask;
@@ -429,21 +445,24 @@ gst_wasapi2_util_parse_waveformatex (WAVEFORMATEX * format,
   if (afmt == NULL)
     return FALSE;
 
-  *out_caps = gst_caps_copy (template_caps);
+  auto caps = gst_static_caps_get (&template_caps);
+  caps = gst_caps_make_writable (caps);
 
   channel_mask = gst_wasapi2_util_waveformatex_to_channel_mask (format,
       out_positions);
 
-  gst_caps_set_simple (*out_caps,
+  gst_caps_set_simple (caps,
       "format", G_TYPE_STRING, afmt,
       "channels", G_TYPE_INT, format->nChannels,
       "rate", G_TYPE_INT, format->nSamplesPerSec, NULL);
 
   if (channel_mask) {
-    gst_caps_set_simple (*out_caps,
+    gst_caps_set_simple (caps,
         "channel-mask", GST_TYPE_BITMASK, channel_mask, NULL);
   }
 
+  *out_caps = caps;
+
   return TRUE;
 }
 
@@ -542,10 +561,11 @@ gst_wasapi2_get_default_mix_format (void)
   format = (WAVEFORMATEX *) CoTaskMemAlloc (sizeof (WAVEFORMATEX));
   format->wFormatTag = WAVE_FORMAT_PCM;
   format->nChannels = 2;
-  format->nSamplesPerSec = 44100;
+  format->nSamplesPerSec = 48000;
   format->wBitsPerSample = 16;
   format->nBlockAlign = format->nChannels * format->wBitsPerSample / 8;
   format->nAvgBytesPerSec = format->nSamplesPerSec * format->nBlockAlign;
+  format->cbSize = 0;
 
   return format;
 }
@@ -592,3 +612,656 @@ gst_wasapi2_get_default_device_id (EDataFlow flow)
 
   return (const char *) render;
 }
+
+const gchar *
+gst_wasapi2_data_flow_to_string (EDataFlow flow)
+{
+  switch (flow) {
+    case eRender:
+      return "eRender";
+    case eCapture:
+      return "eCapture";
+    case eAll:
+      return "eAll";
+    default:
+      break;
+  }
+
+  return "Unknown";
+}
+
+const gchar *
+gst_wasapi2_role_to_string (ERole role)
+{
+  switch (role) {
+    case eConsole:
+      return "eConsole";
+    case eMultimedia:
+      return "eMultimedia";
+    case eCommunications:
+      return "eCommunications";
+    default:
+      break;
+  }
+
+  return "Unknown";
+}
+
+void
+gst_wasapi2_free_wfx (WAVEFORMATEX * wfx)
+{
+  if (wfx)
+    CoTaskMemFree (wfx);
+}
+
+void
+gst_wasapi2_clear_wfx (WAVEFORMATEX ** wfx)
+{
+  if (*wfx) {
+    CoTaskMemFree (*wfx);
+    *wfx = nullptr;
+  }
+}
+
+WAVEFORMATEX *
+gst_wasapi2_copy_wfx (WAVEFORMATEX * src)
+{
+  guint total_size = sizeof (WAVEFORMATEX) + src->cbSize;
+  auto dst = (WAVEFORMATEX *) CoTaskMemAlloc (total_size);
+  memcpy (dst, src, total_size);
+
+  return dst;
+}
+
+static DWORD
+make_channel_mask (WORD nChannels)
+{
+  switch (nChannels) {
+    case 1:
+      return KSAUDIO_SPEAKER_MONO;
+    case 2:
+      return KSAUDIO_SPEAKER_STEREO;
+    case 3:
+      return KSAUDIO_SPEAKER_3POINT0;
+    case 4:
+      return KSAUDIO_SPEAKER_QUAD;
+    case 5:
+      return KSAUDIO_SPEAKER_5POINT0;
+    case 6:
+      return KSAUDIO_SPEAKER_5POINT1;
+    case 7:
+      return KSAUDIO_SPEAKER_7POINT0;
+    case 8:
+      return KSAUDIO_SPEAKER_7POINT1;
+    default:
+      return 0;
+  }
+}
+
+static WAVEFORMATEXTENSIBLE
+make_wfx_ext (DWORD nSamplesPerSec, WORD nChannels, WORD wBitsPerSample,
+    WORD wValidBitsPerSample, bool is_float, DWORD dwChannelMask)
+{
+  WAVEFORMATEXTENSIBLE w = { };
+  w.Format.wFormatTag = WAVE_FORMAT_EXTENSIBLE;
+  w.Format.nChannels = nChannels;
+  w.Format.nSamplesPerSec = nSamplesPerSec;
+
+  w.Format.wBitsPerSample = wBitsPerSample;
+  w.Samples.wValidBitsPerSample = wValidBitsPerSample;
+
+  w.dwChannelMask = dwChannelMask ? dwChannelMask :
+      make_channel_mask (nChannels);
+  w.SubFormat = is_float ? GST_KSDATAFORMAT_SUBTYPE_IEEE_FLOAT
+      : GST_KSDATAFORMAT_SUBTYPE_PCM;
+
+  w.Format.nBlockAlign = (wBitsPerSample / 8) * nChannels;
+  w.Format.nAvgBytesPerSec = w.Format.nSamplesPerSec * w.Format.nBlockAlign;
+  w.Format.cbSize = sizeof (WAVEFORMATEXTENSIBLE) - sizeof (WAVEFORMATEX);
+
+  return w;
+}
+
+static inline gboolean
+is_extensible_format (const WAVEFORMATEX * wfx)
+{
+  return wfx->wFormatTag == WAVE_FORMAT_EXTENSIBLE &&
+      wfx->cbSize >= (sizeof (WAVEFORMATEXTENSIBLE) - sizeof (WAVEFORMATEX));
+}
+
+static inline DWORD
+get_wfx_channel_mask (const WAVEFORMATEX * wfx)
+{
+  if (is_extensible_format (wfx))
+    return ((const WAVEFORMATEXTENSIBLE *) wfx)->dwChannelMask;
+
+  return 0;
+}
+
+/* *INDENT-OFF* */
+gboolean
+gst_wasapi2_get_exclusive_mode_formats (IAudioClient * client,
+    IPropertyStore * props, GPtrArray * list)
+{
+  PROPVARIANT var;
+  PropVariantInit (&var);
+  WAVEFORMATEX *device_format = nullptr;
+  WAVEFORMATEX *closest = nullptr;
+  WAVEFORMATEX *basis = nullptr;
+  DWORD basis_ch_mask = 0;
+  WORD  basis_channels = 0;
+
+  /* Prefer device format if supported */
+  auto hr = props->GetValue (PKEY_AudioEngine_DeviceFormat, &var);
+  if (gst_wasapi2_result (hr)) {
+    if (var.vt == VT_BLOB && var.blob.cbSize >= sizeof (WAVEFORMATEX)
+        && var.blob.pBlobData) {
+      device_format = (WAVEFORMATEX *) CoTaskMemAlloc (var.blob.cbSize);
+
+      memcpy (device_format, var.blob.pBlobData, var.blob.cbSize);
+    }
+    PropVariantClear (&var);
+  }
+
+  if (device_format) {
+    hr = client->IsFormatSupported (AUDCLNT_SHAREMODE_EXCLUSIVE, device_format,
+        &closest);
+
+    if (hr == S_OK) {
+      basis = gst_wasapi2_copy_wfx (device_format);
+      g_ptr_array_add (list, device_format);
+      device_format = nullptr;
+    } else if (hr == S_FALSE && closest) {
+      basis = gst_wasapi2_copy_wfx (closest);
+      g_ptr_array_add (list, closest);
+      closest = nullptr;
+    }
+  }
+
+  gst_wasapi2_clear_wfx (&device_format);
+
+  /* Checks using pre-defined format list */
+  struct DepthPair
+  {
+    WORD wBitsPerSample;
+    WORD wValidBitsPerSample;
+    bool is_float;
+  };
+
+  const DepthPair depth_pairs[] = {
+    {32, 32, true},  /* 32-float */
+    {32, 32, false}, /* 32-int */
+    {16, 16, false}, /* 16-int */
+    {24, 24, false}, /* 24-packed */
+    {32, 24, false}, /* 24-in-32 */
+  };
+
+  const DWORD rates[] = { 192000, 176400, 96000, 88200, 48000, 44100 };
+  const WORD chs[] = { 8, 6, 2, 1 };
+
+  if (basis) {
+    basis_ch_mask = get_wfx_channel_mask (basis);
+    basis_channels = basis->nChannels;
+  }
+
+  for (auto r : rates) {
+    for (auto c : chs) {
+      for (auto d : depth_pairs) {
+        DWORD dwChannelMask = 0;
+        if (basis_ch_mask && c == basis_channels)
+          dwChannelMask = basis_ch_mask;
+
+        auto wfx = make_wfx_ext (r, c, d.wBitsPerSample, d.wValidBitsPerSample,
+            d.is_float, dwChannelMask);
+        hr = client->IsFormatSupported (AUDCLNT_SHAREMODE_EXCLUSIVE,
+            (WAVEFORMATEX *) &wfx, &closest);
+        if (hr == S_OK) {
+          g_ptr_array_add (list, gst_wasapi2_copy_wfx ((WAVEFORMATEX *) &wfx));
+        } else if (hr == S_FALSE && closest) {
+          g_ptr_array_add (list, closest);
+          closest = nullptr;
+        }
+      }
+    }
+  }
+
+  if (!basis) {
+    if (list && list->len > 0) {
+      auto first = (WAVEFORMATEX *) g_ptr_array_index (list, 0);
+      basis = gst_wasapi2_copy_wfx (first);
+    } else {
+      basis = gst_wasapi2_get_default_mix_format ();
+    }
+  }
+
+  gst_wasapi2_sort_wfx (list, basis);
+  gst_wasapi2_free_wfx (basis);
+
+  return TRUE;
+}
+
+gboolean
+gst_wasapi2_get_shared_mode_formats (IAudioClient * client, GPtrArray * list)
+{
+  PROPVARIANT var;
+  PropVariantInit (&var);
+  WAVEFORMATEX *mix_format = nullptr;
+  WAVEFORMATEX *closest = nullptr;
+
+  auto hr = client->GetMixFormat (&mix_format);
+  if (!gst_wasapi2_result (hr))
+    return FALSE;
+
+  g_ptr_array_add (list, gst_wasapi2_copy_wfx (mix_format));
+
+  /* Checks using pre-defined format list */
+  struct DepthPair
+  {
+    WORD wBitsPerSample;
+    WORD wValidBitsPerSample;
+    bool is_float;
+  };
+
+  const DepthPair depth_pairs[] = {
+    {32, 32, true},  /* 32-float */
+    {32, 32, false}, /* 32-int */
+    {16, 16, false}, /* 16-int */
+    {24, 24, false}, /* 24-packed */
+  };
+
+  const DWORD rates[] = { 192000, 176400, 96000, 88200, 48000, 44100 };
+  DWORD dwChannelMask = get_wfx_channel_mask (mix_format);
+
+  if (dwChannelMask == 0)
+    dwChannelMask = make_channel_mask (mix_format->nChannels);
+
+  for (auto r : rates) {
+    for (auto d : depth_pairs) {
+      auto wfx = make_wfx_ext (r, mix_format->nChannels, d.wBitsPerSample,
+          d.wValidBitsPerSample, d.is_float, dwChannelMask);
+      hr = client->IsFormatSupported (AUDCLNT_SHAREMODE_SHARED,
+          (WAVEFORMATEX *) &wfx, &closest);
+      if (hr == S_OK) {
+        g_ptr_array_add (list, gst_wasapi2_copy_wfx ((WAVEFORMATEX *) &wfx));
+      } else if (hr == S_FALSE && closest) {
+        g_ptr_array_add (list, closest);
+        closest = nullptr;
+      }
+    }
+  }
+
+  gst_wasapi2_sort_wfx (list, mix_format);
+  gst_wasapi2_free_wfx (mix_format);
+
+  return TRUE;
+}
+
+GstCaps *
+gst_wasapi2_wfx_list_to_caps (GPtrArray * list)
+{
+  if (!list || list->len == 0)
+    return nullptr;
+
+  std::vector <GstCaps *> caps_list;
+
+  for (guint i = 0; i < list->len; i++) {
+    auto wfx = (WAVEFORMATEX *) g_ptr_array_index (list, i);
+    GstCaps *tmp;
+
+    if (gst_wasapi2_util_parse_waveformatex (wfx, &tmp, nullptr)) {
+      bool unique = true;
+      for (auto it : caps_list) {
+        if (gst_caps_is_equal (it, tmp)) {
+          unique = false;
+          break;
+        }
+      }
+
+      if (unique)
+        caps_list.push_back (tmp);
+      else
+        gst_caps_unref (tmp);
+    }
+  }
+
+  if (caps_list.empty ())
+    return nullptr;
+
+  auto caps = gst_caps_new_empty ();
+  for (auto it : caps_list)
+    gst_caps_append (caps, it);
+
+  return caps;
+}
+/* *INDENT-ON* */
+
+struct FormatView
+{
+  WORD channels;
+  DWORD sample_rate;
+  GUID subformat;
+  WORD bits_per_sample;
+  WORD valid_bits_per_sample;
+  WORD raw_valid_bits_per_sample;
+  DWORD channel_mask;
+  WORD format_tag;
+};
+
+static inline gboolean
+is_float_subformat (const FormatView * v)
+{
+  return IsEqualGUID (v->subformat, GST_KSDATAFORMAT_SUBTYPE_IEEE_FLOAT);
+}
+
+static inline gboolean
+is_pcm_subformat (const FormatView * v)
+{
+  return IsEqualGUID (v->subformat, GST_KSDATAFORMAT_SUBTYPE_PCM);
+}
+
+static inline gint
+effective_bits (const FormatView * v)
+{
+  if (is_float_subformat (v))
+    return 32;
+
+  return v->valid_bits_per_sample ? v->
+      valid_bits_per_sample : v->bits_per_sample;
+}
+
+static inline gboolean
+is_s24_in_32 (const FormatView * v)
+{
+  return is_pcm_subformat (v) &&
+      v->bits_per_sample == 32 &&
+      (v->raw_valid_bits_per_sample == 24 || v->valid_bits_per_sample == 24);
+}
+
+static FormatView
+make_view (const WAVEFORMATEX * wfx)
+{
+  FormatView view = { };
+
+  view.channels = wfx->nChannels;
+  view.sample_rate = wfx->nSamplesPerSec;
+  view.bits_per_sample = wfx->wBitsPerSample;
+  view.format_tag = wfx->wFormatTag;
+
+  if (is_extensible_format (wfx)) {
+    auto wfe = (const WAVEFORMATEXTENSIBLE *) wfx;
+    view.subformat = wfe->SubFormat;
+    view.raw_valid_bits_per_sample = wfe->Samples.wValidBitsPerSample;
+    view.valid_bits_per_sample = view.raw_valid_bits_per_sample ?
+        view.raw_valid_bits_per_sample : view.bits_per_sample;
+    view.channel_mask = wfe->dwChannelMask;
+  } else {
+    if (wfx->wFormatTag == WAVE_FORMAT_PCM) {
+      view.subformat = GST_KSDATAFORMAT_SUBTYPE_PCM;
+    } else if (wfx->wFormatTag == WAVE_FORMAT_IEEE_FLOAT) {
+      view.subformat = GST_KSDATAFORMAT_SUBTYPE_IEEE_FLOAT;
+    }
+
+    view.raw_valid_bits_per_sample = view.bits_per_sample;
+    view.valid_bits_per_sample = view.bits_per_sample;
+    view.channel_mask = 0;
+  }
+
+  return view;
+}
+
+static gint
+compare_format_similarity (const FormatView * a, const FormatView * b,
+    const FormatView * basis)
+{
+  gboolean a_sub_eq = IsEqualGUID (a->subformat, basis->subformat);
+  gboolean b_sub_eq = IsEqualGUID (b->subformat, basis->subformat);
+
+  /* Check subformat (e.g., PCM vs FLOAT) */
+  if (a_sub_eq != b_sub_eq)
+    return a_sub_eq ? -1 : 1;
+
+  /* BPS diff */
+  gint da_bits =
+      abs ((gint) a->bits_per_sample - (gint) basis->bits_per_sample);
+  gint db_bits =
+      abs ((gint) b->bits_per_sample - (gint) basis->bits_per_sample);
+  if (da_bits != db_bits)
+    return (da_bits < db_bits) ? -1 : 1;
+
+  gint a_valid = a->valid_bits_per_sample ?
+      a->valid_bits_per_sample : a->bits_per_sample;
+  gint b_valid = b->valid_bits_per_sample ?
+      b->valid_bits_per_sample : b->bits_per_sample;
+  gint basis_valid = basis->valid_bits_per_sample ?
+      basis->valid_bits_per_sample : basis->bits_per_sample;
+
+  gint da_valid = abs (a_valid - basis_valid);
+  gint db_valid = abs (b_valid - basis_valid);
+  if (da_valid != db_valid)
+    return (da_valid < db_valid) ? -1 : 1;
+
+  /* Checks sample mask */
+  gboolean a_mask_eq = (a->channel_mask != 0 && basis->channel_mask != 0 &&
+      a->channel_mask == basis->channel_mask);
+  gboolean b_mask_eq = (b->channel_mask != 0 && basis->channel_mask != 0 &&
+      b->channel_mask == basis->channel_mask);
+  if (a_mask_eq != b_mask_eq)
+    return a_mask_eq ? -1 : 1;
+
+  /* Check format tag */
+  gint dtag_a = abs ((gint) a->format_tag - (gint) basis->format_tag);
+  gint dtag_b = abs ((gint) b->format_tag - (gint) basis->format_tag);
+  if (dtag_a != dtag_b)
+    return (dtag_a < dtag_b) ? -1 : 1;
+
+  return 0;
+}
+
+static gint
+compare_wfx_func (gconstpointer pa, gconstpointer pb, gpointer user_data)
+{
+  const WAVEFORMATEX *A = (const WAVEFORMATEX *) pa;
+  const WAVEFORMATEX *B = (const WAVEFORMATEX *) pb;
+  const WAVEFORMATEX *basis_wfx = (const WAVEFORMATEX *) user_data;
+
+  FormatView a = make_view (A);
+  FormatView b = make_view (B);
+  FormatView basis = make_view (basis_wfx);
+
+  /* S24_32LE is the lowest */
+  gboolean a_s2432 = is_s24_in_32 (&a);
+  gboolean b_s2432 = is_s24_in_32 (&b);
+  if (a_s2432 != b_s2432)
+    return a_s2432 ? 1 : -1;
+
+  /* Prefer same channel */
+  gint dch_a = abs ((gint) a.channels - (gint) basis.channels);
+  gint dch_b = abs ((gint) b.channels - (gint) basis.channels);
+  if (dch_a != dch_b)
+    return (dch_a < dch_b) ? -1 : 1;
+
+  /* Then sample rate */
+  gint64 dra = (gint64) a.sample_rate - (gint64) basis.sample_rate;
+  gint64 drb = (gint64) b.sample_rate - (gint64) basis.sample_rate;
+  dra = dra >= 0 ? dra : -dra;
+  drb = drb >= 0 ? drb : -drb;
+  if (dra != drb)
+    return (dra < drb) ? -1 : 1;
+
+  /* Prefere higher sample rate */
+  if (a.sample_rate != b.sample_rate)
+    return (a.sample_rate > b.sample_rate) ? -1 : +1;
+
+  /* High bit first */
+  gint a_bits = effective_bits (&a);
+  gint b_bits = effective_bits (&b);
+  if (a_bits != b_bits)
+    return (a_bits > b_bits) ? -1 : +1;
+
+  /* format compare */
+  gint fcmp = compare_format_similarity (&a, &b, &basis);
+  if (fcmp != 0)
+    return fcmp;
+
+  return 0;
+}
+
+/* *INDENT-OFF* */
+static void
+demote_s24_32le (GPtrArray *list)
+{
+  if (!list || list->len == 0)
+    return;
+
+  std::vector<gpointer> head;
+  std::vector<gpointer> tail;
+
+  head.reserve (list->len);
+  tail.reserve (list->len);
+
+  for (guint i = 0; i < list->len; i++) {
+    auto wfx = (WAVEFORMATEX *) g_ptr_array_index (list, i);
+    FormatView v = make_view (wfx);
+    if (is_s24_in_32 (&v))
+      tail.push_back ((gpointer) wfx);
+    else
+      head.push_back ((gpointer) wfx);
+  }
+
+  guint idx = 0;
+  for (gpointer p : head)
+    list->pdata[idx++] = p;
+
+  for (gpointer p : tail)
+    list->pdata[idx++] = p;
+}
+/* *INDENT-ON* */
+
+void
+gst_wasapi2_sort_wfx (GPtrArray * list, WAVEFORMATEX * wfx)
+{
+  if (!list || list->len == 0 || !wfx)
+    return;
+
+  g_ptr_array_sort_with_data (list, compare_wfx_func, wfx);
+  demote_s24_32le (list);
+}
+
+static DWORD
+gst_wasapi2_mask_from_gst_positions (const GstAudioInfo * info)
+{
+  DWORD mask = 0;
+
+  for (guint i = 0; i < (guint) GST_AUDIO_INFO_CHANNELS (info); i++) {
+    auto p = info->position[i];
+
+    if (p == GST_AUDIO_CHANNEL_POSITION_NONE ||
+        p == GST_AUDIO_CHANNEL_POSITION_INVALID) {
+      continue;
+    }
+
+    for (guint k = 0; k < G_N_ELEMENTS (wasapi_to_gst_pos); k++) {
+      if (wasapi_to_gst_pos[k].gst_pos == p) {
+        mask |= (DWORD) wasapi_to_gst_pos[k].wasapi_pos;
+        break;
+      }
+    }
+  }
+
+  if (mask == 0) {
+    guint ch = GST_AUDIO_INFO_CHANNELS (info);
+    if (ch < G_N_ELEMENTS (default_ch_masks))
+      mask = default_ch_masks[ch];
+  }
+
+  return mask;
+}
+
+WAVEFORMATEX *
+gst_wasapi2_audio_info_to_wfx (const GstAudioInfo * info)
+{
+  if (!info)
+    return nullptr;
+
+  auto channels = GST_AUDIO_INFO_CHANNELS (info);
+  auto rate = GST_AUDIO_INFO_RATE (info);
+  auto fmt = GST_AUDIO_INFO_FORMAT (info);
+
+  bool is_float = false;
+  WORD bits = 0;
+  WORD valid_bits = 0;
+
+  switch (fmt) {
+    case GST_AUDIO_FORMAT_S16LE:
+      bits = 16;
+      valid_bits = 16;
+      break;
+    case GST_AUDIO_FORMAT_S24LE:
+      bits = 24;
+      valid_bits = 24;
+      break;
+    case GST_AUDIO_FORMAT_S24_32LE:
+      bits = 32;
+      valid_bits = 24;
+      break;
+    case GST_AUDIO_FORMAT_S32LE:
+      bits = 32;
+      valid_bits = 32;
+      break;
+    case GST_AUDIO_FORMAT_F32LE:
+      is_float = true;
+      bits = 32;
+      valid_bits = 32;
+      break;
+    case GST_AUDIO_FORMAT_F64LE:
+      is_float = true;
+      bits = 64;
+      valid_bits = 64;
+      break;
+    default:
+      return nullptr;
+  }
+
+  DWORD ch_mask = gst_wasapi2_mask_from_gst_positions (info);
+  bool need_ext = false;
+  if ((!is_float && bits > 16) ||
+      (valid_bits != bits) || (channels > 2) || (is_float && channels > 2)) {
+    need_ext = true;
+  }
+
+  if (need_ext) {
+    auto w = (WAVEFORMATEXTENSIBLE *)
+        CoTaskMemAlloc (sizeof (WAVEFORMATEXTENSIBLE));
+
+    memset (w, 0, sizeof (WAVEFORMATEXTENSIBLE));
+    w->Format.wFormatTag = WAVE_FORMAT_EXTENSIBLE;
+    w->Format.nChannels = (WORD) channels;
+    w->Format.nSamplesPerSec = rate;
+    w->Format.wBitsPerSample = bits;
+
+    w->Samples.wValidBitsPerSample = valid_bits;
+    w->dwChannelMask = ch_mask ? ch_mask : make_channel_mask ((WORD) channels);
+    w->SubFormat = is_float ? GST_KSDATAFORMAT_SUBTYPE_IEEE_FLOAT
+        : GST_KSDATAFORMAT_SUBTYPE_PCM;
+
+    w->Format.nBlockAlign = (WORD) ((bits / 8) * channels);
+    w->Format.nAvgBytesPerSec =
+        w->Format.nSamplesPerSec * w->Format.nBlockAlign;
+    w->Format.cbSize = sizeof (WAVEFORMATEXTENSIBLE) - sizeof (WAVEFORMATEX);
+
+    return (WAVEFORMATEX *) w;
+  }
+
+  auto w = (WAVEFORMATEX *) CoTaskMemAlloc (sizeof (WAVEFORMATEX));
+
+  memset (w, 0, sizeof (WAVEFORMATEX));
+  w->wFormatTag = is_float ? WAVE_FORMAT_IEEE_FLOAT : WAVE_FORMAT_PCM;
+  w->nChannels = (WORD) channels;
+  w->nSamplesPerSec = rate;
+  w->wBitsPerSample = bits;
+  w->nBlockAlign = (WORD) ((bits / 8) * channels);
+  w->nAvgBytesPerSec = w->nSamplesPerSec * w->nBlockAlign;
+  w->cbSize = 0;
+
+  return w;
+}
diff --git a/sys/wasapi2/gstwasapi2util.h b/sys/wasapi2/gstwasapi2util.h
index b43a074..f4b4caa 100644
--- a/sys/wasapi2/gstwasapi2util.h
+++ b/sys/wasapi2/gstwasapi2util.h
@@ -101,7 +101,6 @@ guint64       gst_wasapi2_util_waveformatex_to_channel_mask (WAVEFORMATEX * form
 const gchar * gst_wasapi2_util_waveformatex_to_audio_format (WAVEFORMATEX * format);
 
 gboolean      gst_wasapi2_util_parse_waveformatex (WAVEFORMATEX * format,
-                                                   GstCaps * template_caps,
                                                    GstCaps ** out_caps,
                                                    GstAudioChannelPosition ** out_positions);
 
@@ -117,6 +116,30 @@ const wchar_t * gst_wasapi2_get_default_device_id_wide (EDataFlow flow);
 
 const char * gst_wasapi2_get_default_device_id (EDataFlow flow);
 
+const gchar * gst_wasapi2_data_flow_to_string (EDataFlow flow);
+
+const gchar * gst_wasapi2_role_to_string (ERole role);
+
+void gst_wasapi2_free_wfx (WAVEFORMATEX * wfx);
+
+void gst_wasapi2_clear_wfx (WAVEFORMATEX ** wfx);
+
+WAVEFORMATEX * gst_wasapi2_copy_wfx (WAVEFORMATEX * format);
+
+gboolean gst_wasapi2_get_exclusive_mode_formats (IAudioClient * client,
+                                                 IPropertyStore * props,
+                                                 GPtrArray * list);
+
+gboolean gst_wasapi2_get_shared_mode_formats (IAudioClient * client,
+                                              GPtrArray * list);
+
+GstCaps * gst_wasapi2_wfx_list_to_caps (GPtrArray * list);
+
+void      gst_wasapi2_sort_wfx (GPtrArray * list,
+                                WAVEFORMATEX * wfx);
+
+WAVEFORMATEX * gst_wasapi2_audio_info_to_wfx (const GstAudioInfo * info);
+
 G_END_DECLS
 
 #ifdef __cplusplus
diff --git a/sys/wasapi2/meson.build b/sys/wasapi2/meson.build
index a8332b8..98bfdf0 100644
--- a/sys/wasapi2/meson.build
+++ b/sys/wasapi2/meson.build
@@ -1,22 +1,20 @@
 wasapi2_sources = [
-  'gstwasapi2src.c',
-  'gstwasapi2sink.c',
+  'gstwasapi2src.cpp',
+  'gstwasapi2sink.cpp',
   'gstwasapi2util.cpp',
   'gstwasapi2device.cpp',
-  'gstwasapi2ringbuffer.cpp',
   'gstwasapi2activator.cpp',
   'gstwasapi2enumerator.cpp',
-  'gstwasapi2object.cpp',
+  'gstwasapi2rbuf.cpp',
   'plugin.cpp',
 ]
 
 wasapi2_headers = [
-  'gstwasapi2ringbuffer.h',
   'gstwasapi2device.h',
   'gstwasapi2util.h',
   'gstwasapi2src.h',
   'gstwasapi2sink.h',
-  'gstwasapi2object.h',
+  'gstwasapi2rbuf.h',
 ]
 
 mmdeviceapi_symbols = [
@@ -44,10 +42,9 @@ if host_system != 'windows'
 endif
 
 ole32_dep = cc.find_library('ole32', required : get_option('wasapi2'))
-ksuser_dep = cc.find_library('ksuser', required : get_option('wasapi2'))
 mmdeviceapi_dep = cc.find_library('mmdevapi', required : get_option('wasapi2'))
-mfplat_dep = cc.find_library('mfplat', required : get_option('wasapi2'))
-wasapi2_dep = [ole32_dep, ksuser_dep, mmdeviceapi_dep, mfplat_dep]
+avrt_dep = cc.find_library('avrt', required : get_option('wasapi2'))
+wasapi2_dep = [ole32_dep, mmdeviceapi_dep, avrt_dep]
 extra_args = []
 
 foreach dep: wasapi2_dep
diff --git a/sys/wasapi2/plugin.cpp b/sys/wasapi2/plugin.cpp
index 32cad37..7ffef5f 100644
--- a/sys/wasapi2/plugin.cpp
+++ b/sys/wasapi2/plugin.cpp
@@ -21,13 +21,10 @@
 #include <config.h>
 #endif
 
-#include <winapifamily.h>
-
 #include "gstwasapi2sink.h"
 #include "gstwasapi2src.h"
 #include "gstwasapi2device.h"
 #include "gstwasapi2util.h"
-#include <mfapi.h>
 
 GST_DEBUG_CATEGORY (gst_wasapi2_debug);
 GST_DEBUG_CATEGORY (gst_wasapi2_client_debug);
@@ -35,14 +32,12 @@ GST_DEBUG_CATEGORY (gst_wasapi2_client_debug);
 static void
 plugin_deinit (gpointer data)
 {
-  MFShutdown ();
 }
 
 static gboolean
 plugin_init (GstPlugin * plugin)
 {
   guint rank = GST_RANK_PRIMARY + 1;
-  HRESULT hr;
 
   /**
    * plugin-wasapi2:
@@ -50,15 +45,7 @@ plugin_init (GstPlugin * plugin)
    * Since: 1.18
    */
 
-  hr = MFStartup (MF_VERSION, MFSTARTUP_NOSOCKET);
-  if (!gst_wasapi2_result (hr)) {
-    GST_WARNING ("MFStartup failure, hr: 0x%x", (guint) hr);
-    return TRUE;
-  }
-
   GST_DEBUG_CATEGORY_INIT (gst_wasapi2_debug, "wasapi2", 0, "wasapi2");
-  GST_DEBUG_CATEGORY_INIT (gst_wasapi2_client_debug, "wasapi2client",
-      0, "wasapi2client");
 
   gst_element_register (plugin, "wasapi2sink", rank, GST_TYPE_WASAPI2_SINK);
   gst_element_register (plugin, "wasapi2src", rank, GST_TYPE_WASAPI2_SRC);
